{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index:\n",
    "\n",
    "- 0) Data Exploration\n",
    "- 1) Feature Engineering\n",
    "- 2) Data Transformation\n",
    "- 3) Some of the Baselines\n",
    "- 4) Backwards subset selection\n",
    "- 5) Model Optimization\n",
    "- 6) Final Model: Stacking\n",
    "- 7) Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (4000, 18), test shape = (1986, 17)\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "from Utility_functs import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tqdm \n",
    "#import imblearn\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble  import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "#                                  Load Dataset\n",
    "\n",
    "train, test, dataset = reset_dataset()\n",
    "assert len(dataset[dataset.chargesTotal.isna()]) == 0\n",
    "feature_importances = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" creazione lista con nomi variabili categoriche \"\"\"\n",
    "dtypes = train.dtypes.to_numpy()\n",
    "bool_mask = np.where((dtypes != 'float64') & (dtypes != 'int64'), True, False)\n",
    "\n",
    "cat_cols = list(train.iloc[:,bool_mask].columns)\n",
    "cat_cols += [\"senior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Pearson Correlation of Features'}>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train.drop(cat_cols,axis=1).astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c86bfb9f40>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time èa la più correlata alla y\n",
    "sns.displot(train[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1c86738b460>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 301.575x259.2 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(train.drop(cat_cols,axis=1), hue='y', palette = 'seismic',height=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x='backup', data=train, hue=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**aggiungo features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (4000, 18), test shape = (1986, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>senior</th>\n",
       "      <th>time</th>\n",
       "      <th>chargesMonth</th>\n",
       "      <th>chargesTotal</th>\n",
       "      <th>avg_surprise</th>\n",
       "      <th>avg_expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152268</td>\n",
       "      <td>-0.358064</td>\n",
       "      <td>0.186510</td>\n",
       "      <td>-0.207830</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.186984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.152268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.217438</td>\n",
       "      <td>0.094516</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.215827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-0.358064</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.833776</td>\n",
       "      <td>-0.020818</td>\n",
       "      <td>0.263536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargesMonth</th>\n",
       "      <td>0.186510</td>\n",
       "      <td>0.217438</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653476</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>0.994905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargesTotal</th>\n",
       "      <td>-0.207830</td>\n",
       "      <td>0.094516</td>\n",
       "      <td>0.833776</td>\n",
       "      <td>0.653476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054348</td>\n",
       "      <td>0.653650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_surprise</th>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>-0.020818</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>-0.054348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.068010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_expenditure</th>\n",
       "      <td>0.186984</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>0.263536</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>-0.068010</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        y    senior      time  chargesMonth  chargesTotal  \\\n",
       "y                1.000000  0.152268 -0.358064      0.186510     -0.207830   \n",
       "senior           0.152268  1.000000  0.008817      0.217438      0.094516   \n",
       "time            -0.358064  0.008817  1.000000      0.262295      0.833776   \n",
       "chargesMonth     0.186510  0.217438  0.262295      1.000000      0.653476   \n",
       "chargesTotal    -0.207830  0.094516  0.833776      0.653476      1.000000   \n",
       "avg_surprise     0.011984  0.005778 -0.020818     -0.009802     -0.054348   \n",
       "avg_expenditure  0.186984  0.215827  0.263536      0.994905      0.653650   \n",
       "\n",
       "                 avg_surprise  avg_expenditure  \n",
       "y                    0.011984         0.186984  \n",
       "senior               0.005778         0.215827  \n",
       "time                -0.020818         0.263536  \n",
       "chargesMonth        -0.009802         0.994905  \n",
       "chargesTotal        -0.054348         0.653650  \n",
       "avg_surprise         1.000000        -0.068010  \n",
       "avg_expenditure     -0.068010         1.000000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, dset = reset_dataset()\n",
    "#dset = train.copy(deep=True)\n",
    "dset_enh = dset.copy(deep=True) #sub w train to see correlations\n",
    "\n",
    "\n",
    "# quanto paga in più rispetto a quanto pagava prima (in media)\n",
    "dset_enh[\"avg_surprise\"] = (dset.chargesMonth * dset.time) - (dset.chargesTotal)\n",
    "\n",
    "# incremento % (considerando anche il segno) della spesa mensile\n",
    "# se time==0, metto una spesa media molto bassa, così da far uscire 0 come risultato finale\n",
    "# avg_surprise2 avrà valore 0 se la spesa nuova è simile a quella media, >0 se maggiore della media, \n",
    "# > 1 se più del doppio della spesa media\n",
    "time = dset.time.to_numpy()\n",
    "time[time == 0] = 0.00001\n",
    "# prima sottraevo la spesa mensile a charges total, ma in raeltà è già non inclusa, infatti se time==0, spesatotale=0\n",
    "# nota, metto un segno meno ad avg_expenditure poiché indica una spesa,che mi piace pensare come importo negativo\n",
    "avg_expenditure = ((dset.chargesTotal)/ time )\n",
    "#dset_enh[\"avg_surprise2\"] = ( (avg_expenditure - dset.chargesMonth)/abs(avg_expenditure)) \n",
    "\n",
    "# spesa media\n",
    "dset_enh[\"avg_expenditure\"] = avg_expenditure\n",
    "\n",
    "dset_enh.fillna(0, axis=1, inplace=True)\n",
    "\n",
    "dset_enh.iloc[:4000,:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creazione dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "      <th>chargesMonth</th>\n",
       "      <th>chargesTotal</th>\n",
       "      <th>avg_surprise</th>\n",
       "      <th>avg_expenditure</th>\n",
       "      <th>col0_Male</th>\n",
       "      <th>col1_Yes</th>\n",
       "      <th>col2_Yes</th>\n",
       "      <th>col3_No phone service</th>\n",
       "      <th>col3_Yes</th>\n",
       "      <th>col4_Fiber optic</th>\n",
       "      <th>col4_No</th>\n",
       "      <th>col5_No internet service</th>\n",
       "      <th>col5_Yes</th>\n",
       "      <th>col6_No internet service</th>\n",
       "      <th>col6_Yes</th>\n",
       "      <th>col7_No internet service</th>\n",
       "      <th>col7_Yes</th>\n",
       "      <th>col8_No internet service</th>\n",
       "      <th>col8_Yes</th>\n",
       "      <th>col9_No internet service</th>\n",
       "      <th>col9_Yes</th>\n",
       "      <th>col10_No internet service</th>\n",
       "      <th>col10_Yes</th>\n",
       "      <th>col11_Yes</th>\n",
       "      <th>col12_Credit card (automatic)</th>\n",
       "      <th>col12_Electronic check</th>\n",
       "      <th>col12_Mailed check</th>\n",
       "      <th>col13_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>66.15</td>\n",
       "      <td>3199.00</td>\n",
       "      <td>42.35</td>\n",
       "      <td>65.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.95</td>\n",
       "      <td>307.60</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>51.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.75</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>45.00</td>\n",
       "      <td>865.85</td>\n",
       "      <td>-10.85</td>\n",
       "      <td>45.571053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19.50</td>\n",
       "      <td>178.85</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>19.872222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y  time  chargesMonth  chargesTotal  avg_surprise  avg_expenditure  \\\n",
       "0  1.0    49         66.15       3199.00         42.35        65.285714   \n",
       "1  1.0     6         50.95        307.60         -1.90        51.266667   \n",
       "2  2.0     1         19.75         19.75          0.00        19.750000   \n",
       "3  1.0    19         45.00        865.85        -10.85        45.571053   \n",
       "4  1.0     9         19.50        178.85         -3.35        19.872222   \n",
       "\n",
       "   col0_Male  col1_Yes  col2_Yes  col3_No phone service  col3_Yes  \\\n",
       "0          1         0         1                      0         1   \n",
       "1          0         0         0                      1         0   \n",
       "2          1         0         1                      0         0   \n",
       "3          1         0         1                      0         0   \n",
       "4          0         0         1                      0         0   \n",
       "\n",
       "   col4_Fiber optic  col4_No  col5_No internet service  col5_Yes  \\\n",
       "0                 0        0                         0         0   \n",
       "1                 0        0                         0         1   \n",
       "2                 0        1                         1         0   \n",
       "3                 0        0                         0         0   \n",
       "4                 0        1                         1         0   \n",
       "\n",
       "   col6_No internet service  col6_Yes  col7_No internet service  col7_Yes  \\\n",
       "0                         0         0                         0         0   \n",
       "1                         0         1                         0         0   \n",
       "2                         1         0                         1         0   \n",
       "3                         0         0                         0         0   \n",
       "4                         1         0                         1         0   \n",
       "\n",
       "   col8_No internet service  col8_Yes  col9_No internet service  col9_Yes  \\\n",
       "0                         0         1                         0         1   \n",
       "1                         0         1                         0         0   \n",
       "2                         1         0                         1         0   \n",
       "3                         0         0                         0         0   \n",
       "4                         1         0                         1         0   \n",
       "\n",
       "   col10_No internet service  col10_Yes  col11_Yes  \\\n",
       "0                          0          0          1   \n",
       "1                          0          1          0   \n",
       "2                          1          0          0   \n",
       "3                          0          0          1   \n",
       "4                          1          0          1   \n",
       "\n",
       "   col12_Credit card (automatic)  col12_Electronic check  col12_Mailed check  \\\n",
       "0                              0                       0                   0   \n",
       "1                              1                       0                   0   \n",
       "2                              0                       0                   1   \n",
       "3                              0                       0                   0   \n",
       "4                              0                       1                   0   \n",
       "\n",
       "   col13_1  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_enh_dum = pd.get_dummies(dset_enh, columns = cat_cols, drop_first=True, prefix= [\"col\" + str(i) for i in range(len(cat_cols))])\n",
    "dset_enh_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**aggiungo interaction terms ad hoc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 35), (1986, 34))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" creo interaction ad hoc \"\"\"\n",
    "\n",
    "interactions= []\n",
    "\n",
    "# col4_Fiber_optic\n",
    "#int_col4 = dset_enh_dum.drop(\"y\",axis=1).mul(dset_enh_dum[\"col4_Fiber optic\"], axis=0).add_prefix('col4*')\n",
    "\n",
    "# multiple itneractions\n",
    "#int_mult = dset_enh_dum[\"time\"] * dset_enh_dum[\"col5_No\"] * dset_enh_dum[\"col8_No\"] * dset_enh_dum[\"col12_Electronic check\"]\n",
    "#interactions.append(int_mult)\n",
    "\n",
    "# female + senior\n",
    "#old_ladies = dset_enh_dum[\"senior\"] * dset_enh_dum[\"col0_Female\"] * dset_enh_dum[\"time\"]\n",
    "#interactions.append(old_ladies)\n",
    "\n",
    "# time^2\n",
    "time_2 = dset_enh_dum[\"time\"] **2\n",
    "interactions.append(time_2)\n",
    "\n",
    "# low surprise (automatic billing)\n",
    "anti_surpr = dset_enh_dum[\"col12_Credit card (automatic)\"] * dset_enh_dum[\"avg_surprise\"]\n",
    "interactions.append(anti_surpr)\n",
    "\n",
    "# huge backups (backup + time)\n",
    "bkup = dset_enh_dum[\"col9_Yes\"] * dset_enh_dum[\"time\"]\n",
    "interactions.append(bkup)\n",
    "\n",
    "# no inentives (no \"backup\",\"protection\",\"support\")\n",
    "no_services = dset_enh_dum[\"col9_Yes\"] * dset_enh_dum[\"col10_Yes\"] * dset_enh_dum[\"col11_Yes\"]\n",
    "interactions.append(no_services)\n",
    "\n",
    "# high surprise (automatic billing)\n",
    "#high_surp = dset_enh_dum[\"col12_Mailed check\"] * dset_enh_dum[\"avg_surprise\"]\n",
    "#interactions.append(high_surp)\n",
    "\n",
    "\n",
    "relevant_surprise = dset_enh_dum[\"avg_surprise\"] * dset_enh_dum[\"chargesTotal\"]\n",
    "interactions.append(relevant_surprise)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# join\n",
    "df_prova = pd.concat([dset_enh_dum] + interactions, axis=1)\n",
    "\n",
    "_dset = df_prova.copy(deep=True)\n",
    "train_enh_prova, test_enh_prova = split_dset(_dset, split_val=4000)\n",
    "train_enh_prova.shape, test_enh_prova.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**droppo features**\n",
    "\n",
    "droppo alcune features rivelatesi poco interessanti (gender, married, phone) e alcune dummies identiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_dummies = [\"col\"+str(i)+\"_No internet service\"for i in[5,6,7,8,9]]\n",
    "df_enh_pre_drop = dset_enh_dum.drop(columns=duplicated_dummies, axis=1).copy(deep=True)\n",
    "\n",
    "train_enh_org = dset_enh_dum.iloc[:4000,:].copy(deep=True)\n",
    "uninteresting_cols = [\"col0_Male\", \"col1_Yes\", \"col2_Yes\"] + duplicated_dummies\n",
    "#uninteresting_cols = [col for col in dset_enh_dum.columns  for i in cols if col.startswith(str(i)+\"_\")]   \n",
    "\n",
    "dset_enh_dum = dset_enh_dum.drop(columns=uninteresting_cols, axis=1)\n",
    "df_prova     = df_prova.drop(columns=uninteresting_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creo un df in cui aggiungo interaction terms in massa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape del train_poly senza aggiungere le var escluse (5986, 78)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "      <th>chargesMonth</th>\n",
       "      <th>chargesTotal</th>\n",
       "      <th>avg_surprise</th>\n",
       "      <th>avg_expenditure</th>\n",
       "      <th>col3_No phone service</th>\n",
       "      <th>col3_Yes</th>\n",
       "      <th>col5_Yes</th>\n",
       "      <th>col9_Yes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>66.15</td>\n",
       "      <td>3199.00</td>\n",
       "      <td>42.35</td>\n",
       "      <td>65.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>50.95</td>\n",
       "      <td>307.60</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>51.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.75</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y  time  chargesMonth  chargesTotal  avg_surprise  avg_expenditure  \\\n",
       "0  1.0    49         66.15       3199.00         42.35        65.285714   \n",
       "1  1.0     6         50.95        307.60         -1.90        51.266667   \n",
       "2  2.0     1         19.75         19.75          0.00        19.750000   \n",
       "\n",
       "   col3_No phone service  col3_Yes  col5_Yes  col9_Yes    0    1    2    3  \\\n",
       "0                      0         1         0         1  0.0  0.0  0.0  0.0   \n",
       "1                      1         0         1         0  0.0  0.0  1.0  0.0   \n",
       "2                      0         0         0         0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "     4    5    6    7    8    9   10   11   12   13   14   15   16   17   18  \\\n",
       "0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    19   20   21   22   23   24   25   26   27   28   29   30   31   32   33  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "    34   35   36   37   38   39   40   41   42   43   44   45   46   47   48  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    49   50   51   52   53   54   55   56   57   58   59   60   61   62   63  \\\n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "\n",
       "    64   65   66   67   68   69   70   71   72   73   74   75   76   77  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" creo dset_poly \"\"\"\n",
    "# non facciamo il quadrato o le interaction della y \n",
    "df = dset_enh_dum.copy(deep=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "cols = [\"col\" + str(i) for i in[1,4,6,7,8,11,12]]\n",
    "interesting_cols = [col for col in dset_enh_dum.columns  for i in cols if col.startswith(str(i))]     \n",
    "non_interesting = [i for i in dset_enh_dum.columns if i not in interesting_cols]\n",
    "to_drop = [\"y\"] + non_interesting\n",
    "\n",
    "\n",
    "# interaction di ognuno verso ogni altro + le features iniziali,\n",
    "\n",
    "poly = PolynomialFeatures(2, interaction_only = True, include_bias = False)\n",
    "poly.fit(df.drop(to_drop, axis=1))\n",
    "\n",
    "dset_poly  = pd.DataFrame(poly.transform(df.drop(to_drop, axis=1)))\n",
    "print(\"shape del train_poly senza aggiungere le var escluse\", dset_poly.shape)\n",
    "\n",
    "# aggiungiamo le var escluse\n",
    "to_drop.remove(\"y\")\n",
    "dset_poly = pd.concat([df.drop(interesting_cols, axis=1), dset_poly], axis=1)\n",
    "#dset_poly[\"y\"] = df[\"y\"]\n",
    "\n",
    "dset_poly.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Trasformation \n",
    "\n",
    "[sklearn_preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting test and train\n",
    "(necessario per fittare i metodi di data transformation solo sul train ed applicarli anche al test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dset = dset_enh_dum.copy(deep=True)\n",
    "train_enh_dum, test_enh_dum = split_dset(_dset, split_val=4000)\n",
    "train_enh_dum.shape, test_enh_dum.shape\n",
    "\n",
    "_dset = df_enh_pre_drop.copy(deep=True)\n",
    "train_enh_pre_drop, test_enh_pre_drop = split_dset(_dset, split_val=4000)\n",
    "train_enh_pre_drop.shape, test_enh_pre_drop.shape\n",
    "\n",
    "_dset = dset_poly.copy(deep=True)\n",
    "train_enh_poly, test_enh_poly = split_dset(_dset, split_val=4000)\n",
    "train_enh_poly.shape, test_enh_poly.shape\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "train_dfs = []\n",
    "train_dfs.extend([\"train_enh_dum\", \"train_enh_poly\", \"train_enh_prova\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Normalizzazione](https://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Uso lo Standard Scaler di Sklearn \"\"\"\n",
    "\n",
    "def standardize_data(train_df, test_df, cat_cols=None):\n",
    "    assert train_df.drop(\"y\", axis=1).shape[1] == test_df.shape[1], \"unequal shapes\"\n",
    "    \n",
    "    # non vogliamo scalare la y quindi la droppiamo da qui\n",
    "    to_drop = [\"y\"]\n",
    "#    if cat_cols:\n",
    "#        to_drop += cat_cols     \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df.drop(\"y\", axis=1))\n",
    "\n",
    "    stded_train = scaler.transform(train_df.drop(\"y\", axis=1))\n",
    "    stded_test  = scaler.transform(test_df)\n",
    "    \n",
    "    names = [i for i in train_df.columns if i != \"y\"]\n",
    "    train_stded = pd.DataFrame(stded_train, columns= names)\n",
    "    train_stded[\"y\"] = train_df[\"y\"]\n",
    "    test_stded = pd.DataFrame(stded_test, columns= names)\n",
    "\n",
    "    return train_stded, test_stded\n",
    "\n",
    "train_enh_stded, test_enh_stded =  standardize_data(train_enh_dum, test_enh_dum)\n",
    "train_dfs.append(\"train_enh_stded\")\n",
    "\n",
    "train_enh_pre_stded, test_enh_pre_stded =  standardize_data(train_enh_pre_drop, test_enh_pre_drop)\n",
    "train_dfs.append(\"train_enh_pre_stded\")\n",
    "\n",
    "train_prova_stded, test_prova_stded =  standardize_data(train_enh_prova, test_enh_prova)\n",
    "train_dfs.append(\"train_prova_stded\")\n",
    "\n",
    "train_poly_stded, test_poly_stded = standardize_data(train_enh_poly, test_enh_poly)\n",
    "train_dfs.append(\"train_poly_stded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Some of the Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Bernoulli Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -210.9 std =  19.429101883514843\n"
     ]
    }
   ],
   "source": [
    "df = train_enh_dum \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.4\n",
    "priors = [prior_l, 1-prior_l]\n",
    "\n",
    "B_NB = BernoulliNB(alpha=1,\n",
    "                   class_prior=priors) #priors=priors\n",
    "cv_result = compute_cv(B_NB, X, y, 10, scorer=loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[QDA](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -320.1 std =  81.08076220658018\n"
     ]
    }
   ],
   "source": [
    "df = train_enh_dum \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.35 \n",
    "priors = [prior_l, 1-prior_l]\n",
    "\n",
    "QDA = QuadraticDiscriminantAnalysis(tol=-1, priors=priors) #priors=priors\n",
    "cv_result = compute_cv(QDA, X, y, 10, scorer=loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -207.4 std =  26.012304780622575\n"
     ]
    }
   ],
   "source": [
    "df = train_poly_stded #.drop(\"senior\",axis=1) \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "class_weight = {1:1, 2:5}\n",
    "_SVC = SVC(class_weight=class_weight,\n",
    "           kernel = \"rbf\",\n",
    "           C=1.5,\n",
    "           probability=False,         # settalo a true prima di fare fit\n",
    "           random_state=0,\n",
    "           cache_size=600) \n",
    "\n",
    "cv_result = compute_cv(_SVC, X, y, 10, scorer=loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[KNN Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)** (non sembra avere class weights, occorre settare una threshold, crea un custom k_folds).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  189.1 std = 27.020177645604036\n"
     ]
    }
   ],
   "source": [
    "k= 10\n",
    "df = train_enh_stded\n",
    "thr = 0.8\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=50, weights= \"distance\", p=2, n_jobs=-1)\n",
    "\n",
    "cv_scores = custom_k_folds(KNN, df, thr=thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MLP Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugen\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "\n",
      "C:\\Users\\Eugen\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "\n",
      "C:\\Users\\Eugen\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "\n",
      "C:\\Users\\Eugen\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -285.1 std =  21.454370184183922\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df = train_enh_stded \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "MLP = MLPClassifier(alpha = 0.001,        #l2 regularization\n",
    "                    #learning_rate=\"invscaling\",\n",
    "                    #activation=\"relu\",\n",
    "                    learning_rate_init=0.001,\n",
    "                    #early_stopping=True,\n",
    "                    random_state=1,\n",
    "                    max_iter=900)\n",
    "\n",
    "cv_result = compute_cv(MLP, X, y, 10, scorer=loss_function)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Backwards Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features</th>\n",
       "      <th>removed_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col5_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col6_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col8_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col0_Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col1_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col4_Fiber optic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>col12_Mailed check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_expendi...</td>\n",
       "      <td>avg_surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_expendi...</td>\n",
       "      <td>col13_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col2_Yes, c...</td>\n",
       "      <td>avg_expenditure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>col2_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>col9_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>col10_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>col4_No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>col5_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>chargesMonth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>col6_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>col7_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>col9_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>col10_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col7_No interne...</td>\n",
       "      <td>col3_No phone service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col8_No interne...</td>\n",
       "      <td>col7_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col11_Yes, col1...</td>\n",
       "      <td>col8_No internet service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col11_Yes, col1...</td>\n",
       "      <td>col12_Credit card (automatic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>[time, chargesTotal, col11_Yes, col12_Electron...</td>\n",
       "      <td>col3_Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>[time, chargesTotal, col11_Yes]</td>\n",
       "      <td>col12_Electronic check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                           features  \\\n",
       "0             29  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "1             28  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "2             27  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "3             26  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "4             25  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "5             24  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "6             23  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "7             22  [time, chargesMonth, chargesTotal, avg_expendi...   \n",
       "8             21  [time, chargesMonth, chargesTotal, avg_expendi...   \n",
       "9             20  [time, chargesMonth, chargesTotal, col2_Yes, c...   \n",
       "10            19  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "11            18  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "12            17  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "13            16  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "14            15  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "15            14  [time, chargesTotal, col3_No phone service, co...   \n",
       "16            13  [time, chargesTotal, col3_No phone service, co...   \n",
       "17            12  [time, chargesTotal, col3_No phone service, co...   \n",
       "18            11  [time, chargesTotal, col3_No phone service, co...   \n",
       "19            10  [time, chargesTotal, col3_No phone service, co...   \n",
       "20             9  [time, chargesTotal, col3_Yes, col7_No interne...   \n",
       "21             8  [time, chargesTotal, col3_Yes, col8_No interne...   \n",
       "22             7  [time, chargesTotal, col3_Yes, col11_Yes, col1...   \n",
       "23             6  [time, chargesTotal, col3_Yes, col11_Yes, col1...   \n",
       "24             5  [time, chargesTotal, col11_Yes, col12_Electron...   \n",
       "25             4                    [time, chargesTotal, col11_Yes]   \n",
       "\n",
       "                      removed_col  \n",
       "0                        col5_Yes  \n",
       "1                        col6_Yes  \n",
       "2                        col8_Yes  \n",
       "3                       col0_Male  \n",
       "4                        col1_Yes  \n",
       "5                col4_Fiber optic  \n",
       "6              col12_Mailed check  \n",
       "7                    avg_surprise  \n",
       "8                         col13_1  \n",
       "9                 avg_expenditure  \n",
       "10                       col2_Yes  \n",
       "11                       col9_Yes  \n",
       "12                      col10_Yes  \n",
       "13                        col4_No  \n",
       "14       col5_No internet service  \n",
       "15                   chargesMonth  \n",
       "16       col6_No internet service  \n",
       "17                       col7_Yes  \n",
       "18       col9_No internet service  \n",
       "19      col10_No internet service  \n",
       "20          col3_No phone service  \n",
       "21       col7_No internet service  \n",
       "22       col8_No internet service  \n",
       "23  col12_Credit card (automatic)  \n",
       "24                       col3_Yes  \n",
       "25         col12_Electronic check  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #Backwards subset selection with LR \n",
    "\n",
    "import itertools\n",
    "\n",
    "df = train_enh_pre_drop #[[col for col in train_enh_stded if col!=\"avg_expenditure\"]] \n",
    "X = df.drop(\"y\",axis=1)\n",
    "y = df.y.to_numpy()\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        #C = 0.7,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "lista_risultati = []\n",
    "curr_cols = [col for col in X.columns]\n",
    "#Looping \n",
    "for k in range(len(X.columns), 3, -1):\n",
    "    \n",
    "    eva_cols = []\n",
    "    train_err = np.zeros(k)\n",
    "    #Looping over all possible combinations: from 11 choose k\n",
    "    for i, col in enumerate(curr_cols):\n",
    "        curr_X = X.drop(col,axis=1)\n",
    "        LR.fit(curr_X ,y)\n",
    "        train_err[i] = custom_scorer(y, LR.predict(curr_X))\n",
    "        eva_cols.append(col)\n",
    "\n",
    "    col_to_remove = curr_cols[np.argmin(train_err)]\n",
    "    curr_cols.remove(col_to_remove)\n",
    "    lista_risultati.append([k, curr_cols.copy(), col_to_remove])\n",
    "\n",
    "#Store in DataFrame\n",
    "#colonne_df = [\"num_features\", 'cv_mean',\"cv_std\", \"features\" ]\n",
    "#risultati = pd.DataFrame(lista_risultati, columns = colonne_df)\n",
    "colonne_df = [\"num_features\", \"features\", \"removed_col\" ]\n",
    "risultati = pd.DataFrame(lista_risultati, columns = colonne_df)\n",
    "#risultati.to_csv(\"bss_lr.csv\")\n",
    "risultati #.sort_values(\"train_err\").groupby(\"num_features\", as_index=False).first()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# evaluating p models with RF \n",
    "\n",
    "class_weights = {1:1, 2:5}\n",
    "RF = RandomForestClassifier(n_estimators= 1000,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0,\n",
    "                            class_weight= class_weights,\n",
    "                            #min_samples_leaf = 50,\n",
    "                            #min_samples_split =3,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features=\"log2\")\n",
    "\n",
    "scores = []\n",
    "for cols in risultati.features.to_list():\n",
    "    X = df[cols]\n",
    "    y = df.y.to_numpy()\n",
    "    cv_result = compute_cv(RF, X, y, 10, scorer=loss_function)\n",
    "    scores.append([len(cols), cols, cv_result.mean(), cv_result.std()])\n",
    "    \n",
    "colonne_df = [\"num_features\", \"features\", \"mean test_error\", \"test_error_std\" ]\n",
    "df_scores_RF = pd.DataFrame(scores, columns = colonne_df)\n",
    "risultati.to_csv(\"df_scores_RF.csv\")\n",
    "df_scores_RF\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -175.2 std =  11.989995829857492\n",
      "mean =  -175.4 std =  10.229369482035539\n",
      "mean =  -174.5 std =  11.569356075426152\n",
      "mean =  -175.2 std =  10.833282051160674\n",
      "mean =  -175.5 std =  10.809717850156867\n",
      "mean =  -183.5 std =  14.609928131240071\n",
      "mean =  -181.8 std =  13.78259772321604\n",
      "mean =  -181.1 std =  11.80211845390479\n",
      "mean =  -186.4 std =  12.09297316626478\n",
      "mean =  -186.0 std =  13.62350909274112\n",
      "mean =  -186.8 std =  13.302631318652711\n",
      "mean =  -186.7 std =  14.574292435655325\n",
      "mean =  -187.5 std =  14.284607099952032\n",
      "mean =  -187.4 std =  13.828955130450025\n",
      "mean =  -187.7 std =  14.028898745090435\n",
      "mean =  -186.2 std =  10.428806259586953\n",
      "mean =  -186.0 std =  10.658330075579382\n",
      "mean =  -187.8 std =  11.914696806885184\n",
      "mean =  -187.7 std =  11.832582135780845\n",
      "mean =  -187.7 std =  11.832582135780845\n",
      "mean =  -186.4 std =  13.101144988129855\n",
      "mean =  -186.5 std =  13.45548215412588\n",
      "mean =  -190.3 std =  21.269931828757702\n",
      "mean =  -190.4 std =  21.518364250100422\n",
      "mean =  -187.6 std =  21.735684944349003\n",
      "mean =  -199.2 std =  20.63395260244629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_features</th>\n",
       "      <th>features</th>\n",
       "      <th>mean test_error</th>\n",
       "      <th>test_error_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>11.989996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-175.4</td>\n",
       "      <td>10.229369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>11.569356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>10.833282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-175.5</td>\n",
       "      <td>10.809718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-183.5</td>\n",
       "      <td>14.609928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_surpris...</td>\n",
       "      <td>-181.8</td>\n",
       "      <td>13.782598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_expendi...</td>\n",
       "      <td>-181.1</td>\n",
       "      <td>11.802118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, avg_expendi...</td>\n",
       "      <td>-186.4</td>\n",
       "      <td>12.092973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col2_Yes, c...</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>13.623509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>-186.8</td>\n",
       "      <td>13.302631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>-186.7</td>\n",
       "      <td>14.574292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>-187.5</td>\n",
       "      <td>14.284607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>-187.4</td>\n",
       "      <td>13.828955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[time, chargesMonth, chargesTotal, col3_No pho...</td>\n",
       "      <td>-187.7</td>\n",
       "      <td>14.028899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>-186.2</td>\n",
       "      <td>10.428806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>10.658330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>-187.8</td>\n",
       "      <td>11.914697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>-187.7</td>\n",
       "      <td>11.832582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>[time, chargesTotal, col3_No phone service, co...</td>\n",
       "      <td>-187.7</td>\n",
       "      <td>11.832582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col7_No interne...</td>\n",
       "      <td>-186.4</td>\n",
       "      <td>13.101145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col8_No interne...</td>\n",
       "      <td>-186.5</td>\n",
       "      <td>13.455482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col11_Yes, col1...</td>\n",
       "      <td>-190.3</td>\n",
       "      <td>21.269932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>[time, chargesTotal, col3_Yes, col11_Yes, col1...</td>\n",
       "      <td>-190.4</td>\n",
       "      <td>21.518364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>[time, chargesTotal, col11_Yes, col12_Electron...</td>\n",
       "      <td>-187.6</td>\n",
       "      <td>21.735685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>[time, chargesTotal, col11_Yes]</td>\n",
       "      <td>-199.2</td>\n",
       "      <td>20.633953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_features                                           features  \\\n",
       "0             28  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "1             27  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "2             26  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "3             25  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "4             24  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "5             23  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "6             22  [time, chargesMonth, chargesTotal, avg_surpris...   \n",
       "7             21  [time, chargesMonth, chargesTotal, avg_expendi...   \n",
       "8             20  [time, chargesMonth, chargesTotal, avg_expendi...   \n",
       "9             19  [time, chargesMonth, chargesTotal, col2_Yes, c...   \n",
       "10            18  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "11            17  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "12            16  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "13            15  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "14            14  [time, chargesMonth, chargesTotal, col3_No pho...   \n",
       "15            13  [time, chargesTotal, col3_No phone service, co...   \n",
       "16            12  [time, chargesTotal, col3_No phone service, co...   \n",
       "17            11  [time, chargesTotal, col3_No phone service, co...   \n",
       "18            10  [time, chargesTotal, col3_No phone service, co...   \n",
       "19             9  [time, chargesTotal, col3_No phone service, co...   \n",
       "20             8  [time, chargesTotal, col3_Yes, col7_No interne...   \n",
       "21             7  [time, chargesTotal, col3_Yes, col8_No interne...   \n",
       "22             6  [time, chargesTotal, col3_Yes, col11_Yes, col1...   \n",
       "23             5  [time, chargesTotal, col3_Yes, col11_Yes, col1...   \n",
       "24             4  [time, chargesTotal, col11_Yes, col12_Electron...   \n",
       "25             3                    [time, chargesTotal, col11_Yes]   \n",
       "\n",
       "    mean test_error  test_error_std  \n",
       "0            -175.2       11.989996  \n",
       "1            -175.4       10.229369  \n",
       "2            -174.5       11.569356  \n",
       "3            -175.2       10.833282  \n",
       "4            -175.5       10.809718  \n",
       "5            -183.5       14.609928  \n",
       "6            -181.8       13.782598  \n",
       "7            -181.1       11.802118  \n",
       "8            -186.4       12.092973  \n",
       "9            -186.0       13.623509  \n",
       "10           -186.8       13.302631  \n",
       "11           -186.7       14.574292  \n",
       "12           -187.5       14.284607  \n",
       "13           -187.4       13.828955  \n",
       "14           -187.7       14.028899  \n",
       "15           -186.2       10.428806  \n",
       "16           -186.0       10.658330  \n",
       "17           -187.8       11.914697  \n",
       "18           -187.7       11.832582  \n",
       "19           -187.7       11.832582  \n",
       "20           -186.4       13.101145  \n",
       "21           -186.5       13.455482  \n",
       "22           -190.3       21.269932  \n",
       "23           -190.4       21.518364  \n",
       "24           -187.6       21.735685  \n",
       "25           -199.2       20.633953  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  #evaluating p models with LR \n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        #C = 1.2,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "scores = []\n",
    "for cols in risultati.features.to_list():\n",
    "    X = df[cols]\n",
    "    y = df.y.to_numpy()\n",
    "    cv_result = compute_cv(LR, X, y, 10, scorer=loss_function)\n",
    "    scores.append([len(cols), cols, cv_result.mean(), cv_result.std()])\n",
    "    \n",
    "colonne_df = [\"num_features\", \"features\", \"mean test_error\", \"test_error_std\" ]\n",
    "df_scores_LR = pd.DataFrame(scores, columns = colonne_df)\n",
    "risultati.to_csv(\"df_scores_LR.csv\")\n",
    "df_scores_LR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Models and Hyperparameters Optimization\n",
    "\n",
    "**note:** \\\n",
    "confusion matrix scores are: \\\n",
    "true_positives, false negatives \\\n",
    "false_positives, true_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.3500000000000005, class_weight={1: 1, 2: 4.25},\n",
      "                   max_iter=2000, random_state=0, solver='liblinear') -172.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019289</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'C': 0.7}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.3</td>\n",
       "      <td>22.746648</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'C': 0.75}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.3</td>\n",
       "      <td>22.746648</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'C': 0.8}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>22.738514</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'C': 0.8500000000000001}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>22.738514</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018489</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'C': 0.9000000000000001}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>22.738514</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'C': 0.9500000000000002}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.3</td>\n",
       "      <td>22.737854</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0000000000000002}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>22.791226</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>{'C': 1.0500000000000003}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>22.791226</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019490</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'C': 1.1000000000000003}</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.9</td>\n",
       "      <td>23.834639</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.15</td>\n",
       "      <td>{'C': 1.1500000000000004}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.8</td>\n",
       "      <td>23.625410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.019988</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'C': 1.2000000000000004}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.8</td>\n",
       "      <td>23.625410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020089</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1.25</td>\n",
       "      <td>{'C': 1.2500000000000004}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.8</td>\n",
       "      <td>23.625410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1.3</td>\n",
       "      <td>{'C': 1.3000000000000005}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.8</td>\n",
       "      <td>23.625410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>1.35</td>\n",
       "      <td>{'C': 1.3500000000000005}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.7</td>\n",
       "      <td>23.618002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.4</td>\n",
       "      <td>{'C': 1.4000000000000006}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.7</td>\n",
       "      <td>23.618002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1.45</td>\n",
       "      <td>{'C': 1.4500000000000006}</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-172.7</td>\n",
       "      <td>23.618002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.019289      0.001951         0.000300        0.000458     0.7   \n",
       "1        0.019389      0.001685         0.000300        0.000458    0.75   \n",
       "2        0.018789      0.001599         0.000399        0.000489     0.8   \n",
       "3        0.019590      0.002198         0.000100        0.000300    0.85   \n",
       "4        0.018489      0.001746         0.000100        0.000300     0.9   \n",
       "5        0.019288      0.001997         0.000200        0.000400    0.95   \n",
       "6        0.019990      0.002000         0.000600        0.000490     1.0   \n",
       "7        0.018888      0.001811         0.000000        0.000000    1.05   \n",
       "8        0.019490      0.001687         0.000000        0.000000     1.1   \n",
       "9        0.019191      0.001248         0.000297        0.000454    1.15   \n",
       "10       0.019988      0.001948         0.000400        0.000490     1.2   \n",
       "11       0.020089      0.001867         0.000300        0.000458    1.25   \n",
       "12       0.020391      0.001198         0.000198        0.000397     1.3   \n",
       "13       0.020590      0.001360         0.000099        0.000296    1.35   \n",
       "14       0.020488      0.001207         0.000200        0.000400     1.4   \n",
       "15       0.020190      0.001325         0.000300        0.000458    1.45   \n",
       "\n",
       "                       params  split0_test_score  split1_test_score  \\\n",
       "0                  {'C': 0.7}             -223.0             -127.0   \n",
       "1                 {'C': 0.75}             -223.0             -127.0   \n",
       "2                  {'C': 0.8}             -223.0             -127.0   \n",
       "3   {'C': 0.8500000000000001}             -223.0             -127.0   \n",
       "4   {'C': 0.9000000000000001}             -223.0             -127.0   \n",
       "5   {'C': 0.9500000000000002}             -223.0             -127.0   \n",
       "6   {'C': 1.0000000000000002}             -223.0             -127.0   \n",
       "7   {'C': 1.0500000000000003}             -223.0             -127.0   \n",
       "8   {'C': 1.1000000000000003}             -223.0             -122.0   \n",
       "9   {'C': 1.1500000000000004}             -222.0             -122.0   \n",
       "10  {'C': 1.2000000000000004}             -222.0             -122.0   \n",
       "11  {'C': 1.2500000000000004}             -222.0             -122.0   \n",
       "12  {'C': 1.3000000000000005}             -222.0             -122.0   \n",
       "13  {'C': 1.3500000000000005}             -222.0             -122.0   \n",
       "14  {'C': 1.4000000000000006}             -222.0             -122.0   \n",
       "15  {'C': 1.4500000000000006}             -222.0             -122.0   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              -183.0             -175.0             -171.0   \n",
       "1              -183.0             -175.0             -171.0   \n",
       "2              -183.0             -175.0             -172.0   \n",
       "3              -183.0             -175.0             -172.0   \n",
       "4              -183.0             -175.0             -172.0   \n",
       "5              -183.0             -175.0             -172.0   \n",
       "6              -183.0             -175.0             -172.0   \n",
       "7              -183.0             -175.0             -172.0   \n",
       "8              -183.0             -175.0             -172.0   \n",
       "9              -183.0             -175.0             -172.0   \n",
       "10             -183.0             -175.0             -172.0   \n",
       "11             -183.0             -175.0             -172.0   \n",
       "12             -183.0             -175.0             -172.0   \n",
       "13             -183.0             -174.0             -172.0   \n",
       "14             -183.0             -174.0             -172.0   \n",
       "15             -183.0             -174.0             -172.0   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0              -164.0             -185.0             -174.0   \n",
       "1              -164.0             -185.0             -174.0   \n",
       "2              -164.0             -185.0             -174.0   \n",
       "3              -164.0             -185.0             -174.0   \n",
       "4              -164.0             -185.0             -174.0   \n",
       "5              -164.0             -185.0             -173.0   \n",
       "6              -164.0             -186.0             -173.0   \n",
       "7              -164.0             -186.0             -173.0   \n",
       "8              -164.0             -186.0             -173.0   \n",
       "9              -164.0             -186.0             -173.0   \n",
       "10             -164.0             -186.0             -173.0   \n",
       "11             -164.0             -186.0             -173.0   \n",
       "12             -164.0             -186.0             -173.0   \n",
       "13             -164.0             -186.0             -173.0   \n",
       "14             -164.0             -186.0             -173.0   \n",
       "15             -164.0             -186.0             -173.0   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0              -173.0             -158.0           -173.3       22.746648   \n",
       "1              -173.0             -158.0           -173.3       22.746648   \n",
       "2              -173.0             -158.0           -173.4       22.738514   \n",
       "3              -173.0             -158.0           -173.4       22.738514   \n",
       "4              -173.0             -158.0           -173.4       22.738514   \n",
       "5              -173.0             -158.0           -173.3       22.737854   \n",
       "6              -173.0             -158.0           -173.4       22.791226   \n",
       "7              -173.0             -158.0           -173.4       22.791226   \n",
       "8              -173.0             -158.0           -172.9       23.834639   \n",
       "9              -173.0             -158.0           -172.8       23.625410   \n",
       "10             -173.0             -158.0           -172.8       23.625410   \n",
       "11             -173.0             -158.0           -172.8       23.625410   \n",
       "12             -173.0             -158.0           -172.8       23.625410   \n",
       "13             -173.0             -158.0           -172.7       23.618002   \n",
       "14             -173.0             -158.0           -172.7       23.618002   \n",
       "15             -173.0             -158.0           -172.7       23.618002   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 9  \n",
       "1                 9  \n",
       "2                12  \n",
       "3                12  \n",
       "4                12  \n",
       "5                 9  \n",
       "6                12  \n",
       "7                12  \n",
       "8                 8  \n",
       "9                 4  \n",
       "10                4  \n",
       "11                4  \n",
       "12                4  \n",
       "13                1  \n",
       "14                1  \n",
       "15                1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  \n",
    "#grid search\n",
    "df = train_enh_stded\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "params={\"C\":np.arange(0.7,1.5,0.05),\n",
    "        #\"class_weight\":[{1:1, 2:i} for i in np.arange(4,6,0.25)]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=2000,\n",
    "                        #C=1.2,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight={1:1,2:4.25}\n",
    "                                      ),                     \n",
    "                   param_grid = params, \n",
    "                   scoring = loss_function,\n",
    "                   cv=10)\n",
    "                   #verbose = 1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "res = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_estimator_, grid.best_score_)\n",
    "res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -173.2 std =  22.346364357541475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = train_enh_dum #[[i for i in train_enh_dum.columns if i!=\"avg_surprise2\"]]\n",
    "df_test = test_enh_dum\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        C=1.2000000000000004,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "cv_result = compute_cv(LR, X, y, 10, loss_function)\n",
    "\n",
    "LR.fit(X, y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(df, LR)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = LR.predict(df_test)\n",
    "get_txt(y_pred, filename = \"LR_Predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[LDA](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)**\n",
    "\n",
    "auto shrinakge gives similar results to a shrinkage of the order of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearDiscriminantAnalysis(priors=[0.35, 0.65], shrinkage=0.011, solver='lsqr'),\n",
       " -175.2)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "# grid search\n",
    "df = train_enh_stded\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "params={\"shrinkage\":np.arange(0.001, 0.1, 0.001)\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(LinearDiscriminantAnalysis(solver = \"lsqr\",\n",
    "                                 #shrinkage=\"auto\",\n",
    "                                 priors=priors),                     \n",
    "                   param_grid = params, \n",
    "                   scoring = loss_function,\n",
    "                   cv=10)\n",
    "                   #verbose = 1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "res = pd.DataFrame(grid.cv_results_)\n",
    "grid.best_estimator_, grid.best_score_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -174.7 std =  21.4151815308673\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" fit \"\"\"\n",
    "\n",
    "df = train_enh_stded\n",
    "df_test = test_enh_stded\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.35 \n",
    "priors = [prior_l, 1-prior_l]\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                                 shrinkage=\"auto\",\n",
    "                                 priors=priors) #priors=priors\n",
    "\n",
    "cv_result = compute_cv(LDA, X, y, 10, scorer=loss_function)\n",
    "\n",
    "LDA.fit(X,y)\n",
    "\n",
    "fpr, tpr, roc_auc = find_ROC_Score(df, LDA)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = LDA.predict(df_test)\n",
    "get_txt(y_pred, filename = \"LDA_Predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  175.8 std = 21.334479135896427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[182.2, 111.8],\n",
       "       [ 12.8,  93.2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" confusion matrix \"\"\"\n",
    "df = train_enh_dum\n",
    "\n",
    "prior_l = 0.35\n",
    "priors = [prior_l, 1-prior_l]\n",
    "\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                                shrinkage=\"auto\",\n",
    "                                priors=priors\n",
    "                                )\n",
    "\n",
    "\n",
    "cv_scores, y_tr_y_pr, y_prob = custom_k_folds(LDA, df)\n",
    "\n",
    "y_tr_y_pr\n",
    "\n",
    "conf_matrices = np.zeros((2,2))\n",
    "for i in range(len(y_tr_y_pr)):\n",
    "    conf_matrix = confusion_matrix(y_tr_y_pr[i][0], y_tr_y_pr[i][1])\n",
    "    conf_matrices += conf_matrix     \n",
    "               \n",
    "conf_matrices/len(y_tr_y_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)**\n",
    "\n",
    "predice benissimo la seconda classe, paradossalmente buiaogna metteren una prior in verso opposto.\n",
    "magari posso sfruttarlo per 'fidarmi' delle sue predizioni su una classe.\n",
    "con p=0.1 predici bene "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_enh_dum \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.9\n",
    "priors = [prior_l, 1-prior_l]\n",
    "G_NB = GaussianNB(priors=priors) #priors=priors\n",
    "cv_result = compute_cv(G_NB, X, y, 10, scorer=loss_function)\n",
    "\n",
    "G_NB.fit(X,y)\n",
    "preds = G_NB.predict(test_enh_dum)\n",
    "\n",
    "fpr, tpr, roc_auc = find_ROC_Score(train_enh_dum, G_NB)\n",
    "plot_ROC(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" confusion matrix prior alta \"\"\"\n",
    "df = train_enh_dum \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.9\n",
    "priors = [prior_l, 1-prior_l]\n",
    "G_NB = GaussianNB(priors=priors) #priors=priors\n",
    "cv_result = compute_cv(G_NB, X, y, 10, scorer=loss_function, silence=True)\n",
    "\n",
    "\n",
    "cv_scores, y_tr_y_pr, _ = custom_k_folds(G_NB, df)\n",
    "\n",
    "mean_conf_matrix(y_tr_y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" confusion matrix prior bassa \"\"\"\n",
    "df = train_enh_dum \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "prior_l = 0.1\n",
    "priors = [prior_l, 1-prior_l]\n",
    "G_NB = GaussianNB(priors=priors) #priors=priors\n",
    "cv_result = compute_cv(G_NB, X, y, 10, scorer=loss_function, silence=True)\n",
    "\n",
    "\n",
    "cv_scores, y_tr_y_pr, _ = custom_k_folds(G_NB, df)\n",
    "\n",
    "mean_conf_matrix(y_tr_y_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -176.8 std =  18.475930287809597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" #fitto il best model (e faccio feature importances )\n",
    "df = train_enh_dum\n",
    "df_test = test_enh_dum\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "class_weights = {1:1, 2:5}\n",
    "RF = RandomForestClassifier(n_estimators= 1000,\n",
    "                            #n_jobs=-1,\n",
    "                            random_state=10,\n",
    "                            class_weight= class_weights,\n",
    "                            #min_samples_leaf = 50,\n",
    "                            #min_samples_split =3,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features= 0.16) #'log2'\n",
    "\n",
    "cv_result = compute_cv(RF, X, y, 10, loss_function)\n",
    "#cv_result, _, _  = k_folds_upsampling(RF, df, 7, ratio=0, k_neighbors=800)\n",
    "\n",
    "RF.fit(X,y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(train_enh_dum, RF)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "#y_pred = RF.predict(df_test)\n",
    "#get_txt(y_pred, filename = \"RF_Predictions.txt\")\n",
    "\n",
    "feature_importances[\"rf\"] = RF.fit(X, y).feature_importances_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[AdaBoost Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)** (DecisionTreeBoosting)\n",
    "\n",
    "se d=2 -> 28 estimators con learning rate = 0.35 o al max 0.4\n",
    "\n",
    "se d=1 -> 174 estimators con 0.4 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                    learning_rate=0.09999999999999999, n_estimators=1500,\n",
       "                    random_state=0),\n",
       " -278.3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  # grid search\n",
    "df = train_enh_stded \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "#class_weight = {1:1, 2:4}\n",
    "params={#\"n_estimators\":  np.arange(140,190,3),\n",
    "        \"n_estimators\":  [1500,2000],\n",
    "        \"learning_rate\": np.arange(0.09,0.12,0.01),\n",
    "        #\"base_estimator\":[DecisionTreeClassifier(max_depth=2, class_weight=i) for i in [{1:1, 2:4},{1:1, 2:5},{1:1, 2:6}]]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, \n",
    "                                                              #class_weight=class_weight\n",
    "                                                              ),                     \n",
    "                                       random_state=0,\n",
    "                                       #n_estimators=174,\n",
    "                                       #learning_rate = 0.4,\n",
    "                                          ),\n",
    "                   param_grid = params, \n",
    "                   scoring = loss_function,\n",
    "                   cv=10)\n",
    "                   #verbose = 1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "res = pd.DataFrame(grid.cv_results_)\n",
    "grid.best_estimator_, grid.best_score_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -175.4 std =  25.519404381764087\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGwElEQVR4nO3dd3gU5fbA8e9JIQkQWoJIL1IFKRJAVBAp0kWvV7FcFK9eDU3FhhdRsSIWEKRERH/Y8aooCCqKIiAqTUKRJiBCkF5CaKnv74+ZJEtINkvI7uxuzud58uyUd2bOTHbnTH1fMcaglFJKFSTE6QCUUkr5N00USiml3NJEoZRSyi1NFEoppdzSRKGUUsotTRRKKaXc0kQRJETkdxHp5HQcThORBBF5wsfLnCEiz/lymd4iIreJyLdFnDZov4MiYkSkvtNxOEX0PYriJyI7gCpAJnAc+AYYaow57mRcwUZEBgJ3G2OudDiOGUCSMWaUw3GMBuobY/7lg2XNwA/W2VdExAANjDFbnY7FCXpG4T19jTFlgZZAK+C/zoZz7kQkrCQu20m6zZVfMsboXzH/ATuAri79LwHzXPovA34GjgJrgE4u4yoB/wf8DRwBvnAZ1wdItKf7GWied5lANeAUUMllXCvgIBBu9/8b2GjPfz5Q26WsAYYAfwB/FrB+1wK/23H8CDTJE8d/gQ32/P8PiDyHdRgBrAVSgTDgMWAbkGLP83q7bBPgNLlnbUft4TOA5+zuTkAS8BCwH9gD3OmyvBjgS+AYsAJ4DvjJzf/1Spf/2y5goMsyJwPz7DiXARe5TDfBLn8MWAV0cBk3GvgUeN8efzfQFvjFXs4eYBJQymWapsB3wGFgHzAS6AGkAen29lhjly0PvGXPZ7e9jqH2uIHAUmC8Pa/n7GE/2ePFHrcfSLb/L82Ae+zlpNnL+jLv9x4ItePK/t+tAmoWsF3z/T0Al2N9b2va/S3sMo3t/ny/G/ms21Fguz2/gfb/Yj9wh0v5GUCCvV1TgEWc/buob3dHAK8AO+3tnwBEOb3f8eo+zekAgvEvzw+mBrAOmGD3VwcOAb2wzui62f2V7fHzgI+BikA4cJU9/FL7y93O/hHeYS8nIp9l/gD8xyWel4EEu/s6YCvWjjYMGAX87FLW2D+WSvl9+YGGwAk77nDgUXt+pVziWA/UtOexlNwdtyfrkGhPG2UPuxEr+YUA/e1lV7XHDSTPjp2zE0UG8Iwday/gJFDRHj/T/isNXIy1A8k3UQC1sHYgt9jzigFauizzMNYOPgz4AJjpMu2/7PJhWElrL3byxEoU6fb/JQSIAlpj7TzDgDpYSf0Bu3w01k7/ISDS7m/nMq/388T9BfAGUAa4AFgO3Ouy/TKAYfayojgzUXTH2sFXwEoaTVy2fc52LuB7/wjW976RPW0LICaf7VrY7+F5rO9zFFaiGuoybWHfjQzgTqzv2nNYO/bJWDv6a+z/Z1mX9UkBOtrjJ+DyXeDMRPEaMAfr+x2NdbAxxun9jlf3aU4HEIx/9g/muP3FM8D3QAV73AjgvTzl52PtNKsCWdg7sjxlpgLP5hm2mdxE4vojvRv4we4WrB1gR7v/a+Aul3mEYO08a9v9BujsZt2eAP6XZ/rd5B4F7gDiXcb3Aradwzr8u5Btmwj0s7sHUniiOAWEuYzfj7UTDsXaQTdyGVfgGQXWWdLnBYybAUzPs86b3KzDEaCF3T0aWFzIOj+QvWysRLW6gHKjcUkUWPfJUnFJ+Pb0C122384888jZpkBnYIu9vUIK2s55vvfZ38HN2f+nQtatwN+D3R2OlazWYd3rk3P4bvzhMu4SrO92FZdhhzgz2bsm97JYZ6vZZzMGqI/1ezrBmWeM7Sng7DtY/vQehfdcZ4yJxtpZNQZi7eG1gRtF5Gj2H9YljapYR9KHjTFH8plfbeChPNPVxDqiyutToL2IVMM6QjLAEpf5THCZx2GsL391l+l3uVmvasBf2T3GmCy7fEHT/+USoyfrcMayReR2EUl0Kd+M3G3piUPGmAyX/pNYO4HKWEfRrstzt941sS5zFGRvPssAQEQeEpGNIpJsr0N5zlyHvOvcUETmisheETkGvOBSvrA4XNXG2tHucdl+b2CdWeS7bFfGmB+wLntNBvaJyDQRKefhsj2N093vAWNMOtZOvBnwqrH3zODRd2OfS/cpe355h5V16c/ZFsZ68OQwZ/++KmOdga5yWe439vCgpYnCy4wxi7C+6K/Yg3ZhHUFVcPkrY4x50R5XSUQq5DOrXcDzeaYrbYz5KJ9lHgW+BW4CbgU+cvmB7cK69OA6nyhjzM+us3CzSn9j/bgBEBHB2insdilT06W7lj2Np+vguiOoDbwJDMW6bFEB67KWeBBnYQ5gXZqoUUDcee0CLjrXhYhIB6yj5puwzhQrYF3vF5dieddjKrAJ6ymbcljX+rPLu4sj73x2YZ1RxLps73LGmKZupjlzhsZMNMa0xrov0hDrklKh0xUSZ95yBf0eEJHqwFNY97peFZEIe3hh342iyPn/i0hZrEtLf+cpcxArwTR1ibe8sR5cCVqaKHzjNaCbiLTEumnZV0S6i0ioiESKSCcRqWGM2YN1aWiKiFQUkXAR6WjP400gXkTaiaWMiPQWkegClvkhcDtwg92dLQH4r4g0BRCR8iJy4zmsy/+A3iLSRUTCsa6Vp2LdjMw2RERqiEglrJ3cx0VchzJYO6QDdqx3Yh01ZtsH1BCRUucQPwDGmExgFjBaREqLSGOs7VWQD4CuInKTiISJSIz9/yxMNFZCOgCEiciTQGFH5dFYN7aP23ENchk3F7hQRB4QkQgRiRaRdva4fUAdEQmx13EP1gHDqyJSTkRCROQiEbnKg7gRkTb2/yoc63JL9sMD2cuq52by6cCzItLA/l83F5GYfMoV+HuwD0JmYN2Mvwvr3syz9nSFfTeKopeIXGl/n54Flhljzjjjss+g3wTGi8gF9rKri0j381y2X9NE4QPGmAPAu8AT9hevH9YO9ADWEdUj5P4vBmBdO9+EdT39AXseK4H/YF0KOIJ1A3mgm8XOARoA+4wxa1xi+RwYC8y0L2usB3qew7psxro5+zrW0VVfrEeB01yKfYi1g9pu/z1XlHUwxmwAXsV6Amgf1nXmpS5FfsB6+mqviBz0dB1cDMW6DLQXeA/4CCvp5RfLTqx7Dw9hXZJIxLpBW5j5WMl/C9ZluNO4v8QF8DDWmWAK1k4pO9FijEnBuuHb1477D+Bqe/Qn9uchEfnN7r4dKEXuU2ifYl/W8UA5e/lH7NgPkXtm/BZwsX355Yt8ph2HdVDxLVbSewvrhvQZCvk93Id1n+UJ+4z4TuBOEengwXejKD7EOns5jPVAwW0FlBuB9d391f4NLcC6aR+09IU7VazEetnwbmPMAqdjOVciMha40Bhzh9OxKN+SEvYC4bnSMwpVYolIY/uSiIhIW6zLG587HZdS/kbfxFQlWTTW5aZqWJf5XgVmOxqRUn5ILz0ppZRySy89KaWUcivgLj3FxsaaOnXqOB2GUkoFlFWrVh00xhTpxcCASxR16tRh5cqVToehlFIBRUT+KrxU/vTSk1JKKbc0USillHJLE4VSSim3NFEopZRySxOFUkoptzRRKKWUcstriUJE3haR/SKyvoDxIiITRWSriKwVkUu9FYtSSqmi8+Z7FDOwqpN+t4DxPbGqwW6A1YbyVPtTKaWcl3oM9vwCJsvpSM5bWtr5rYPXEoUxZrGI1HFTpB/wrl3P/K8iUkFEqtqNrSilVPHKyoC/f4b0kx4UNrBgEBwr8jtqfmPCknZMX3Z+F2ycfDO7Omc24JJkDzsrUYjIPcA9ALVq1fJJcEopP2cM7FsFpw97Vn7Fy7CzCM2k1OoKIQFXiUWOFsfLseHLCwov6IaTa59f27b5VmVrjJkGTAOIi4vT6m6VChaHNkJKUtGm/fMr+O21ok1bx4OWSyUUWg6Ber2KtgyH7NqVzNy5Wxg0qA0AnW6ArbcfoV69p4s8TycTRRJnNmZfg7MbMldK+ZvUZNi7kgKO6zy37zdYMqJYQqJ2N8/KRVSATuMhunrxLNePZGRkMXHiMp58ciEnTqTTrNkFdOhQG4C6dSue17ydTBRzgKEiMhPrJnay3p9Qys+kpZyZFEwWfDMQju8uvmWERUG1K4o4bSRc/jRUKdkPTS5blsS9985lzZp9ANxwQxPq1Tu/5ODKa4lCRD4COgGxIpKE1Wh5OIAxJgH4Cqux+q3ASayG05VSxc0Y2LcS0o6f+7Sfdi34qZ+aV4Oc5xP2ZS6ErlOhVPT5zaeEOnLkFCNHfs8bb6zCGKhTpwKTJvWkd++Gxbocbz71dEsh4w0wxFvLV6rEO7QRTu6DtW/Cpg/Pb17lakP5elZ3SBjEPQJ1PLzco7zm6acXkZCwirCwEB5+uD1PPHEVpUuHF/tyAvdWvlLqbCbLehJo1yJY/MjZ42t2Ovd5xjSDzhNB8nv+RPlaRkYWYWHWmdyoUR3588+jPP98Z5o1O78nm9zRRKGUvzIG9v/m4XP/thUvwfa5Zw6rcZV1aafTOKjYoHhjVD5z+nQGY8f+xBdfbGbZsrspVSqU2NjSzJ59s9eXrYlCKX+1ehIsvK/o09fqDO1GQa2riy8m5Yjvv9/OoEHz+OMP652R+fO30rdvI58tXxOFUv4oKxP++NTqLlcHomt4Pm1kJegy+dymUX5p377jPPTQt3zwwToAmjSJZerU3lx1VR2fxqGJQil/tHgEJC22ulsNg7gHnY1H+dz7769l2LCvOXr0NJGRYTz5ZEceeuhySpUK9XksmiiU8gcmC/avgcxUq3//qtxxDa53JiblqKwsw9Gjp+nRoz6TJ/cq1vcizpUmCqWcduwv+H7o2TehAa79DMrX9X1MyueOH0/jl1920a3bRQAMGNCcatWi6dKlLuLwE2eaKJTypcw0OLCWnDed96+B7/5zZpmqdm37pS+0XmpTQe+LLzYxbNjXHDhwgvXrB1O/fiVEhK5d6zkdGqCJQqnilZUJB9dZVVrnZ84/IGVX/uPq9oRr3oKyVb0Xn/Irf/11lPvu+4Y5czYDEBdXjdTUAr47DtJEoVRRHNkKacfOHv7DMKvNg8KERkDsJVZ3SDi0f8JKFKpESE/P5LXXfmX06EWcPJlOdHQpXnihC4MGxREa6n8tVGuiUMpTWZlw6HfYNBOWjym8fJXW+Q+v2BB6vgchvn96RfmH++77moQE64GFm25qyvjx3alWzX/ru9JEoVR+sjLg0IYzK8T7fsjZZwsXtDp72rLVoNeHEFHOuzGqgPXAA5exaNFfjBvXnR496jsdTqE0USjlKi0Fkv+EuTfD4Y0Fl6t+JXR+HS5o6bPQVGAyxvD++2v56qutfPjhPxARGjWKZf36wYSEBEb9WZooVHDLTIPDmz0rm5UB7+fTrkHlFrndZatDn4+hVNniiU8Ftc2bDzJo0DwWLtwBWI+89upl1bcVKEkCNFGoYPfOJXBky7lPF3sJVKhvJYXQ4q+2WQW3U6fSGTPmJ8aOXUpaWiYxMVG8+uo19Ozp/5eZ8qOJQgWHtJSzHzvd9mVukoisaJ0NeKLBP+Hyp4o3PlViLFiwnfj4uWzbdgSAu+5qxdixXYmJKe1wZEWniUIFvhN7IaGQdw8GH9L2FJRP/PzzLrZtO0LTppVJSOjDlVfWcjqk86aJQgWmY39BxmkrSfyvU+7wSk3OLBdeBrpM0iShvCYzM4utWw/TqFEsACNGXEFsbGnuvvtSRyrw8wZNFCowZKRayQHgt9dgzdSzy1zxHFz2uE/DUiXb6tV7iI+fx/btR9i8eSiVKkURERHG4MFtnA6tWGmiUIHhw3ZwYM3Zwys2BAmx2nC+5N++j0uVSCkpqTz55EImTlxOVpahevVotm07TKVKHt4HCzCaKJR/ysrIPYMAOLje+qxQ37qMFBkDvT/UmlWVTxljmDVrI/ff/w27d6cQEiIMH34ZTz/diejoCKfD8xpNFMq3UpKsdxsK87+rIWXn2cMHbtDHVZVjHnjgGyZOXA5AmzbVeOONPrRqFfyVOGqiUN6XlWnt9Fe8nP+9BXciyltnDwC1u2mSUI66/vomvPPOGl54oQv33tvaLyvw8wZNFKr4HN8DWfmcLczqbVWm58qTS0bVLrcqz9MnlpRDfvppJwsX/skTT1wFQKdOddi5czjlygXvZab8aKJQxWPpE/Drc+7LhIRZlej1/QzK1fRNXEoVwaFDJxkxYgFvvbUagC5d6nH55dZ3tqQlCdBEoYrDiX1nJonofF4wqnKp1aynlIxTdRWYjDG8++4aHn74Ow4ePEl4eAiPPXYlrVpd6HRojtJEoc6PyYJ3XSrNuycJooPzEUEV3DZuPMCgQfNYtMh62u7qq+swZUpvGjeOdTgy52miUJ47dRgyT5857H+d4eQ+q7vzJE0SKmCNG/cLixb9ReXKpRk3rju33XYJovfHAE0UqjBpKZB2HDZ+AIsfKbhchxeh1RDfxaVUMUhOPk358pEAjBnTlTJlSvHkk1dRqVKUw5H5F00UqmC7frTeZ8irTJ7nxi9sC20e9UVEShWLv/9OYfjw+axdu481a+IpVSqU2NjSvPZaD6dD80uaKFT+tnwKX96Y21/mQoioYLXPULm5Y2EpdT4yM7OYMmUFjz/+AykpaZQuHc5vv+3hsstqOB2aX9NEoXKlHYeMU1b3+rdzh187Cxpc70xMShWTVav+5t5757Jq1R4Arr22Ea+/3pNatco7HJn/82qiEJEewAQgFJhujHkxz/jywPtALTuWV4wx/+fNmFQBdi6ETzqfPVyfYlJBYPToH3n22cVkZRlq1izH66/3pF+/xk6HFTC8lihEJBSYDHQDkoAVIjLHGLPBpdgQYIMxpq+IVAY2i8gHxhgPKgNSRZZ6zKp0z5VrkoiyHwe86FpNEioo1KtXERF46KH2jB7dibJlSzkdUkDx5hlFW2CrMWY7gIjMBPoBronCANFiPYNWFjgMZOSdkTpP6ScgM93qTpwMS0cVXPaGb6FON9/EpZSXbN9+hBUrdtO/fzMABgxoTrt21XMaF1LnxpuJojrg2ohxEtAuT5lJwBzgbyAa6G+Myco7IxG5B7gHoFatwG9W0GdSj8GGd+GHYfmPj6x4Zn/dXpokVEBLS8vklVd+5tlnF2OMoXXratSvXwkR0SRxHryZKPJ7U8Xk6e8OJAKdgYuA70RkiTHm2BkTGTMNmAYQFxeXdx4qL2Ng3i2w+eMzh0fYN+2iKsMN86FCPd/HppSXLF78F/Hxc9m48SAAt912SYmsl8kbvJkokgDXmt9qYJ05uLoTeNEYY4CtIvIn0BhY7sW4gk9GKmSl5/Z/eg3s+SW3v1wduP5LiG3m89CU8raDB0/yyCPfMWNGIgANGlRi6tTedOmiB0LFxZuJYgXQQETqAruBm4Fb85TZCXQBlohIFaARsN2LMQWf7V/BF32tOpfyir0EblsBYXpUpYJXfPxcPvtsIxERoYwc2YFHH72CyEh98r84eW1rGmMyRGQoMB/r8di3jTG/i0i8PT4BeBaYISLrsC5VjTDGHPRWTEElKwPWvgnfD84dFl4mt7tmZ7hutrbloIJSVpYhJMT6bj//fGdOncrgtde606BBjMORBSexrvoEjri4OLNy5Uqnw3BGZpp15pCyC95vbdXDlO3G76FWPu9BKBVETp5M59lnF5GYuI+vvrpVK+07ByKyyhgTV5Rp9fwsUPz2Ovz4wNmXmMrWgH/Oh5iLHQlLKV+ZN28LQ4d+zY4dRxGB5ct3066dVr3hC5ooAkFmGuxaaCWJkDCQUOuz40vQcnDh0ysVwJKSjnH//d8wa9ZGAFq0qEJCQh9NEj6kicLffdkftvwvt7/3R9Dwn87Fo5QPTZmyghEjFnD8eBplyoTz7LNXM2xYO8LCtKVEX9JE4e92LrA+Q8Ks6r0vbONsPEr50MGDJzl+PI3rr2/MhAk9qFlTK/BzgiYKf2MMZ76XaHfH74UofaJDBbejR0+zadPBnGq/R4y4grZtq9OjR32HIyvZNFH4kz3LrJfl0o4VXlapIGKM4eOPf2f48PlkZmaxadNQKlWKIiIiTJOEH9BE4Q9WT4KFD4DJdBno8thftfZn18ukVJDYuvUwQ4Z8xbffbgPg8strkpx8Wpsj9SOaKJx28uCZlfaFRUGvD6HBdY6FpJQvpKZm8NJLS3n++SWkpmZSsWIkL73UjX//u1XOy3TKP3icKESkjDHmhDeDKZEOrsvt/s9fUE5rx1UlQ//+nzJ79mYAbr+9BS+/3I0LLihTyFTKCYUmChG5HJiO1V5ELRFpAdxrjNEH+M/F37/C570hNfnM4dkv0NW4SpOEKlEeeOAyNm8+xJQpvbj66rpOh6Pc8OSMYjxWdeBzAIwxa0Sko1ejCjbGwEft3RQQqK3tQKjglZVlePvt1WzceIBXX+0OQKdOdVi/fhChofpOhL/z6NKTMWZXnjpVMgsqq/Lh2uxo30+hfr+zy4To7SIVnNat20d8/Dx+/tlqx+z221vQosWFAJokAoQne6dd9uUnIyKlgPuAjd4NK4hkpsEH2S/JCTS8wdFwlPKVEyfSePrpRYwb9wuZmYYLLyzLa691p3nzKk6Hps6RJ4kiHpiA1bRpEvAtoPcnPHXsLziw1uquc42zsSjlI19+uZmhQ79m585kRGDIkDY8/3xnypePdDo0VQSeJIpGxpjbXAeIyBXAUu+EFKTK1oB/fO10FEr5xBdfbGLnzmRatbqQN97oQ5s21Z0OSZ0HTxLF68ClHgxT7oRFaiNCKmhlZGSxe/cxateuAMDYsd1o1aoq8fFxWoFfECgwUYhIe+ByoLKIPOgyqhxWi3VKKcWvvyYRHz+X1NRM1qyJp1SpUGJjSzN0aFunQ1PFxF2qL4X17kQYEO3ydwzQeq6VKuGOHDnFoEFzufzyt1izZh+nT2ewY8dRp8NSXlDgGYUxZhGwSERmGGP+8mFMSik/Zozho4/WM3z4fPbvP0FYWAiPPHI5o0Z1pHTpcKfDU17gyT2KkyLyMtAUyHlkwRijDTQrVQLddtssPvpoPQAdOtRi6tTeNG16gcNRKW/y5C7TB8AmoC7wNLADWOHFmILHqUPwbguno1CqWPXoUZ+YmCjefvtafvxxoCaJEsCTM4oYY8xbInK/y+WoRd4OLCCtGg/LxuTW33T6UO64au6q8FDKfy1YsJ1t2w5z771xAAwY0Jw+fRpqNeAliCeJIt3+3CMivYG/AW3VPD+bP4ZTB84e3nIIdH7d9/EodR727TvOgw9+y4cfriMiIpSuXetx0UWVEBFNEiWMJ4niOREpDzyE9f5EOeABbwYV8P7xNVSxjr4ICdVGh1RAycoyTJu2isceW0ByciqRkWE8+WRHba+6BCs0URhj5tqdycDVkPNmtipIRAUoHet0FEqdszVr9nLvvXNZtmw3AD171mfSpF7Uq6cHOyWZuxfuQoGbsOp4+sYYs15E+gAjgSiglW9CDBCLR1htXisVwB59dAHLlu2mWrVoJkzowQ03NEG0RoESz90ZxVtATWA5MFFE/gLaA48ZY77wQWyBY99qWPFSbn+Fi5yLRalzYIzh5Ml0ypQpBcDEiT1ISFjJ009fTblyEQ5Hp/yFu0QRBzQ3xmSJSCRwEKhvjNnrm9ACxJ/fwKyeuf1DkyGinHPxKOWhv/46yrBhX3PiRDoLFgxARGjUKJbx43s4HZryM+4SRZox1nOexpjTIrJFk0Q+/piV293zXU0Syu+lp2cyfvyvPP30Ik6eTCc6uhR//HGYhg1jnA5N+Sl3iaKxiNgNKSDARXa/AMYY09zr0QWSK1+Aiwc4HYVSbi1dupP4+HmsX78fgP79mzJuXHeqVYt2ODLlz9wliiY+iyJQZWXAujet7ig9GlP+bdiwr5g0yapUoV69ikye3IsePeo7HJUKBO4qBdSKAAtyeAvMuxn2r84dFtPUuXiU8kDlymUIDw9hxIgrGDmyA1FRWoGf8ownL9wVmYj0wGpGNRSYbox5MZ8ynYDXgHDgoDHmKm/GdF6Mgbk3wZZPzxxe+xqorq+WKP+yadNBdu5M5pprrKfwRoy4gptuakrjxvqOjzo3XksU9nsYk4FuWG1trxCROcaYDS5lKgBTgB7GmJ0i4r+1i6WfgPdaw5HNucPaPAotBkG5Ws7FpVQep06l88ILSxg7dikVKkSyadNQKlWKIiIiTJOEKhKPEoWIRAG1jDGbCy2cqy2w1Riz3Z7HTKAfsMGlzK3ALGPMTgBjzP5zmL9vfRefmyQqNoAbF0K0tgOs/Mu3325j8OB5bNt2BIBrr22kLfCq81ZoNeMi0hdIBL6x+1uKyBwP5l0d2OXSn2QPc9UQqCgiP4rIKhG53aOofe3n0bDxfas7uiYM3KhJQvmVPXtSuPnmT+ne/X22bTtC06aVWbLkTqZPv5aKFbUCP3V+PDmjGI11dvAjgDEmUUTqeDBdfscxJp/ltwa6YFUL8ouI/GqM2XLGjETuAe4BqFXLx5d59q+BX57O7f/XKquiP6X8yD/+8T9+/TWJqKgwRo/uxPDhlxEert9TVTw8abgowxiTXIR5J2FVAZKtBlYV5XnLfGOMOWGMOQgsBs5q6ccYM80YE2eMiatcuXIRQjkP21xOngYdgNI+Xr5SBTAm97jrxRe70KdPQzZsGMKjj16hSUIVK0/OKNaLyK1AqIg0AO4DfvZguhVAAxGpC+wGbsa6J+FqNjBJRMKAUkA7YLynwXvVxg9h+YtwYo/V3/pBrRFW+YWUlFSefHIhJ06kM21aXwCuuqoOV11Vx9nAVNDyJFEMAx4HUoEPgfnAc4VNZIzJEJGhdvlQ4G1jzO8iEm+PTzDGbBSRb4C1QBbWI7Tri7YqxejUYfjqtjOHVWntTCxK2YwxzJq1kfvv/4bdu1MICwth5MgO1KlTwenQVJAT19PXfAuItDLGrHZbyIfi4uLMypUrvbuQrXNgdj+r+/p5ENsUytX27jKVcuPPP48wdOjXfPXVHwC0bVudhITetGpV1eHIVKAQkVXGmLiiTOvJGcU4EakKfALMNMb8XpQFBZTVE63Pqu2hXi9nY1ElmjGGl15aytNPL+LUqQzKl49gzJgu3HNPa0JDPbnFqNT586SFu6tF5EKsRoymiUg54GNjTKGXnwLWEfuhqwr1nI1DlXgiwpYthzh1KoNbbmnGuHHdufDCsk6HpUqYQi89nVFY5BLgUaC/MaaU16JywyeXnt6sC8d2wF3bNFkonzt48CR79x6nWbMLcvpXr95Dt27aIJYquvO59OTJC3dNRGS0iKwHJmE98VSjKAsLOPpKq/IhYwwzZiTSuPEkbrzxE9LSMgGIjS2tSUI5ypN7FP8HfARcY4zJ+x6EUqoYbNx4gPj4eSxebFXa3KLFhRw5cooqVfQyk3KeJ/coLvNFIEqVRCdPpvP884t5+eWfSU/PonLl0owb153bbrsE0TNa5ScKTBQi8j9jzE0iso4zq97QFu6UKgbGGDp3fodly3YDcO+9rRkzpovWzaT8jrszivvtzz6+CMRvJO+wbmQr5WUiwuDBbTh5Mp033uhD+/Y1C59IKQcUeDPbGGPXXcFgY8xfrn/AYN+E5wDXup2itMoOVXwyM7N4/fVljBv3S86wAQOas2rVPZoklF/z5I2dbvkM61ncgfgNk2V9Nr4FSmmD86p4rFz5N+3aTee++75h5Mjv+fvvFMA6q9AK/JS/c3ePYhDWmUM9EVnrMioaWOrtwBxX2n8b21OBIzn5NKNG/cDkySswBmrWLMfrr/ekWjU9CFGBw909ig+Br4ExwGMuw1OMMYe9GpVSAc4YwyefbOCBB75hz57jhIYKw4dfxlNPdaJsWUfeVVWqyNwlCmOM2SEiQ/KOEJFKQZks9ifCj8OdjkIFiTfeWMWePce57LIaJCT0pkWLC50OSakiKeyMog+wCuvxWNeHug0QfHVbbHgvtzvaxy3pqYCXmprB0aOnqVKlLCLClCm9+PHHHfznP60JCdF3IlTgKjBRGGP62J91fReOg4yBVeOs7sa3QusHHA1HBZZFi3YQHz+PatWiWbBgACJCo0axNGqkT86pwOdJXU9XiEgZu/tfIjJORILvcDtlV253g3+AaBXOqnAHDpxg4MAv6NTpHTZtOsiuXcns23fC6bCUKlae7A2nAidFpAVWzbF/Ae+5nyQAmczc7gb/cC4OFRCysgxvvfUbjRtP5p131hAREcrTT3di7dpBWg24CjqeVAqYYYwxItIPmGCMeUtE7vB2YI4pV0drjVVuGWPo3v19FizYDkDXrvWYMqUXDRrEOByZUt7hSaJIEZH/AgOADiISCoR7Nyyl/JeI0KFDLdat28f48d25+eZmWoGfCmqeXHrqD6QC/zbG7AWqAy97NSql/My8eVv44otNOf0jRlzBpk1DueUWreVVBT9PqhnfKyIfAG1EpA+w3BjzrvdD86E/PofVrzsdhfJDSUnHuP/+b5g1ayOxsaXp2LE2lSpFERERRkSEJyfkSgU+T556uglYDtyI1W72MhH5p7cD86lfn4NdC63ustWcjUX5hYyMLMaP/4UmTSYza9ZGypQJZ+TIKylXLsLp0JTyOU8OiR4H2hhj9gOISGVgAfCpNwPzKZNhfXaeBE1udTYW5bjly3dz771zSUzcC8D11zdmwoQe1KxZ3uHIlHKGJ4kiJDtJ2A7h2b2NwFP9Sois6HQUykFZWYY775zNhg0HqFWrPJMm9aRv30ZOh6WUozxJFN+IyHysdrPBurn9lfdC8rFTh+DA2sLLqaBljCE1NZPIyDBCQoTJk3vx9dd/8OSTV1GmjFbgp5QnN7MfEZF/AFdi1fc0zRjzudcj85W5N+V2a9XiJc7WrYcZPHgeNWuW4623+gHQqVMdOnWq42xgSvkRd+1RNABeAS4C1gEPG2N2+yown0jeATt/sLprdYWyVR0NR/lOamoGY8cu5YUXlpCamkmlSlG89NJJYmJKOx2aUn7H3b2Gt4G5wA1YNcgG1/Oj+xNhukt9h/1mORaK8q0ffviT5s0TeOqpH0lNzeSOO1qwadMQTRJKFcDdpadoY8ybdvdmEfnNFwH5hMmC91rl9sc9os2elgCZmVnceeds3nvPuifVqFEMCQl99DKTUoVwlygiRaQVue1QRLn2G2MCN3GsnpTbHfcwdHjBuViUz4SGhhAWFkJkZBijRnXg4Ycv15fmlPKAGGPyHyGy0M10xhjT2TshuRcXF2dWrlx5fjP5oC3sXWF1P5ipVYoHsXXr9nH6dAZt2lQH4NChkxw9epqLLqrkcGRK+ZaIrDLGxBVlWncNF11d9JD8XKj9du21szRJBKkTJ9IYPfpHxo//lQYNYlizJp5SpUKJiSmt9yKUOkcl77w7/QTs/snqjtLWx4LRnDmbGTbsa3buTEYEunatS3p6JqVKhTodmlIByauH0yLSQ0Q2i8hWEXnMTbk2IpLpkzqk/vo+t1vfmwgqO3cmc911M+nXbyY7dyZz6aVVWb78P7z+ei99cU6p8+C1Mwq73YrJQDcgCVghInOMMRvyKTcWmO+tWM6w5RPrs8yFUEmrZggWmZlZdOo0gz//PEp0dCmee64zgwe3ISxMLy0qdb4KTRRiVbZ/G1DPGPOM3V72hcaY5YVM2hbYaozZbs9nJtAP2JCn3DDgM6DNuQZfJH/Osz5rdPLJ4pR3GWMQEUJDQxg9uhNffrmF117rTvXq5ZwOTamg4cnh1hSgPXCL3Z+CdaZQmOrALpf+JHtYDhGpDlwPJLibkYjcIyIrRWTlgQMHPFi0G2H2jczLRp3ffJSjjhw5RXz8XF54YUnOsAEDmvPJJzdqklCqmHly6amdMeZSEVkNYIw5IiKeXPDNr9mvvM/ivgaMMMZkumslzBgzDZgG1uOxHiy7cBFaZXQgMsbw4YfrePDBb9m//wTR0aUYOrQt5ctHaktzSnmJJ4ki3b6PYCCnPYosD6ZLAmq69NcA/s5TJg6Yaf/AY4FeIpJhjPnCg/mrEmbLlkMMHjyP77//E4AOHWoxdWpvypePdDgypYKbJ4liIvA5cIGIPA/8E/Dkus0KoIGI1AV2AzcDZ7QKZIzJqWxJRGYAczVJqLwyMrJ47rnFjBnzE2lpmcTERPHyy90YOLClnkUo5QOeVDP+gYisArpgXU66zhiz0YPpMkRkKNbTTKHA28aY30Uk3h7v9r6EUtlCQ4UlS3aSlpbJv//dkrFjuxEbqy/NKeUrnjz1VAs4CXzpOswYs7OwaY0xX5GnkaOCEoQxZmBh8ztvGz+A48FVU3qw2rfvOKdPZ1C7dgVEhISE3uzZc5yOHWs7HZpSJY4nl57mYd2fECASqAtsBpp6Ma7id3QbfPUvqzskXGuL9VNZWYZp01bx2GMLiIurxnffDUBEaNAghgYNYpwOT6kSyZNLT5e49ovIpcC9XovIW1xrjL3pR33qyQ8lJu4lPn4uy5ZZZ32lSoVy/Hga0dERDkemVMl2zm9mG2N+ExHfvBxXnDLTrM/m90D1y52NRZ0hJSWVp576kQkTlpGVZahWLZoJE3pwww1N9Ga1Un7Ak3sUD7r0hgCXAuf51puDYps7HYFykZaWyaWXTmPr1sOEhAj339+OZ565mnLl9CxCKX/hyRmF68X8DKx7Fp95JxwvObge1kxxOgqVj1KlQhkwoDlffrmFhITetG5dzemQlFJ5uE0U9ot2ZY0xj/goHu/4+anc7siKzsWhSE/PZPz4X6lVqzw339wMgMceu5LHH+9AaKhW4KeUPyowUYhImP0uxKW+DKjYZWXCH7Os7sa3QkPv12Su8rd06U7i4+exfv1+KlcuTZ8+DSlbtpS2E6GUn3N3RrEc635EoojMAT4BTmSPNMbM8nJsxWPVuNzulkMgVNsl8LXDh08xYsR3TJ++GoB69SoyZUovypbV/4VSgcCTexSVgENAZ3LfpzBAYCSK1a/ndldr71wcJZAxhvfeW8tDD33LwYMnCQ8PYcSIKxg5sgNRUeFOh6eU8pC7RHGB/cTTenITRLbiqcHVF8LLWp83zAd91NKn0tOzGDPmJw4ePMlVV9Vm6tTeNGlS2emwlFLnyF2iCAXK4ll14f4p/QQctquliq7hbCwlxKlT6aSlZVK+fCSlSoUybVoftm8/wu23t9B3IpQKUO4SxR5jzDM+i6S4ndwPM6/M7S+ljdl42/z5Wxk8+Cs6darNW2/1A6BDh9p06KD1MykVyNwlisA+/Fs7DY78YXVXaqxnFF60Z08Kw4fP5+OPfwegTJlwTp5Mp3RpvQ+hVDBw9+B6F59F4Q2/v2N9lrkQ+i9xX1YVSWZmFpMmLadx48l8/PHvREWFMXZsV1atukeThFJBpMAzCmPMYV8GUqxSk+HoVqu73SgoHetsPEHo9OkMOnb8P1assBot7NOnIa+/3pM6dSo4G5hSqtidc6WAASHjdG530zuciyOIRUaG0azZBezZc5yJE3tw3XWN9Wa1UkEqOBPFsb+sz9IXQKmyzsYSJIwxzJq1kSpVynLllbUAGDeuO6GhotWAKxXkgi9RGAMftrO6U486Gkqw+PPPIwwd+jVfffUHjRvHkph4LxERYVSoEOl0aEopHwi+RHHo99zutv91Lo4gkJaWyauv/syzzy7m1KkMypeP4P772xEWppX3KVWSBF+iSDue293ucefiCHBLlvxFfPw8Nmywmh659dZLePXVa7jwQr2Up1RJE3yJIlvVdhCqj2gWxalT6fzzn5+wf/8J6tevxJQpvejW7SKnw1JKOST4EsWRzU5HEJCMMWRmGsLCQoiKCmfcuGvYsuUQ//1vByIjg+9ropTyXPDtAbKrFc845WwcAWTDhgPEx8+lW7d6PPHEVQDcdps2GauUsgTXXcnMdDiw1upudZ+zsQSAkyfTGTnye1q0SGDJkp1Mn76a1NQMp8NSSvmZ4DmjSDsO827J7a/azrlYAsDXX//BkCFf8eefRwG4997WjBnThYiI4PlKKKWKR/DsFeb/G7bPtXsEYpo6Go6/OnEijYEDZ/PppxsAaN68CgkJvWnfvqbDkSml/FVwJIrMdNjyidUtIXDXVm2kqAClS4dz+PApypQJ5+mnO3H//ZfpexFKKbeCI1Gc2JvbHb8XSmsraq5WrvybChUiqV+/EiLC9Ol9CQ0NoVat8k6HppQKAMFxKJn9pBNoknCRnHyaYcO+om3bN4mPn4sxVsOEdetW1CShlPJYcJxRpJ+wPhv8w9k4/IQxhv/973ceeGA+e/ceJzRUuPTSqmRkZBEeHup0eEqpABMciSJbne5OR+C4bdsOM2TIV8yfvw2A9u1rkJDQh+bNqzgcmVIqUAVHotjxjdMR+IWUlFTi4t7k6NHTVKgQydixXbn77ksJCdEb+0qpovNqohCRHsAEIBSYbox5Mc/424ARdu9xYJAxZs05LSRlN6TssrrDos4z4sAWHR3B8OGXsXXrYV555RouuKCM0yEppYKA1xKFiIQCk4FuQBKwQkTmGGM2uBT7E7jKGHNERHoC04Bze1MuLTm3u/715xl1YDlw4ASPPPIdXbrUZcCAFgA88URHbWlOKVWsvPnUU1tgqzFmuzEmDZgJ9HMtYIz52RhzxO79FahR5KVValJiWrPLyjJMn/4bjRpN4p131vD44z+Qnp4JoElCKVXsvHnpqTqwy6U/CfdnC3cBX+c3QkTuAe4BqFWrVnHFF5DWr99PfPxcli61Nm3XrvWYMqWXPs2klPIabyaK/A5tTb4FRa7GShRX5jfeGDMN67IUcXFx+c4j2J06lc7o0T8ybtyvZGRkUaVKGcaP787NNzfTswillFd5M1EkAa4VCNUA/s5bSESaA9OBnsaYQ16MJ6CFhAhz5mwhMzOLwYPjeP75LtpmtVLKJ7yZKFYADUSkLrAbuBm41bWAiNQCZgEDjDFbvBhLQEpKOkbp0uFUqhRFREQYM2ZYt3jatSv6rRyllDpXXruZbYzJAIYC84GNwP+MMb+LSLyIxNvFngRigCkikigiK70VTyDJyMhi/PhfaNJkMo888m3O8HbtamiSUEr5nFffozDGfAV8lWdYgkv33cDd3owh0CxblsS9985lzZp9ACQnp5KRkaU1vCqlHBMcb2YHgaNHTzNy5PckJKzEGKhduzyTJvWiT5+GToemlCrhAjtRGAPr3ra6wwL3xu6RI6e4+OIp7N17nLCwEB56qD1PPNGRMmVKOR2aUkoFeKLYOhtWvWp1t3vc2VjOQ8WKUfTsWZ8tWw4xdWpvLrlEK/BTSvmPwE4U391jfVZtDw1vcDaWc5CamsHYsUu56qraXHVVHQAmTepFZGSYVuCnlPI7gZsosjLg1AGru9UwZ2M5Bz/88CeDBs1jy5ZDNGkSy7p1gwgNDaF06XCnQ1NKqXwFbqJY8VJud/UrnIvDQ/v3n+Chh77l/ffXAtC4cSxTpvQmNFSfZlJK+bfATRQ/udyTKOe/9T9lV+A3YsQCjh49TWRkGKNGdeCRR66gVCmtn0kp5f8CN1GEhFmXn+5Y73QkbiUnn+bxx3/g6NHTdO9+EZMn9+Kiiyo5HZZSSnkscBNFtor+957BiRNphIWFEBERRsWKUSQk9CYz03DjjRdrBX5KqYCjF8iL2Zw5m7n44im89NLSnGE33HAxN93UVJOEUiogBV6iMFmw9k3rshMCfrLz3bkzmeuum0m/fjPZuTOZ+fO3kZVVImtEV0oFmcBLFClJue9P1Otj3atwUHp6Jq+88jNNmkxm9uzNREeXYsKEHixaNFDfiVBKBYXAu0eRlW59hkVBl0mOhnLw4Em6dHmXtWutCvxuvPFixo/vTvXq5RyNSymlilPgJYpsPd91/LHYmJgoYmNLU7duBSZN6kWvXg0cjUf5l/T0dJKSkjh9+rTToagSJDIykho1ahAeXnwv8QZuonCAMYYPPlhH27bVadgwBhHh/fevp3z5SH2zWp0lKSmJ6Oho6tSpow8yKJ8wxnDo0CGSkpKoW7dusc038O5ROGTz5oN07foeAwZ8zuDB8zDGulFdtWq0JgmVr9OnTxMTE6NJQvmMiBATE1PsZ7F6RlGI06czGDNmCS++uJS0tExiYqL417+aOx2WChCaJJSveeM7p4nCjQULtjNo0Dy2bj0MwL//3ZKXXupGTExphyNTSinf0UtPBdi37zh9+nzI1q2HufjiyixePJC33uqnSUIFlNDQUFq2bEmzZs3o27cvR48ezRn3+++/07lzZxo2bEiDBg149tlncy6pAnz99dfExcXRpEkTGjduzMMPP+zAGri3evVq7r7bf1tTTk1NpX///tSvX5927dqxY8eOfMt99NFHXHLJJTRv3pwePXpw8OBBAGbMmEHlypVp2bIlLVu2ZPr06QAcOHCAHj16+Go1NFG4ysoyOT+UKlXK8swzVzNmTBdWr76XDh1qOxydUucuKiqKxMRE1q9fT6VKlZg8eTIAp06d4tprr+Wxxx5jy5YtrFmzhp9//pkpU6YAsH79eoYOHcr777/Pxo0bWb9+PfXq1SvW2DIyMs57Hi+88ALDhnnezEBxLPNcvPXWW1SsWJGtW7cyfPhwRowYkW9M999/PwsXLmTt2rU0b96cSZNyH/3v378/iYmJJCYm5iTFypUrU7VqVZYuXXrW/LxBLz3ZEhP3Eh8/lyFD2jBgQAsAHn3U/6svVwHiVS/dq3jI87f/27dvz9q1VjX3H374IVdccQXXXHMNAKVLl2bSpEl06tSJIUOG8NJLL/H444/TuHFjAMLCwhg8ePBZ8zx+/DjDhg1j5cqViAhPPfUUN9xwA2XLluX48eMAfPrpp8ydO5cZM2YwcOBAKlWqxOrVq2nZsiWff/45iYmJVKhQAYD69euzdOlSQkJCiI+PZ+fOnQC89tprXHHFmb/HlJQU1q5dS4sW1u91+fLlPPDAA5w6dYqoqCj+7//+j0aNGjFjxgzmzZvH6dOnOXHiBF9++SXDhg1j3bp1ZGRkMHr0aPr168eOHTsYMGAAJ06cAGDSpElcfvnlHm/f/MyePZvRo0cD8M9//pOhQ4dijDnjPoIx1gHqiRMniImJ4dixY9SvX7/QeV933XV88MEHZ20XbyjxiSIlJZWnnvqRCROWkZVlSE3N5F//aq43IVVQyczM5Pvvv+euu+4CrMtOrVu3PqPMRRddxPHjxzl27Bjr16/noYceKnS+zz77LOXLl2fdunUAHDlypNBptmzZwoIFCwgNDSUrK4vPP/+cO++8k2XLllGnTh2qVKnCrbfeyvDhw7nyyivZuXMn3bt3Z+PGjWfMZ+XKlTRr1iynv3HjxixevJiwsDAWLFjAyJEj+eyzzwD45ZdfWLt2LZUqVWLkyJF07tyZt99+m6NHj9K2bVu6du3KBRdcwHfffUdkZCR//PEHt9xyCytXrjwr/g4dOpCSknLW8FdeeYWuXbueMWz37t3UrFkTsJJt+fLlOXToELGxsTllwsPDmTp1KpdccgllypShQYMGOWd+AJ999hmLFy+mYcOGjB8/Pmd+cXFxjBo1qtDtXRxKbKIwxvDFF5u4775vSEo6RkiIcP/97Xjmmas1Sajidw5H/sXp1KlTtGzZkh07dtC6dWu6desGcNZRratz+f4vWLCAmTNn5vRXrFix0GluvPFGQkOttlj69+/PM888w5133snMmTPp379/znw3bNiQM82xY8dISUkhOjo6Z9iePXuoXLlyTn9ycjJ33HEHf/zxByJCenp6zrhu3bpRqZJVvf+3337LnDlzeOWVVwDrMeadO3dSrVo1hg4dSmJiIqGhoWzZsiXf+JcsWVLoOmZzveeTLe/2TU9PZ+rUqaxevZp69eoxbNgwxowZw6hRo+jbty+33HILERERJCQkcMcdd/DDDz8AcMEFF/D33397HMv5KJGJ4uDBk9x552zmzrW+CHFx1XjjjT5cemlVhyNTqnhl36NITk6mT58+TJ48mfvuu4+mTZuyePHiM8pu376dsmXLEh0dTdOmTVm1alXOZZ2CFJRwXIflfaa/TJkyOd3t27dn69atHDhwgC+++CLnCDkrK4tffvmFqKgot+vmOu8nnniCq6++ms8//5wdO3bQqVOnfJdpjOGzzz6jUaNGZ8xv9OjRVKlShTVr1pCVlUVkZGS+yz2XM4oaNWqwa9cuatSoQUZGBsnJyTkJK1tiYiJgndEB3HTTTbz44osAxMTE5JT7z3/+c8Y9jtOnT7vdPsWpRN7Mjo4uxdathylXLoJJk3ry6693aZJQQa18+fJMnDiRV155hfT0dG677TZ++uknFixYAFhnHvfddx+PPvooAI888ggvvPBCzlF1VlYW48aNO2u+11xzzRk3XrMvPVWpUoWNGzfmXFoqiIhw/fXX8+CDD9KkSZOcHWPe+WbvTF01adKErVu35vQnJydTvXp1wHpaqCDdu3fn9ddfzznaX716dc70VatWJSQkhPfee4/MzMx8p1+yZEnOzWXXv7xJAuDaa6/lnXfeAax7NZ07dz4rsVavXp0NGzZw4MABAL777juaNGkCWGdN2ebMmZMzHKxLeK6X3rypxCSKpUt3cujQSQAiIsKYOfMGNm0awpAhbbXdalUitGrVihYtWjBz5kyioqKYPXs2zz33HI0aNeKSSy6hTZs2DB06FIDmzZvz2muvccstt9CkSROaNWt2xk4r26hRozhy5AjNmjWjRYsWLFy4EIAXX3yRPn360LlzZ6pWdX8Q1r9/f95///2cy04AEydOZOXKlTRv3pyLL76YhISEs6Zr3LgxycnJOUf3jz76KP/973+54oorCtzJg3XmkZ6eTvPmzWnWrBlPPPEEAIMHD+add97hsssuY8uWLWechRTVXXfdxaFDh6hfvz7jxo3LOVMAaNmyJQDVqlXjqaeeomPHjjRv3pzExERGjhyZsx2aNm1KixYtmDhx4hkJcOHChfTu3fu8Y/SE5HcNzZ/F1a9oVg46Cn0/gYb/LLT8oUMneeyxBUyfvpq77mrF9OnXej9IpYCNGzeecQSoit/48eOJjo7263cpvKVjx47Mnj073/tC+X33RGSVMSauKMsK2kNpYwzvvJNI48aTmT59NeHhIVSrFp3vzSWlVGAaNGgQERERTofhcwcOHODBBx/06OGB4hCUN7M3bTpIfPxcFi36C4BOneowdWpvGjeOLWRKpVQgiYyMZMCAAU6H4XOVK1fmuuuu89nygi5RJCUdo0WLBNLSMomNLc2rr17DgAH6XoRyhrvHUJXyBm9cNQm6RFGjRjkGDGhOSIjw4otdqVTJN4+PKZVXZGQkhw4d0qrGlc9kt0dR0KO9RRXwiWLPnhSGD59PfHwcnTrVAWDatL7aXrVyXI0aNUhKSsp57FEpX8hu4a44BWyiyMw0TJ20nMcf/4Fjx1LZuvUwK1b8BxHRJKH8Qnh4eLG2MqaUU7z61JOI9BCRzSKyVUQey2e8iMhEe/xaEbm00JlmnOS3pKpcdtN2hg37mmPHUunbtyGffXaTnt4rpZQXeO2MQkRCgclANyAJWCEic4wxG1yK9QQa2H/tgKn2Z4F2HYqkzYT/kGVOU6NGOV5/vSf9+jXSJKGUUl7izTOKtsBWY8x2Y0waMBPol6dMP+BdY/kVqCAibl/jPHwyChF48L6WbNw4hOuua6xJQimlvMib9yiqA7tc+pM4+2whvzLVgTPqChCRe4B77N5UeGb9uIkwbmLxBhyAYoGDTgfhJ3Rb5NJtkUu3Ra5GhRfJnzcTRX6H+Xkf8PWkDMaYacA0ABFZWdTX0IONbotcui1y6bbIpdsil4ic3biGh7x56SkJqOnSXwPIW3m6J2WUUko5yJuJYgXQQETqikgp4GZgTp4yc4Db7aefLgOSjTFnV1GplFLKMV679GSMyRCRocB8IBR42xjzu4jE2+MTgK+AXsBW4CRwpweznualkAORbotcui1y6bbIpdsiV5G3RcBVM66UUsq3graacaWUUsVDE4VSSim3/DZReKX6jwDlwba4zd4Ga0XkZxFp4UScvlDYtnAp10ZEMkWk8GYQA5Qn20JEOolIooj8LiKLfB2jr3jwGykvIl+KyBp7W3hyPzTgiMjbIrJfRNYXML5o+01jjN/9Yd383gbUA0oBa4CL85TpBXyN9S7GZcAyp+N2cFtcDlS0u3uW5G3hUu4HrIcl/ul03A5+LyoAG4Badv8FTsft4LYYCYy1uysDh4FSTsfuhW3REbgUWF/A+CLtN/31jMIr1X8EqEK3hTHmZ2PMEbv3V6z3UYKRJ98LgGHAZ8B+XwbnY55si1uBWcaYnQDGmGDdHp5sCwNEi1XfT1msRJHh2zC9zxizGGvdClKk/aa/JoqCqvY41zLB4FzX8y6sI4ZgVOi2EJHqwPVAgg/jcoIn34uGQEUR+VFEVonI7T6Lzrc82RaTgCZYL/SuA+43xmT5Jjy/UqT9pr+2R1Fs1X8EAY/XU0SuxkoUV3o1Iud4si1eA0YYYzKDvLJIT7ZFGNAa6AJEAb+IyK/GmC3eDs7HPNkW3YFEoDNwEfCdiCwxxhzzcmz+pkj7TX9NFFr9Ry6P1lNEmgPTgZ7GmEM+is3XPNkWccBMO0nEAr1EJMMY84VPIvQdT38jB40xJ4ATIrIYaAEEW6LwZFvcCbxorAv1W0XkT6AxsNw3IfqNIu03/fXSk1b/kavQbSEitYBZwIAgPFp0Vei2MMbUNcbUMcbUAT4FBgdhkgDPfiOzgQ4iEiYipbFqb97o4zh9wZNtsRPrzAoRqYJVk+p2n0bpH4q03/TLMwrjveo/Ao6H2+JJIAaYYh9JZ5ggrDHTw21RIniyLYwxG0XkG2AtkAVMN8bk+9hkIPPwe/EsMENE1mFdfhlhjAm66sdF5COgExArIknAU0A4nN9+U6vwUEop5Za/XnpSSinlJzRRKKWUcksThVJKKbc0USillHJLE4VSSim3NFEov2TX/Jro8lfHTdnjxbC8GSLyp72s30SkfRHmMV1ELra7R+YZ9/P5xmjPJ3u7rLdrQ61QSPmWItKrOJatSi59PFb5JRE5bowpW9xl3cxjBjDXGPOpiFwDvGKMaX4e8zvvmAqbr4i8A2wxxjzvpvxAIM4YM7S4Y1Elh55RqIAgImVF5Hv7aH+diJxVa6yIVBWRxS5H3B3s4deIyC/2tJ+ISGE78MVAfXvaB+15rReRB+xhZURknt22wXoR6W8P/1FE4kTkRSDKjuMDe9xx+/Nj1yN8+0zmBhEJFZGXRWSFWO0E3OvBZvkFu0I3EWkrVlskq+3PRvZbys8A/e1Y+tuxv20vZ3V+21Gpszhdf7r+6V9+f0AmViVuicDnWLUIlLPHxWK9WZp9Rnzc/nwIeNzuDgWi7bKLgTL28BHAk/ksbwZ22xXAjcAyrAr11gFlsKqm/h1oBdwAvOkybXn780eso/ecmFzKZMd4PfCO3V0KqybPKOAeYJQ9PAJYCdTNJ87jLuv3CdDD7i8HhNndXYHP7O6BwCSX6V8A/mV3V8Cq96mM0/9v/fPvP7+swkMp4JQxpmV2j4iEAy+ISEes6iiqA1WAvS7TrADetst+YYxJFJGrgIuBpXb1JqWwjsTz87KIjAIOYNXC2wX43FiV6iEis4AOwDfAKyIyFuty1ZJzWK+vgYkiEgH0ABYbY07Zl7uaS26LfOWBBsCfeaaPEpFEoA6wCvjOpfw7ItIAqzbQ8AKWfw1wrYg8bPdHArUIzjqgVDHRRKECxW1YLZO1Nsaki8gOrJ1cDmPMYjuR9AbeE5GXgSPAd8aYWzxYxiPGmE+ze0Ska36FjDFbRKQ1Vp05Y0TkW2PMM56shDHmtIj8iFXtdX/go+zFAcOMMfMLmcUpY0xLESkPzAWGABOx6jJaaIy53r7x/2MB0wtwgzFmsyfxKgV6j0IFjvLAfjtJXA3UzltARGrbZd4E3sJqEvJX4AoRyb7nUFpEGnq4zMXAdfY0ZbAuGy0RkWrASWPM+8Ar9nLySrfPbPIzE6sytg5YFdlhfw7KnkZEGtrLzJcxJhm4D3jYnqY8sNsePdClaArWJbhs84FhYp9eiUirgpahVDZNFCpQfADEichKrLOLTfmU6QQkishqrPsIE4wxB7B2nB+JyFqsxNHYkwUaY37DunexHOuexXRjzGrgEmC5fQnoceC5fCafBqzNvpmdx7dYbRsvMFbTnWC1JbIB+E1E1gNvUMgZvx3LGqxqtV/COrtZinX/IttC4OLsm9lYZx7hdmzr7X6l3NLHY5VSSrmlZxRKKaXc0kShlFLKLU0USiml3NJEoZRSyi1NFEoppdzSRKGUUsotTRRKKaXc+n/iEajPUBCvEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" #qui metto max_depth=1 \n",
    "df = train_enh_stded \n",
    "\n",
    "class_weight = {1:1, 2:6}\n",
    "Ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, class_weight=class_weight),\n",
    "                         n_estimators=174,\n",
    "                         learning_rate = 0.4,     #default = 1\n",
    "                         random_state=0)\n",
    "\n",
    "cv_result = compute_cv(Ada, X, y, 10, scorer=loss_function)\n",
    "\n",
    "Ada.fit(X,y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(train_enh_dum, Ada)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = Ada.predict(df_test)\n",
    "get_txt(y_pred, filename = \"ADA_d1_Predictions.txt\")\n",
    "\n",
    "feature_importances[\"ada_d1\"] = Ada.fit(X, y).feature_importances_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -179.3 std =  18.171681265089372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" #qui metto max_depth=2 (bilanciando con meno estimators e learning rate minore) \n",
    "df = train_enh_stded \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "class_weight = {1:1, 2:4}\n",
    "Ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, class_weight=class_weight),\n",
    "                         n_estimators=28,\n",
    "                         learning_rate = 0.3,     #default = 1\n",
    "                         random_state=0)\n",
    "\n",
    "cv_result = compute_cv(Ada, X, y, 10, scorer=loss_function)\n",
    "\n",
    "Ada.fit(X,y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(train_enh_dum, Ada)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "feature_importances[\"ada_d2\"] = Ada.fit(X, y).feature_importances_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Final Model: Ensemble\n",
    "\n",
    "### [Model Stacking](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html )\n",
    "\n",
    "mean =  -171.6 std =  17.86728854639114  \\\n",
    "usando 5.2 final class wwights, e initial class wewights solo a boosting con d=1 e random forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data on which to fit\n",
    "\n",
    "df_train = train_enh_stded #train_enh_dum - train_enh_stded\n",
    "df_test  = test_enh_stded\n",
    "\n",
    "X, y = create_X_y(df_train)\n",
    "\n",
    "# adjusting labels\n",
    "\n",
    "y=y-1\n",
    "class_1 = 0\n",
    "class_2 = class_1 + 1\n",
    "\n",
    "# models' parameters\n",
    "\n",
    "final_lr_weights  = {class_1:1, class_2:5.2}\n",
    "#final_lr_weights  = {class_1:1, class_2:4.25}\n",
    "lr_weights        = {class_1:1, class_2:4.25}\n",
    "ada1_class_weight = {class_1:1, class_2:6}\n",
    "ada2_class_weight = {class_1:1, class_2:4}\n",
    "RF_class_weights  = {class_1:1, class_2:5}\n",
    "\n",
    "prior_l = 0.3 \n",
    "final_lda_priors = [prior_l, 1-prior_l]\n",
    "prior_l = 0.35 \n",
    "lda_priors = [prior_l, 1-prior_l]\n",
    "prior_l = 0.9\n",
    "gnb_priors = [prior_l, 1-prior_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers to stack\n",
    "\n",
    "clf_1 = LogisticRegression(max_iter=2000,\n",
    "                            C=1.20,\n",
    "                            random_state=0,\n",
    "                            solver = 'liblinear', \n",
    "                            class_weight= lr_weights\n",
    "                          ) \n",
    "\n",
    "clf_2 = LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                                   shrinkage=\"auto\",\n",
    "                                   priors=lda_priors\n",
    "                                  )\n",
    "\n",
    "clf_3 = GaussianNB(priors=gnb_priors) #priors=gnb_priors\n",
    "\n",
    "clf_4 = RandomForestClassifier(n_estimators= 1000,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0,\n",
    "                            class_weight= RF_class_weights,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features=0.16) #\"log2\"\n",
    "\n",
    "clf_5 =  AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, \n",
    "                                                   class_weight=ada1_class_weight\n",
    "                                                 ),\n",
    "                         n_estimators=174,\n",
    "                         learning_rate = 0.4,     #default = 1\n",
    "                         random_state=0)\n",
    "\n",
    "\n",
    "clf_6 =  AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, \n",
    "                                                   class_weight=ada2_class_weight\n",
    "                                                 ),\n",
    "                         n_estimators=28,\n",
    "                         learning_rate = 0.3,     #default = 1\n",
    "                         random_state=0)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#           playing around with class weights\n",
    "\n",
    "clf_1_bis = LogisticRegression(max_iter=2000,\n",
    "                            C=1.20,\n",
    "                            random_state=0,\n",
    "                            solver = 'liblinear', \n",
    "                            #class_weight= lr_weights\n",
    "                          ) \n",
    "\n",
    "clf_2_bis = LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                                   shrinkage=\"auto\",\n",
    "                                   #priors=lda_priors\n",
    "                                  )\n",
    "\n",
    "clf_3_bis = GaussianNB() #priors=gnb_priors\n",
    "\n",
    "clf_4_bis = RandomForestClassifier(n_estimators= 1000,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0,\n",
    "                            #class_weight= RF_class_weights,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features=0.16) #\"log2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the stacking model\n",
    "\n",
    "estimators = [\n",
    "     #('LR',  clf_1),\n",
    "     #('LDA', clf_2), \n",
    "     #('G_NB', clf_3),\n",
    "     ('RF', clf_4),\n",
    "     #('ADA_1', clf_5),\n",
    "     ('ADA_2', clf_6),\n",
    "        ('LR_bis',clf_1_bis),\n",
    "        ('LDA_bis',clf_2_bis),\n",
    "        ('G_NB_bis',clf_3_bis),\n",
    "        ('RF_bis',clf_4_bis)\n",
    "     #('naiveLDA', clf_7)\n",
    "     #('svr', make_pipeline(StandardScaler(),\n",
    "     #                      LinearSVC(random_state=42))\n",
    "     ]\n",
    "    \n",
    "stack = StackingClassifier(estimators=estimators,\n",
    "                           final_estimator=LogisticRegression(class_weight= final_lr_weights,\n",
    "                                                              max_iter=2000,\n",
    "                                                              C=0.8),\n",
    "                           #final_estimator=LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                           #                                           shrinkage=\"auto\",\n",
    "                           #                                           priors=final_lda_priors),\n",
    "                           #passthrough = True,\n",
    "                           cv=7\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier(cv=7,\n",
      "                   estimators=[('RF',\n",
      "                                RandomForestClassifier(class_weight={0: 1,\n",
      "                                                                     1: 5},\n",
      "                                                       criterion='entropy',\n",
      "                                                       max_features=0.16,\n",
      "                                                       max_leaf_nodes=45,\n",
      "                                                       n_estimators=1000,\n",
      "                                                       n_jobs=-1,\n",
      "                                                       random_state=0)),\n",
      "                               ('ADA_2',\n",
      "                                AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight={0: 1,\n",
      "                                                                                                       1: 4},\n",
      "                                                                                         max_depth=2),\n",
      "                                                   learning_rate=0.3,\n",
      "                                                   n_estimators=28,\n",
      "                                                   random_state=0)),\n",
      "                               ('LR_bis...\n",
      "                                                   random_state=0,\n",
      "                                                   solver='liblinear')),\n",
      "                               ('LDA_bis',\n",
      "                                LinearDiscriminantAnalysis(shrinkage='auto',\n",
      "                                                           solver='eigen')),\n",
      "                               ('G_NB_bis', GaussianNB()),\n",
      "                               ('RF_bis',\n",
      "                                RandomForestClassifier(criterion='entropy',\n",
      "                                                       max_features=0.16,\n",
      "                                                       max_leaf_nodes=45,\n",
      "                                                       n_estimators=1000,\n",
      "                                                       n_jobs=-1,\n",
      "                                                       random_state=0))],\n",
      "                   final_estimator=LogisticRegression(C=0.8,\n",
      "                                                      class_weight={0: 1,\n",
      "                                                                    1: 5.2},\n",
      "                                                      max_iter=2000)) -171.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.338031</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.170039</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>20.757890</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240803</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.769207</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>20.104726</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.004849</td>\n",
       "      <td>0.752788</td>\n",
       "      <td>0.385608</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-175.4</td>\n",
       "      <td>17.505428</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375458</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>21.592591</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.422458</td>\n",
       "      <td>0.243215</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>20.464848</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.970117</td>\n",
       "      <td>0.509622</td>\n",
       "      <td>0.374631</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>19.975235</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.507589</td>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.171174</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-174.1</td>\n",
       "      <td>21.528818</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.668487</td>\n",
       "      <td>0.075723</td>\n",
       "      <td>0.210029</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>20.464848</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.226551</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.265682</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>21.633539</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.663946</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.215796</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.3</td>\n",
       "      <td>20.342320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.523239</td>\n",
       "      <td>0.169048</td>\n",
       "      <td>0.167592</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>[(LDA_bis, LinearDiscriminantAnalysis(shrinkag...</td>\n",
       "      <td>{'estimators': [('LDA_bis', LinearDiscriminant...</td>\n",
       "      <td>-238.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.2</td>\n",
       "      <td>26.076043</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.444264</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>0.167179</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>21.913466</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.826047</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>20.145471</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.479482</td>\n",
       "      <td>0.133666</td>\n",
       "      <td>0.167930</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>19.461757</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.344757</td>\n",
       "      <td>0.172851</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.341275</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.511933</td>\n",
       "      <td>0.153101</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.222759</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17.827831</td>\n",
       "      <td>0.053075</td>\n",
       "      <td>0.215502</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>19.980991</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.060865</td>\n",
       "      <td>0.073835</td>\n",
       "      <td>0.216202</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>21.688937</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.489904</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.029744</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.1</td>\n",
       "      <td>20.042205</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.509003</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>20.740299</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.898372</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.174592</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.8</td>\n",
       "      <td>21.618511</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.251430</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-201.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-178.2</td>\n",
       "      <td>27.650678</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.235789</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.205144</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-180.3</td>\n",
       "      <td>23.524668</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.715888</td>\n",
       "      <td>0.079068</td>\n",
       "      <td>0.337473</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.744884</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.384014</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.172627</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-177.9</td>\n",
       "      <td>23.010650</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.459732</td>\n",
       "      <td>0.056540</td>\n",
       "      <td>0.168546</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>23.673825</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.614578</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>23.389955</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.473724</td>\n",
       "      <td>0.060351</td>\n",
       "      <td>0.165792</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>22.991520</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.458482</td>\n",
       "      <td>0.095058</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>22.991520</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.351031</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.042241</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>22.415173</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.722246</td>\n",
       "      <td>0.263365</td>\n",
       "      <td>0.202473</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-176.6</td>\n",
       "      <td>20.819222</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16.479936</td>\n",
       "      <td>0.163674</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>21.565945</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.514436</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.327700</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.365683</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.042184</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.4</td>\n",
       "      <td>22.253988</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>26.677653</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.379080</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>19.910801</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26.607392</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.377038</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>20.295073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.743629</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>0.169809</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>20.909567</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.402036</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>21.525798</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.170853</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.387883</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.270118</td>\n",
       "      <td>0.131239</td>\n",
       "      <td>0.170939</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-245.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.1</td>\n",
       "      <td>27.602355</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.349277</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.034372</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>20.504877</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.520792</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.327700</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16.550430</td>\n",
       "      <td>0.272073</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.6</td>\n",
       "      <td>20.771134</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.594746</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.179112</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.3</td>\n",
       "      <td>21.298122</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.757929</td>\n",
       "      <td>0.055073</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>21.964744</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.178113</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.387883</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11.820202</td>\n",
       "      <td>0.066309</td>\n",
       "      <td>0.177736</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>20.898804</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.493909</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.270703</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.589494</td>\n",
       "      <td>0.109068</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>20.401961</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>17.802411</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.207504</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>19.735501</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>16.680314</td>\n",
       "      <td>0.072946</td>\n",
       "      <td>0.206944</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.238879</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20.445895</td>\n",
       "      <td>0.129050</td>\n",
       "      <td>0.335978</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.876241</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>17.689830</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.212837</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.185844</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>26.677761</td>\n",
       "      <td>0.573716</td>\n",
       "      <td>0.381371</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>17.872045</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>16.913673</td>\n",
       "      <td>0.439962</td>\n",
       "      <td>0.207221</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>19.955200</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>22.611394</td>\n",
       "      <td>0.401519</td>\n",
       "      <td>0.351329</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.336588</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.609984</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.277081</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.466545</td>\n",
       "      <td>0.157950</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>20.908372</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.641372</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.165792</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>20.757890</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.199324</td>\n",
       "      <td>0.281303</td>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.6</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>20.727508</td>\n",
       "      <td>0.400496</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.3</td>\n",
       "      <td>22.271282</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>11.809794</td>\n",
       "      <td>0.055980</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>21.235819</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-201.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>27.539971</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10.496971</td>\n",
       "      <td>0.075052</td>\n",
       "      <td>0.169609</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>23.673825</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>12.162654</td>\n",
       "      <td>0.468353</td>\n",
       "      <td>0.177859</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-229.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>21.634463</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>11.846477</td>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.177972</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>20.036217</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10.434697</td>\n",
       "      <td>0.089211</td>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-205.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.7</td>\n",
       "      <td>22.601106</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10.622375</td>\n",
       "      <td>0.067721</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-173.2</td>\n",
       "      <td>20.028979</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>20.621899</td>\n",
       "      <td>0.109678</td>\n",
       "      <td>0.341510</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>22.622997</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>11.697997</td>\n",
       "      <td>0.047223</td>\n",
       "      <td>0.174580</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.3</td>\n",
       "      <td>20.342320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>28.561059</td>\n",
       "      <td>0.420984</td>\n",
       "      <td>0.380764</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-149.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.275892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>11.840588</td>\n",
       "      <td>0.054972</td>\n",
       "      <td>0.177862</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-178.3</td>\n",
       "      <td>20.823304</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.586694</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>20.161597</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-203.1</td>\n",
       "      <td>14.754321</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>20.628272</td>\n",
       "      <td>0.318612</td>\n",
       "      <td>0.340096</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>18.883856</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>28.260366</td>\n",
       "      <td>0.465883</td>\n",
       "      <td>0.384251</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-149.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.275892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20.737981</td>\n",
       "      <td>0.136795</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-178.6</td>\n",
       "      <td>21.513717</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>21.778537</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>0.347962</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>17.995833</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.591568</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>21.630765</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>16.398293</td>\n",
       "      <td>0.469406</td>\n",
       "      <td>0.206567</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-246.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-185.7</td>\n",
       "      <td>26.400947</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.225161</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16.699623</td>\n",
       "      <td>0.269708</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.1</td>\n",
       "      <td>21.073443</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.511976</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>19.493845</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.255388</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.035718</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>21.772689</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.338684</td>\n",
       "      <td>0.103812</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.2</td>\n",
       "      <td>19.239543</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12.002461</td>\n",
       "      <td>0.170282</td>\n",
       "      <td>0.176504</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-175.5</td>\n",
       "      <td>22.037468</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10.435406</td>\n",
       "      <td>0.139609</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>21.288729</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6.137977</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>22.116962</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7.463664</td>\n",
       "      <td>0.022040</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.513949</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.481651</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7.592929</td>\n",
       "      <td>0.234298</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>20.740299</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>16.624000</td>\n",
       "      <td>0.082506</td>\n",
       "      <td>0.208226</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.7</td>\n",
       "      <td>21.977488</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>21.918261</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>22.118770</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.118742</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LDA_bis, LinearDiscriminantAnalysis(shrinkag...</td>\n",
       "      <td>{'estimators': [('LDA_bis', LinearDiscriminant...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-202.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.9</td>\n",
       "      <td>23.062741</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16.686289</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.204673</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.238879</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.006875</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.040995</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-201.4</td>\n",
       "      <td>14.214078</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.162990</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-202.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>22.022716</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>16.272473</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.205279</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>18.434750</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>28.144504</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>0.380145</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.453850</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>16.373527</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.204847</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.9</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22.023809</td>\n",
       "      <td>0.078075</td>\n",
       "      <td>0.343827</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-171.9</td>\n",
       "      <td>19.454819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>26.723527</td>\n",
       "      <td>0.094741</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>22.885803</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10.365902</td>\n",
       "      <td>0.040477</td>\n",
       "      <td>0.164555</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>22.284524</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17.648201</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.213160</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.185844</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.146865</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>21.089334</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>16.394125</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.205983</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.9</td>\n",
       "      <td>21.874414</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>17.529424</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.213070</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>17.881834</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.481933</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>23.462523</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.336050</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>21.058015</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>17.603315</td>\n",
       "      <td>0.047949</td>\n",
       "      <td>0.216387</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-177.1</td>\n",
       "      <td>20.651634</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>16.532062</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.206722</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>21.926240</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>22.338609</td>\n",
       "      <td>0.388232</td>\n",
       "      <td>0.347016</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>19.824480</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>16.601015</td>\n",
       "      <td>0.046072</td>\n",
       "      <td>0.210782</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.092416</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.565913</td>\n",
       "      <td>0.677105</td>\n",
       "      <td>0.038640</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>23.460818</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.178289</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-183.8</td>\n",
       "      <td>22.666275</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>11.283880</td>\n",
       "      <td>0.385224</td>\n",
       "      <td>0.173312</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-173.8</td>\n",
       "      <td>22.144074</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.402329</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.2</td>\n",
       "      <td>20.093780</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-203.1</td>\n",
       "      <td>14.754321</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12.135676</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.178477</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-177.3</td>\n",
       "      <td>21.000238</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.517433</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12.253810</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-176.6</td>\n",
       "      <td>20.563074</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16.746793</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>21.292252</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>17.398432</td>\n",
       "      <td>0.258976</td>\n",
       "      <td>0.208468</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.1</td>\n",
       "      <td>20.505853</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12.258847</td>\n",
       "      <td>0.726106</td>\n",
       "      <td>0.182136</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>16.794047</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>30.103281</td>\n",
       "      <td>4.527205</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>20.295073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.489912</td>\n",
       "      <td>0.322433</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.4</td>\n",
       "      <td>21.298826</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>25.083474</td>\n",
       "      <td>0.909619</td>\n",
       "      <td>0.200606</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.2</td>\n",
       "      <td>21.989998</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.256063</td>\n",
       "      <td>0.575405</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>20.842265</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.949700</td>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>20.145471</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>16.717961</td>\n",
       "      <td>0.220108</td>\n",
       "      <td>0.192011</td>\n",
       "      <td>0.057382</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-173.5</td>\n",
       "      <td>21.855205</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>26.874849</td>\n",
       "      <td>6.055256</td>\n",
       "      <td>0.341520</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.461757</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>17.808298</td>\n",
       "      <td>0.072345</td>\n",
       "      <td>0.213130</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>20.660106</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.479141</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.4</td>\n",
       "      <td>21.298826</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1.470770</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>19.616575</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.612307</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.781052</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.545272</td>\n",
       "      <td>0.082314</td>\n",
       "      <td>0.043132</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-182.6</td>\n",
       "      <td>20.090794</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.358336</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>22.241628</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>22.206022</td>\n",
       "      <td>0.081089</td>\n",
       "      <td>0.348265</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>20.075109</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.340004</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>21.058015</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>29.355811</td>\n",
       "      <td>1.736490</td>\n",
       "      <td>0.390960</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-148.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.223943</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>23.304129</td>\n",
       "      <td>0.995861</td>\n",
       "      <td>0.348271</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>20.006249</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.568629</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-177.6</td>\n",
       "      <td>18.932512</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.122207</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>21.761434</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.148275</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>23.371778</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>18.086180</td>\n",
       "      <td>0.658769</td>\n",
       "      <td>0.214433</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.2</td>\n",
       "      <td>21.989998</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>27.433562</td>\n",
       "      <td>0.205625</td>\n",
       "      <td>0.382657</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-231.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-178.1</td>\n",
       "      <td>22.801096</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.531030</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.8</td>\n",
       "      <td>22.741152</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        11.338031      0.616046         0.170039        0.007064   \n",
       "1         0.240803      0.007910         0.000000        0.000000   \n",
       "2         7.769207      0.151929         0.042650        0.006559   \n",
       "3        29.004849      0.752788         0.385608        0.007033   \n",
       "4         0.375458      0.007136         0.000000        0.000000   \n",
       "5        12.422458      0.243215         0.178342        0.012183   \n",
       "6        26.970117      0.509622         0.374631        0.010245   \n",
       "7        10.507589      0.063128         0.171174        0.002264   \n",
       "8        17.668487      0.075723         0.210029        0.006483   \n",
       "9         0.226551      0.008009         0.001562        0.004687   \n",
       "10        6.265682      0.051541         0.037496        0.007654   \n",
       "11       18.663946      0.907740         0.215796        0.006366   \n",
       "12       10.523239      0.169048         0.167592        0.009199   \n",
       "13       10.444264      0.121723         0.167179        0.007162   \n",
       "14        7.826047      0.081363         0.043181        0.004352   \n",
       "15       10.479482      0.133666         0.167930        0.009013   \n",
       "16        6.344757      0.172851         0.039059        0.007812   \n",
       "17       10.511933      0.153101         0.169517        0.004707   \n",
       "18       17.827831      0.053075         0.215502        0.005288   \n",
       "19       18.060865      0.073835         0.216202        0.011192   \n",
       "20        1.489904      0.011686         0.006696        0.000458   \n",
       "21       22.029744      0.044366         0.344463        0.005416   \n",
       "22        1.509003      0.011985         0.007958        0.002572   \n",
       "23       11.898372      0.042674         0.174592        0.005462   \n",
       "24        0.251430      0.005144         0.001562        0.004687   \n",
       "25       16.235789      0.041534         0.205144        0.006802   \n",
       "26       20.715888      0.079068         0.337473        0.006560   \n",
       "27       10.384014      0.078998         0.172627        0.009713   \n",
       "28       10.459732      0.056540         0.168546        0.009329   \n",
       "29        1.614578      0.004004         0.007096        0.000300   \n",
       "30       10.473724      0.060351         0.165792        0.006424   \n",
       "31       10.458482      0.095058         0.168135        0.007231   \n",
       "32        6.351031      0.031394         0.042241        0.005865   \n",
       "33       16.722246      0.263365         0.202473        0.005590   \n",
       "34       16.479936      0.163674         0.201546        0.004686   \n",
       "35        1.514436      0.006573         0.006246        0.007650   \n",
       "36        6.365683      0.028051         0.042184        0.007160   \n",
       "37       26.677653      0.090335         0.379080        0.006523   \n",
       "38       26.607392      0.130199         0.377038        0.007078   \n",
       "39       10.743629      0.053643         0.169809        0.004632   \n",
       "40        6.402036      0.059917         0.037081        0.006765   \n",
       "41        0.170853      0.008464         0.001562        0.004687   \n",
       "42       10.270118      0.131239         0.170939        0.002772   \n",
       "43        6.349277      0.025258         0.034372        0.006250   \n",
       "44        1.520792      0.007140         0.005484        0.007033   \n",
       "45       16.550430      0.272073         0.204773        0.001801   \n",
       "46       11.594746      0.065455         0.179112        0.009984   \n",
       "47       17.757929      0.055073         0.212648        0.006640   \n",
       "48        0.178113      0.010364         0.000000        0.000000   \n",
       "49       11.820202      0.066309         0.177736        0.006524   \n",
       "50        1.493909      0.012209         0.003122        0.006243   \n",
       "51       10.589494      0.109068         0.166401        0.005828   \n",
       "52       17.802411      0.053811         0.207504        0.005664   \n",
       "53       16.680314      0.072946         0.206944        0.005965   \n",
       "54       20.445895      0.129050         0.335978        0.009469   \n",
       "55       17.689830      0.119883         0.212837        0.003909   \n",
       "56       26.677761      0.573716         0.381371        0.020648   \n",
       "57       16.913673      0.439962         0.207221        0.007054   \n",
       "58       22.611394      0.401519         0.351329        0.005883   \n",
       "59        1.609984      0.009884         0.007649        0.006995   \n",
       "60       10.466545      0.157950         0.168857        0.005424   \n",
       "61       10.641372      0.363227         0.165792        0.006424   \n",
       "62        6.199324      0.281303         0.031796        0.001092   \n",
       "63       20.727508      0.400496         0.332787        0.006482   \n",
       "64       11.809794      0.055980         0.178112        0.010364   \n",
       "65        0.138462      0.008490         0.001562        0.004687   \n",
       "66       10.496971      0.075052         0.169609        0.008402   \n",
       "67       12.162654      0.468353         0.177859        0.006379   \n",
       "68       11.846477      0.107379         0.177972        0.005656   \n",
       "69       10.434697      0.089211         0.173383        0.005776   \n",
       "70       10.622375      0.067721         0.169517        0.005240   \n",
       "71       20.621899      0.109678         0.341510        0.008520   \n",
       "72       11.697997      0.047223         0.174580        0.005511   \n",
       "73       28.561059      0.420984         0.380764        0.006100   \n",
       "74       11.840588      0.054972         0.177862        0.006696   \n",
       "75        1.586694      0.006148         0.006596        0.000490   \n",
       "76        0.031283      0.001734         0.000700        0.000458   \n",
       "77       20.628272      0.318612         0.340096        0.003066   \n",
       "78       28.260366      0.465883         0.384251        0.007977   \n",
       "79       20.737981      0.136795         0.337677        0.008308   \n",
       "80       21.778537      0.065320         0.347962        0.005764   \n",
       "81        1.591568      0.004357         0.005497        0.002764   \n",
       "82       16.398293      0.469406         0.206567        0.004098   \n",
       "83        0.225161      0.006946         0.001562        0.004687   \n",
       "84       16.699623      0.269708         0.205486        0.005115   \n",
       "85        1.511976      0.023316         0.009370        0.007650   \n",
       "86        6.255388      0.031432         0.035718        0.006172   \n",
       "87        6.338684      0.103812         0.041271        0.007022   \n",
       "88       12.002461      0.170282         0.176504        0.007244   \n",
       "89       10.435406      0.139609         0.166160        0.006748   \n",
       "90        6.137977      0.029763         0.035988        0.005923   \n",
       "91        7.463664      0.022040         0.040128        0.007387   \n",
       "92        1.481651      0.006145         0.003125        0.006249   \n",
       "93        7.592929      0.234298         0.042577        0.005911   \n",
       "94       16.624000      0.082506         0.208226        0.005805   \n",
       "95       21.918261      0.059086         0.352108        0.007276   \n",
       "96        0.118742      0.007655         0.000000        0.000000   \n",
       "97       16.686289      0.063797         0.204673        0.004687   \n",
       "98        6.006875      0.027010         0.040995        0.006098   \n",
       "99        6.162990      0.062706         0.037079        0.006764   \n",
       "100      16.272473      0.171200         0.205279        0.004547   \n",
       "101      28.144504      0.107874         0.380145        0.009882   \n",
       "102      16.373527      0.145729         0.204847        0.004659   \n",
       "103      22.023809      0.078075         0.343827        0.001230   \n",
       "104      26.723527      0.094741         0.371938        0.004929   \n",
       "105      10.365902      0.040477         0.164555        0.008139   \n",
       "106      17.648201      0.059243         0.213160        0.009940   \n",
       "107       0.146865      0.007654         0.000000        0.000000   \n",
       "108      16.394125      0.073185         0.205983        0.004952   \n",
       "109      17.529424      0.058594         0.213070        0.009976   \n",
       "110       1.481933      0.006930         0.004683        0.007154   \n",
       "111       0.336050      0.007686         0.000000        0.000000   \n",
       "112      17.603315      0.047949         0.216387        0.008596   \n",
       "113      16.532062      0.052886         0.206722        0.006319   \n",
       "114      22.338609      0.388232         0.347016        0.006176   \n",
       "115      16.601015      0.046072         0.210782        0.010074   \n",
       "116       6.565913      0.677105         0.038640        0.007033   \n",
       "117       0.178289      0.031383         0.000800        0.000600   \n",
       "118      11.283880      0.385224         0.173312        0.001047   \n",
       "119       0.402329      0.007207         0.001453        0.000720   \n",
       "120       0.031383      0.000489         0.000700        0.000458   \n",
       "121      12.135676      0.074441         0.178477        0.003758   \n",
       "122       1.517433      0.014843         0.008689        0.003575   \n",
       "123      12.253810      0.366250         0.178333        0.005651   \n",
       "124      16.746793      0.511529         0.204576        0.005909   \n",
       "125      17.398432      0.258976         0.208468        0.006186   \n",
       "126      12.258847      0.726106         0.182136        0.012055   \n",
       "127      30.103281      4.527205         0.341620        0.026096   \n",
       "128       2.489912      0.322433         0.004859        0.004756   \n",
       "129      25.083474      0.909619         0.200606        0.010593   \n",
       "130       2.256063      0.575405         0.009374        0.007654   \n",
       "131       2.949700      0.266497         0.008323        0.007221   \n",
       "132      16.717961      0.220108         0.192011        0.057382   \n",
       "133      26.874849      6.055256         0.341520        0.014047   \n",
       "134      17.808298      0.072345         0.213130        0.006206   \n",
       "135       1.479141      0.014743         0.009368        0.007649   \n",
       "136       1.470770      0.012873         0.004685        0.007156   \n",
       "137       7.612307      0.026254         0.043457        0.006164   \n",
       "138       7.545272      0.082314         0.043132        0.005743   \n",
       "139       6.358336      0.030528         0.037079        0.006764   \n",
       "140      22.206022      0.081089         0.348265        0.006273   \n",
       "141       0.340004      0.007686         0.000800        0.000400   \n",
       "142      29.355811      1.736490         0.390960        0.014817   \n",
       "143      23.304129      0.995861         0.348271        0.004052   \n",
       "144      10.568629      0.237228         0.173741        0.004679   \n",
       "145       0.122207      0.011408         0.001563        0.004688   \n",
       "146       0.148275      0.007099         0.000000        0.000000   \n",
       "147      18.086180      0.658769         0.214433        0.006646   \n",
       "148      27.433562      0.205625         0.382657        0.007949   \n",
       "149       1.531030      0.021288         0.006248        0.007652   \n",
       "\n",
       "                                      param_estimators  \\\n",
       "0    [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "1    [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "2    [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "3    [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "4    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "5    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "6    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "7    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "8    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "9    [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "10   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "11   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "12   [(LDA_bis, LinearDiscriminantAnalysis(shrinkag...   \n",
       "13   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "14   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "15   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "16   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "17   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "18   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "19   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "20   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "21   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "22   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "23   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "24   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "25   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "26   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "27   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "28   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "29   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "30   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "31   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "32   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "33   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "34   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "35   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "36   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "37   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "38   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "39   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "40   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "41   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "42   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "43   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "44   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "45   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "46   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "47   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "48   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "49   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "50   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "51   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "52   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "53   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "54   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "55   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "56   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "57   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "58   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "59   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "60   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "61   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "62   [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "63   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "64   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "65   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "66   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "67   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "68   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "69   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "70   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "71   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "72   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "73   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "74   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "75   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "76   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "77   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "78   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "79   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "80   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "81   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "82   [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "83   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "84   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "85   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "86   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "87   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "88   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "89   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "90   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "91   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "92   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "93   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "94   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "95   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "96   [(LDA_bis, LinearDiscriminantAnalysis(shrinkag...   \n",
       "97   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "98   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "99   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "100  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "101  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "102  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "103  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "104  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "105  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "106  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "107  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "108  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "109  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "110  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "111  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "112  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "113  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "114  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "115  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "116  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "117  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "118  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "119  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "120  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "121  [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "122  [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "123  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "124  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "125  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "126  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "127  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "128  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "129  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "130  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "131  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "132  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "133  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "134  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "135  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "136  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "137  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "138  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "139  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "140  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "141  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "142  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "143  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "144  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "145  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "146  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "147  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "148  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "149  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "1    {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "2    {'estimators': [('LDA', LinearDiscriminantAnal...             -217.0   \n",
       "3    {'estimators': [('RF', RandomForestClassifier(...             -210.0   \n",
       "4    {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "5    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "6    {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "7    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "8    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "9    {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "10   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "11   {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "12   {'estimators': [('LDA_bis', LinearDiscriminant...             -238.0   \n",
       "13   {'estimators': [('LR_bis', LogisticRegression(...             -218.0   \n",
       "14   {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "15   {'estimators': [('RF', RandomForestClassifier(...             -216.0   \n",
       "16   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "17   {'estimators': [('G_NB', GaussianNB(priors=[0....             -222.0   \n",
       "18   {'estimators': [('LDA', LinearDiscriminantAnal...             -225.0   \n",
       "19   {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "20   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "21   {'estimators': [('G_NB', GaussianNB(priors=[0....             -222.0   \n",
       "22   {'estimators': [('G_NB', GaussianNB(priors=[0....             -207.0   \n",
       "23   {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "24   {'estimators': [('G_NB', GaussianNB(priors=[0....             -220.0   \n",
       "25   {'estimators': [('G_NB', GaussianNB(priors=[0....             -235.0   \n",
       "26   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "27   {'estimators': [('LR_bis', LogisticRegression(...             -224.0   \n",
       "28   {'estimators': [('LR_bis', LogisticRegression(...             -226.0   \n",
       "29   {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "30   {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "31   {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "32   {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "33   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "34   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "35   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "36   {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "37   {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "38   {'estimators': [('RF', RandomForestClassifier(...             -214.0   \n",
       "39   {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "40   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "41   {'estimators': [('LR', LogisticRegression(C=1....             -216.0   \n",
       "42   {'estimators': [('G_NB', GaussianNB(priors=[0....             -245.0   \n",
       "43   {'estimators': [('LDA', LinearDiscriminantAnal...             -220.0   \n",
       "44   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "45   {'estimators': [('LR', LogisticRegression(C=1....             -226.0   \n",
       "46   {'estimators': [('G_NB', GaussianNB(priors=[0....             -225.0   \n",
       "47   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "48   {'estimators': [('LR', LogisticRegression(C=1....             -216.0   \n",
       "49   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -220.0   \n",
       "50   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "51   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "52   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "53   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "54   {'estimators': [('RF', RandomForestClassifier(...             -210.0   \n",
       "55   {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "56   {'estimators': [('RF', RandomForestClassifier(...             -212.0   \n",
       "57   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "58   {'estimators': [('LR', LogisticRegression(C=1....             -228.0   \n",
       "59   {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "60   {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "61   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "62   {'estimators': [('ADA_1', AdaBoostClassifier(b...             -294.0   \n",
       "63   {'estimators': [('RF', RandomForestClassifier(...             -225.0   \n",
       "64   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "65   {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "66   {'estimators': [('LR_bis', LogisticRegression(...             -226.0   \n",
       "67   {'estimators': [('LDA', LinearDiscriminantAnal...             -229.0   \n",
       "68   {'estimators': [('G_NB', GaussianNB(priors=[0....             -223.0   \n",
       "69   {'estimators': [('G_NB', GaussianNB(priors=[0....             -223.0   \n",
       "70   {'estimators': [('LR', LogisticRegression(C=1....             -218.0   \n",
       "71   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "72   {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "73   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "74   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -222.0   \n",
       "75   {'estimators': [('LDA', LinearDiscriminantAnal...             -217.0   \n",
       "76   {'estimators': [('G_NB', GaussianNB(priors=[0....             -236.0   \n",
       "77   {'estimators': [('G_NB', GaussianNB(priors=[0....             -211.0   \n",
       "78   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "79   {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "80   {'estimators': [('G_NB', GaussianNB(priors=[0....             -211.0   \n",
       "81   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "82   {'estimators': [('ADA_1', AdaBoostClassifier(b...             -246.0   \n",
       "83   {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "84   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "85   {'estimators': [('LR', LogisticRegression(C=1....             -218.0   \n",
       "86   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "87   {'estimators': [('LDA', LinearDiscriminantAnal...             -216.0   \n",
       "88   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "89   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "90   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "91   {'estimators': [('LDA', LinearDiscriminantAnal...             -220.0   \n",
       "92   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "93   {'estimators': [('G_NB', GaussianNB(priors=[0....             -207.0   \n",
       "94   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "95   {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "96   {'estimators': [('LDA_bis', LinearDiscriminant...             -217.0   \n",
       "97   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "98   {'estimators': [('G_NB', GaussianNB(priors=[0....             -232.0   \n",
       "99   {'estimators': [('G_NB', GaussianNB(priors=[0....             -217.0   \n",
       "100  {'estimators': [('G_NB', GaussianNB(priors=[0....             -214.0   \n",
       "101  {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "102  {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "103  {'estimators': [('RF', RandomForestClassifier(...             -215.0   \n",
       "104  {'estimators': [('LDA', LinearDiscriminantAnal...             -225.0   \n",
       "105  {'estimators': [('LDA', LinearDiscriminantAnal...             -230.0   \n",
       "106  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "107  {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "108  {'estimators': [('LDA', LinearDiscriminantAnal...             -226.0   \n",
       "109  {'estimators': [('RF', RandomForestClassifier(...             -216.0   \n",
       "110  {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "111  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "112  {'estimators': [('G_NB', GaussianNB(priors=[0....             -219.0   \n",
       "113  {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "114  {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "115  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "116  {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "117  {'estimators': [('G_NB', GaussianNB(priors=[0....             -217.0   \n",
       "118  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "119  {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "120  {'estimators': [('G_NB', GaussianNB(priors=[0....             -236.0   \n",
       "121  {'estimators': [('ADA_2', AdaBoostClassifier(b...             -221.0   \n",
       "122  {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "123  {'estimators': [('G_NB', GaussianNB(priors=[0....             -219.0   \n",
       "124  {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "125  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -224.0   \n",
       "126  {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "127  {'estimators': [('RF', RandomForestClassifier(...             -214.0   \n",
       "128  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "129  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -226.0   \n",
       "130  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "131  {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "132  {'estimators': [('LR', LogisticRegression(C=1....             -227.0   \n",
       "133  {'estimators': [('RF', RandomForestClassifier(...             -221.0   \n",
       "134  {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "135  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "136  {'estimators': [('LR', LogisticRegression(C=1....             -219.0   \n",
       "137  {'estimators': [('LR', LogisticRegression(C=1....             -219.0   \n",
       "138  {'estimators': [('G_NB', GaussianNB(priors=[0....             -225.0   \n",
       "139  {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "140  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "141  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "142  {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "143  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "144  {'estimators': [('G_NB', GaussianNB(priors=[0....             -216.0   \n",
       "145  {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "146  {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "147  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -226.0   \n",
       "148  {'estimators': [('LDA', LinearDiscriminantAnal...             -231.0   \n",
       "149  {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               -135.0             -180.0             -188.0   \n",
       "1               -126.0             -215.0             -195.0   \n",
       "2               -132.0             -184.0             -179.0   \n",
       "3               -143.0             -190.0             -186.0   \n",
       "4               -130.0             -185.0             -176.0   \n",
       "5               -135.0             -176.0             -176.0   \n",
       "6               -145.0             -179.0             -182.0   \n",
       "7               -131.0             -182.0             -181.0   \n",
       "8               -135.0             -176.0             -176.0   \n",
       "9               -126.0             -215.0             -195.0   \n",
       "10              -128.0             -184.0             -180.0   \n",
       "11              -136.0             -175.0             -182.0   \n",
       "12              -138.0             -209.0             -188.0   \n",
       "13              -134.0             -199.0             -191.0   \n",
       "14              -130.0             -181.0             -179.0   \n",
       "15              -138.0             -188.0             -190.0   \n",
       "16              -129.0             -177.0             -175.0   \n",
       "17              -143.0             -185.0             -184.0   \n",
       "18              -141.0             -181.0             -187.0   \n",
       "19              -127.0             -179.0             -181.0   \n",
       "20              -141.0             -199.0             -184.0   \n",
       "21              -141.0             -181.0             -181.0   \n",
       "22              -127.0             -198.0             -185.0   \n",
       "23              -127.0             -179.0             -181.0   \n",
       "24              -126.0             -216.0             -201.0   \n",
       "25              -140.0             -200.0             -175.0   \n",
       "26              -140.0             -186.0             -186.0   \n",
       "27              -133.0             -200.0             -193.0   \n",
       "28              -132.0             -200.0             -185.0   \n",
       "29              -129.0             -197.0             -172.0   \n",
       "30              -135.0             -192.0             -180.0   \n",
       "31              -135.0             -192.0             -180.0   \n",
       "32              -127.0             -180.0             -178.0   \n",
       "33              -135.0             -185.0             -183.0   \n",
       "34              -138.0             -186.0             -187.0   \n",
       "35              -133.0             -174.0             -178.0   \n",
       "36              -127.0             -180.0             -180.0   \n",
       "37              -144.0             -171.0             -182.0   \n",
       "38              -135.0             -187.0             -180.0   \n",
       "39              -138.0             -181.0             -176.0   \n",
       "40              -130.0             -178.0             -176.0   \n",
       "41              -133.0             -184.0             -182.0   \n",
       "42              -133.0             -209.0             -196.0   \n",
       "43              -133.0             -184.0             -177.0   \n",
       "44              -133.0             -174.0             -178.0   \n",
       "45              -143.0             -184.0             -187.0   \n",
       "46              -142.0             -196.0             -181.0   \n",
       "47              -135.0             -171.0             -181.0   \n",
       "48              -133.0             -184.0             -182.0   \n",
       "49              -137.0             -197.0             -175.0   \n",
       "50              -136.0             -177.0             -183.0   \n",
       "51              -136.0             -185.0             -184.0   \n",
       "52              -143.0             -179.0             -170.0   \n",
       "53              -139.0             -180.0             -180.0   \n",
       "54              -144.0             -196.0             -188.0   \n",
       "55              -135.0             -176.0             -181.0   \n",
       "56              -142.0             -196.0             -186.0   \n",
       "57              -142.0             -168.0             -183.0   \n",
       "58              -143.0             -179.0             -175.0   \n",
       "59              -132.0             -183.0             -179.0   \n",
       "60              -137.0             -181.0             -183.0   \n",
       "61              -135.0             -180.0             -188.0   \n",
       "62              -294.0             -294.0             -300.0   \n",
       "63              -142.0             -195.0             -188.0   \n",
       "64              -131.0             -177.0             -177.0   \n",
       "65              -126.0             -215.0             -201.0   \n",
       "66              -132.0             -200.0             -185.0   \n",
       "67              -144.0             -184.0             -186.0   \n",
       "68              -142.0             -194.0             -188.0   \n",
       "69              -136.0             -205.0             -194.0   \n",
       "70              -137.0             -180.0             -176.0   \n",
       "71              -135.0             -190.0             -180.0   \n",
       "72              -136.0             -175.0             -182.0   \n",
       "73              -149.0             -168.0             -175.0   \n",
       "74              -137.0             -197.0             -178.0   \n",
       "75              -130.0             -181.0             -179.0   \n",
       "76              -190.0             -213.0             -209.0   \n",
       "77              -140.0             -196.0             -189.0   \n",
       "78              -149.0             -168.0             -175.0   \n",
       "79              -142.0             -186.0             -193.0   \n",
       "80              -143.0             -197.0             -184.0   \n",
       "81              -132.0             -187.0             -183.0   \n",
       "82              -143.0             -212.0             -185.0   \n",
       "83              -126.0             -215.0             -195.0   \n",
       "84              -137.0             -183.0             -192.0   \n",
       "85              -134.0             -180.0             -181.0   \n",
       "86              -136.0             -192.0             -194.0   \n",
       "87              -134.0             -184.0             -178.0   \n",
       "88              -127.0             -180.0             -176.0   \n",
       "89              -130.0             -182.0             -180.0   \n",
       "90              -134.0             -190.0             -192.0   \n",
       "91              -130.0             -180.0             -180.0   \n",
       "92              -141.0             -199.0             -184.0   \n",
       "93              -127.0             -198.0             -185.0   \n",
       "94              -134.0             -185.0             -179.0   \n",
       "95              -138.0             -185.0             -177.0   \n",
       "96              -137.0             -211.0             -202.0   \n",
       "97              -139.0             -180.0             -180.0   \n",
       "98              -185.0             -213.0             -209.0   \n",
       "99              -129.0             -202.0             -191.0   \n",
       "100             -141.0             -193.0             -189.0   \n",
       "101             -144.0             -189.0             -176.0   \n",
       "102             -134.0             -186.0             -179.0   \n",
       "103             -136.0             -172.0             -182.0   \n",
       "104             -132.0             -183.0             -194.0   \n",
       "105             -138.0             -188.0             -187.0   \n",
       "106             -135.0             -176.0             -181.0   \n",
       "107             -130.0             -180.0             -182.0   \n",
       "108             -137.0             -176.0             -183.0   \n",
       "109             -142.0             -180.0             -181.0   \n",
       "110             -129.0             -197.0             -172.0   \n",
       "111             -127.0             -179.0             -178.0   \n",
       "112             -137.0             -197.0             -183.0   \n",
       "113             -139.0             -185.0             -187.0   \n",
       "114             -143.0             -176.0             -171.0   \n",
       "115             -139.0             -175.0             -181.0   \n",
       "116             -123.0             -182.0             -188.0   \n",
       "117             -136.0             -212.0             -200.0   \n",
       "118             -125.0             -184.0             -180.0   \n",
       "119             -133.0             -184.0             -177.0   \n",
       "120             -190.0             -213.0             -209.0   \n",
       "121             -136.0             -193.0             -179.0   \n",
       "122             -141.0             -199.0             -184.0   \n",
       "123             -137.0             -197.0             -178.0   \n",
       "124             -130.0             -182.0             -180.0   \n",
       "125             -144.0             -196.0             -188.0   \n",
       "126             -152.0             -180.0             -183.0   \n",
       "127             -135.0             -187.0             -180.0   \n",
       "128             -135.0             -182.0             -187.0   \n",
       "129             -145.0             -197.0             -185.0   \n",
       "130             -128.0             -176.0             -174.0   \n",
       "131             -130.0             -181.0             -179.0   \n",
       "132             -136.0             -172.0             -178.0   \n",
       "133             -142.0             -187.0             -186.0   \n",
       "134             -134.0             -176.0             -176.0   \n",
       "135             -135.0             -182.0             -187.0   \n",
       "136             -137.0             -177.0             -184.0   \n",
       "137             -134.0             -174.0             -179.0   \n",
       "138             -142.0             -191.0             -188.0   \n",
       "139             -127.0             -180.0             -179.0   \n",
       "140             -144.0             -167.0             -172.0   \n",
       "141             -127.0             -179.0             -178.0   \n",
       "142             -148.0             -166.0             -175.0   \n",
       "143             -144.0             -183.0             -170.0   \n",
       "144             -141.0             -193.0             -189.0   \n",
       "145             -131.0             -187.0             -184.0   \n",
       "146             -123.0             -182.0             -187.0   \n",
       "147             -145.0             -197.0             -185.0   \n",
       "148             -140.0             -189.0             -194.0   \n",
       "149             -128.0             -181.0             -185.0   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0               -177.0             -162.0             -179.0   \n",
       "1               -166.0             -165.0             -186.0   \n",
       "2               -171.0             -180.0             -184.0   \n",
       "3               -175.0             -161.0             -180.0   \n",
       "4               -181.0             -170.0             -180.0   \n",
       "5               -179.0             -165.0             -182.0   \n",
       "6               -176.0             -159.0             -181.0   \n",
       "7               -182.0             -161.0             -173.0   \n",
       "8               -179.0             -165.0             -182.0   \n",
       "9               -166.0             -165.0             -186.0   \n",
       "10              -181.0             -168.0             -177.0   \n",
       "11              -171.0             -159.0             -179.0   \n",
       "12              -188.0             -162.0             -184.0   \n",
       "13              -166.0             -173.0             -174.0   \n",
       "14              -173.0             -172.0             -178.0   \n",
       "15              -173.0             -163.0             -180.0   \n",
       "16              -176.0             -169.0             -180.0   \n",
       "17              -170.0             -162.0             -181.0   \n",
       "18              -173.0             -165.0             -175.0   \n",
       "19              -174.0             -172.0             -180.0   \n",
       "20              -182.0             -172.0             -174.0   \n",
       "21              -165.0             -166.0             -180.0   \n",
       "22              -184.0             -171.0             -176.0   \n",
       "23              -176.0             -171.0             -175.0   \n",
       "24              -165.0             -165.0             -186.0   \n",
       "25              -188.0             -163.0             -179.0   \n",
       "26              -173.0             -165.0             -181.0   \n",
       "27              -170.0             -173.0             -175.0   \n",
       "28              -168.0             -174.0             -176.0   \n",
       "29              -169.0             -169.0             -184.0   \n",
       "30              -172.0             -160.0             -184.0   \n",
       "31              -172.0             -160.0             -184.0   \n",
       "32              -173.0             -168.0             -178.0   \n",
       "33              -176.0             -164.0             -181.0   \n",
       "34              -178.0             -160.0             -176.0   \n",
       "35              -177.0             -174.0             -186.0   \n",
       "36              -174.0             -169.0             -178.0   \n",
       "37              -174.0             -158.0             -180.0   \n",
       "38              -172.0             -160.0             -184.0   \n",
       "39              -177.0             -157.0             -179.0   \n",
       "40              -175.0             -170.0             -181.0   \n",
       "41              -169.0             -172.0             -184.0   \n",
       "42              -192.0             -169.0             -177.0   \n",
       "43              -175.0             -169.0             -177.0   \n",
       "44              -177.0             -174.0             -186.0   \n",
       "45              -182.0             -160.0             -178.0   \n",
       "46              -186.0             -171.0             -177.0   \n",
       "47              -171.0             -164.0             -187.0   \n",
       "48              -169.0             -172.0             -184.0   \n",
       "49              -171.0             -180.0             -178.0   \n",
       "50              -166.0             -170.0             -186.0   \n",
       "51              -177.0             -170.0             -183.0   \n",
       "52              -167.0             -161.0             -181.0   \n",
       "53              -176.0             -156.0             -177.0   \n",
       "54              -180.0             -162.0             -180.0   \n",
       "55              -171.0             -163.0             -185.0   \n",
       "56              -174.0             -169.0             -181.0   \n",
       "57              -168.0             -160.0             -181.0   \n",
       "58              -177.0             -161.0             -178.0   \n",
       "59              -172.0             -169.0             -185.0   \n",
       "60              -171.0             -164.0             -183.0   \n",
       "61              -177.0             -162.0             -179.0   \n",
       "62              -294.0             -294.0             -294.0   \n",
       "63              -183.0             -162.0             -179.0   \n",
       "64              -179.0             -165.0             -183.0   \n",
       "65              -168.0             -165.0             -186.0   \n",
       "66              -168.0             -174.0             -176.0   \n",
       "67              -174.0             -160.0             -178.0   \n",
       "68              -173.0             -181.0             -178.0   \n",
       "69              -180.0             -174.0             -183.0   \n",
       "70              -177.0             -157.0             -179.0   \n",
       "71              -166.0             -164.0             -181.0   \n",
       "72              -171.0             -159.0             -179.0   \n",
       "73              -167.0             -162.0             -185.0   \n",
       "74              -171.0             -183.0             -178.0   \n",
       "75              -177.0             -171.0             -178.0   \n",
       "76              -197.0             -200.0             -208.0   \n",
       "77              -180.0             -162.0             -180.0   \n",
       "78              -167.0             -162.0             -185.0   \n",
       "79              -174.0             -166.0             -183.0   \n",
       "80              -175.0             -161.0             -180.0   \n",
       "81              -165.0             -170.0             -183.0   \n",
       "82              -194.0             -165.0             -179.0   \n",
       "83              -166.0             -165.0             -186.0   \n",
       "84              -167.0             -159.0             -184.0   \n",
       "85              -179.0             -169.0             -186.0   \n",
       "86              -184.0             -164.0             -185.0   \n",
       "87              -171.0             -170.0             -181.0   \n",
       "88              -178.0             -174.0             -183.0   \n",
       "89              -177.0             -167.0             -175.0   \n",
       "90              -169.0             -162.0             -184.0   \n",
       "91              -170.0             -167.0             -187.0   \n",
       "92              -182.0             -172.0             -174.0   \n",
       "93              -184.0             -171.0             -176.0   \n",
       "94              -172.0             -156.0             -177.0   \n",
       "95              -166.0             -164.0             -182.0   \n",
       "96              -178.0             -167.0             -183.0   \n",
       "97              -176.0             -156.0             -177.0   \n",
       "98              -197.0             -200.0             -198.0   \n",
       "99              -182.0             -172.0             -179.0   \n",
       "100             -172.0             -163.0             -180.0   \n",
       "101             -167.0             -161.0             -180.0   \n",
       "102             -172.0             -161.0             -175.0   \n",
       "103             -171.0             -159.0             -179.0   \n",
       "104             -165.0             -165.0             -179.0   \n",
       "105             -167.0             -162.0             -176.0   \n",
       "106             -171.0             -163.0             -185.0   \n",
       "107             -179.0             -172.0             -182.0   \n",
       "108             -167.0             -159.0             -183.0   \n",
       "109             -175.0             -162.0             -179.0   \n",
       "110             -168.0             -169.0             -184.0   \n",
       "111             -174.0             -169.0             -177.0   \n",
       "112             -171.0             -175.0             -178.0   \n",
       "113             -173.0             -166.0             -176.0   \n",
       "114             -177.0             -161.0             -182.0   \n",
       "115             -177.0             -156.0             -178.0   \n",
       "116             -172.0             -163.0             -187.0   \n",
       "117             -178.0             -177.0             -181.0   \n",
       "118             -175.0             -170.0             -173.0   \n",
       "119             -175.0             -168.0             -177.0   \n",
       "120             -197.0             -200.0             -208.0   \n",
       "121             -172.0             -184.0             -176.0   \n",
       "122             -182.0             -172.0             -174.0   \n",
       "123             -171.0             -175.0             -178.0   \n",
       "124             -177.0             -167.0             -176.0   \n",
       "125             -188.0             -184.0             -176.0   \n",
       "126             -169.0             -165.0             -182.0   \n",
       "127             -172.0             -160.0             -184.0   \n",
       "128             -170.0             -170.0             -191.0   \n",
       "129             -191.0             -174.0             -177.0   \n",
       "130             -175.0             -171.0             -181.0   \n",
       "131             -173.0             -172.0             -178.0   \n",
       "132             -174.0             -157.0             -180.0   \n",
       "133             -173.0             -167.0             -181.0   \n",
       "134             -179.0             -165.0             -182.0   \n",
       "135             -170.0             -170.0             -191.0   \n",
       "136             -167.0             -164.0             -182.0   \n",
       "137             -172.0             -170.0             -185.0   \n",
       "138             -189.0             -178.0             -184.0   \n",
       "139             -173.0             -168.0             -178.0   \n",
       "140             -178.0             -161.0             -184.0   \n",
       "141             -174.0             -169.0             -177.0   \n",
       "142             -174.0             -161.0             -185.0   \n",
       "143             -182.0             -165.0             -181.0   \n",
       "144             -172.0             -163.0             -180.0   \n",
       "145             -174.0             -165.0             -189.0   \n",
       "146             -171.0             -164.0             -187.0   \n",
       "147             -191.0             -174.0             -177.0   \n",
       "148             -170.0             -166.0             -180.0   \n",
       "149             -168.0             -168.0             -190.0   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0               -177.0             -175.0             -164.0           -175.9   \n",
       "1               -163.0             -185.0             -155.0           -177.7   \n",
       "2               -170.0             -171.0             -162.0           -175.0   \n",
       "3               -166.0             -180.0             -163.0           -175.4   \n",
       "4               -173.0             -179.0             -160.0           -175.6   \n",
       "5               -176.0             -179.0             -158.0           -174.7   \n",
       "6               -171.0             -183.0             -162.0           -176.3   \n",
       "7               -175.0             -176.0             -159.0           -174.1   \n",
       "8               -176.0             -179.0             -158.0           -174.7   \n",
       "9               -163.0             -185.0             -155.0           -177.7   \n",
       "10              -177.0             -179.0             -167.0           -176.3   \n",
       "11              -161.0             -180.0             -161.0           -172.3   \n",
       "12              -173.0             -181.0             -161.0           -182.2   \n",
       "13              -162.0             -187.0             -166.0           -177.0   \n",
       "14              -182.0             -176.0             -167.0           -175.6   \n",
       "15              -168.0             -181.0             -165.0           -176.2   \n",
       "16              -178.0             -180.0             -160.0           -174.5   \n",
       "17              -161.0             -180.0             -160.0           -174.8   \n",
       "18              -173.0             -177.0             -167.0           -176.4   \n",
       "19              -175.0             -177.0             -158.0           -174.3   \n",
       "20              -171.0             -180.0             -162.0           -177.2   \n",
       "21              -164.0             -181.0             -160.0           -174.1   \n",
       "22              -171.0             -182.0             -161.0           -176.2   \n",
       "23              -175.0             -176.0             -158.0           -173.8   \n",
       "24              -163.0             -185.0             -155.0           -178.2   \n",
       "25              -171.0             -179.0             -173.0           -180.3   \n",
       "26              -167.0             -182.0             -157.0           -176.4   \n",
       "27              -165.0             -181.0             -165.0           -177.9   \n",
       "28              -162.0             -181.0             -161.0           -176.5   \n",
       "29              -172.0             -185.0             -153.0           -175.1   \n",
       "30              -155.0             -181.0             -160.0           -174.3   \n",
       "31              -155.0             -181.0             -160.0           -174.3   \n",
       "32              -177.0             -176.0             -164.0           -174.6   \n",
       "33              -178.0             -177.0             -164.0           -176.6   \n",
       "34              -169.0             -183.0             -158.0           -175.9   \n",
       "35              -177.0             -183.0             -169.0           -176.8   \n",
       "36              -177.0             -176.0             -168.0           -175.4   \n",
       "37              -165.0             -185.0             -164.0           -174.6   \n",
       "38              -158.0             -181.0             -160.0           -173.1   \n",
       "39              -164.0             -184.0             -164.0           -174.3   \n",
       "40              -178.0             -183.0             -159.0           -175.2   \n",
       "41              -178.0             -182.0             -169.0           -176.9   \n",
       "42              -184.0             -187.0             -169.0           -186.1   \n",
       "43              -177.0             -175.0             -158.0           -174.5   \n",
       "44              -177.0             -183.0             -169.0           -176.8   \n",
       "45              -171.0             -183.0             -162.0           -177.6   \n",
       "46              -158.0             -182.0             -165.0           -178.3   \n",
       "47              -171.0             -188.0             -170.0           -176.5   \n",
       "48              -178.0             -182.0             -169.0           -176.9   \n",
       "49              -169.0             -186.0             -159.0           -177.2   \n",
       "50              -178.0             -186.0             -169.0           -176.8   \n",
       "51              -179.0             -177.0             -161.0           -177.4   \n",
       "52              -166.0             -179.0             -162.0           -173.1   \n",
       "53              -164.0             -183.0             -160.0           -173.9   \n",
       "54              -168.0             -181.0             -163.0           -177.2   \n",
       "55              -171.0             -188.0             -170.0           -176.4   \n",
       "56              -165.0             -182.0             -170.0           -177.7   \n",
       "57              -167.0             -186.0             -166.0           -174.3   \n",
       "58              -163.0             -183.0             -158.0           -174.5   \n",
       "59              -171.0             -177.0             -162.0           -174.8   \n",
       "60              -167.0             -188.0             -170.0           -176.8   \n",
       "61              -177.0             -175.0             -164.0           -175.9   \n",
       "62              -294.0             -294.0             -294.0           -294.6   \n",
       "63              -161.0             -182.0             -156.0           -177.3   \n",
       "64              -178.0             -181.0             -160.0           -175.2   \n",
       "65              -163.0             -185.0             -155.0           -178.5   \n",
       "66              -162.0             -181.0             -161.0           -176.5   \n",
       "67              -171.0             -182.0             -157.0           -176.5   \n",
       "68              -167.0             -184.0             -165.0           -179.5   \n",
       "69              -170.0             -181.0             -161.0           -180.7   \n",
       "70              -164.0             -183.0             -161.0           -173.2   \n",
       "71              -164.0             -181.0             -162.0           -175.0   \n",
       "72              -161.0             -180.0             -161.0           -172.3   \n",
       "73              -169.0             -185.0             -164.0           -174.8   \n",
       "74              -170.0             -183.0             -164.0           -178.3   \n",
       "75              -180.0             -176.0             -162.0           -175.1   \n",
       "76              -207.0             -179.0             -192.0           -203.1   \n",
       "77              -168.0             -181.0             -163.0           -177.0   \n",
       "78              -169.0             -185.0             -164.0           -174.8   \n",
       "79              -177.0             -178.0             -159.0           -178.6   \n",
       "80              -166.0             -180.0             -168.0           -176.5   \n",
       "81              -170.0             -181.0             -159.0           -175.1   \n",
       "82              -173.0             -185.0             -175.0           -185.7   \n",
       "83              -163.0             -185.0             -155.0           -177.7   \n",
       "84              -172.0             -176.0             -169.0           -176.1   \n",
       "85              -178.0             -183.0             -169.0           -177.7   \n",
       "86              -172.0             -178.0             -159.0           -178.5   \n",
       "87              -172.0             -174.0             -162.0           -174.2   \n",
       "88              -176.0             -182.0             -158.0           -175.5   \n",
       "89              -175.0             -180.0             -160.0           -174.7   \n",
       "90              -173.0             -179.0             -158.0           -176.2   \n",
       "91              -178.0             -175.0             -158.0           -174.5   \n",
       "92              -171.0             -180.0             -162.0           -177.2   \n",
       "93              -171.0             -182.0             -161.0           -176.2   \n",
       "94              -161.0             -179.0             -161.0           -172.7   \n",
       "95              -165.0             -181.0             -160.0           -174.6   \n",
       "96              -185.0             -181.0             -158.0           -181.9   \n",
       "97              -164.0             -183.0             -160.0           -173.9   \n",
       "98              -208.0             -180.0             -192.0           -201.4   \n",
       "99              -179.0             -183.0             -166.0           -180.0   \n",
       "100             -172.0             -181.0             -169.0           -177.4   \n",
       "101             -165.0             -184.0             -159.0           -174.8   \n",
       "102             -156.0             -181.0             -161.0           -172.9   \n",
       "103             -162.0             -182.0             -161.0           -171.9   \n",
       "104             -169.0             -179.0             -161.0           -175.2   \n",
       "105             -173.0             -180.0             -169.0           -177.0   \n",
       "106             -171.0             -188.0             -170.0           -176.4   \n",
       "107             -174.0             -183.0             -168.0           -177.2   \n",
       "108             -164.0             -186.0             -168.0           -174.9   \n",
       "109             -169.0             -180.0             -164.0           -174.8   \n",
       "110             -172.0             -186.0             -153.0           -175.1   \n",
       "111             -177.0             -176.0             -169.0           -174.6   \n",
       "112             -169.0             -183.0             -159.0           -177.1   \n",
       "113             -168.0             -182.0             -158.0           -176.2   \n",
       "114             -166.0             -183.0             -161.0           -174.3   \n",
       "115             -164.0             -183.0             -162.0           -173.9   \n",
       "116             -174.0             -175.0             -162.0           -174.7   \n",
       "117             -193.0             -183.0             -161.0           -183.8   \n",
       "118             -176.0             -176.0             -159.0           -173.8   \n",
       "119             -177.0             -175.0             -158.0           -174.2   \n",
       "120             -207.0             -179.0             -192.0           -203.1   \n",
       "121             -170.0             -184.0             -158.0           -177.3   \n",
       "122             -171.0             -180.0             -162.0           -177.2   \n",
       "123             -169.0             -183.0             -159.0           -176.6   \n",
       "124             -175.0             -180.0             -160.0           -174.8   \n",
       "125             -171.0             -182.0             -158.0           -181.1   \n",
       "126             -172.0             -184.0             -168.0           -177.4   \n",
       "127             -158.0             -181.0             -160.0           -173.1   \n",
       "128             -179.0             -181.0             -165.0           -178.4   \n",
       "129             -156.0             -182.0             -159.0           -179.2   \n",
       "130             -179.0             -177.0             -169.0           -175.0   \n",
       "131             -182.0             -176.0             -167.0           -175.6   \n",
       "132             -165.0             -180.0             -166.0           -173.5   \n",
       "133             -161.0             -180.0             -170.0           -176.8   \n",
       "134             -176.0             -179.0             -158.0           -174.6   \n",
       "135             -179.0             -181.0             -165.0           -178.4   \n",
       "136             -178.0             -186.0             -169.0           -176.3   \n",
       "137             -183.0             -184.0             -169.0           -176.9   \n",
       "138             -184.0             -183.0             -162.0           -182.6   \n",
       "139             -177.0             -175.0             -169.0           -175.1   \n",
       "140             -167.0             -184.0             -162.0           -174.3   \n",
       "141             -177.0             -176.0             -169.0           -174.6   \n",
       "142             -167.0             -185.0             -164.0           -174.8   \n",
       "143             -176.0             -183.0             -157.0           -176.5   \n",
       "144             -173.0             -182.0             -167.0           -177.6   \n",
       "145             -175.0             -176.0             -165.0           -176.8   \n",
       "146             -174.0             -175.0             -162.0           -174.6   \n",
       "147             -156.0             -182.0             -159.0           -179.2   \n",
       "148             -170.0             -180.0             -161.0           -178.1   \n",
       "149             -178.0             -176.0             -161.0           -175.8   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "0         20.757890               69  \n",
       "1         27.184738              119  \n",
       "2         20.104726               51  \n",
       "3         17.505428               62  \n",
       "4         21.592591               65  \n",
       "5         20.464848               38  \n",
       "6         19.975235               78  \n",
       "7         21.528818               16  \n",
       "8         20.464848               38  \n",
       "9         27.184738              119  \n",
       "10        21.633539               78  \n",
       "11        20.342320                2  \n",
       "12        26.076043              142  \n",
       "13        21.913466              102  \n",
       "14        20.145471               65  \n",
       "15        19.461757               73  \n",
       "16        21.341275               27  \n",
       "17        20.222759               42  \n",
       "18        19.980991               81  \n",
       "19        21.688937               20  \n",
       "20        17.485994              106  \n",
       "21        20.042205               16  \n",
       "22        20.740299               73  \n",
       "23        21.618511               11  \n",
       "24        27.650678              126  \n",
       "25        23.524668              138  \n",
       "26        21.744884               81  \n",
       "27        23.010650              124  \n",
       "28        23.673825               85  \n",
       "29        23.389955               54  \n",
       "30        22.991520               20  \n",
       "31        22.991520               20  \n",
       "32        22.415173               31  \n",
       "33        20.819222               91  \n",
       "34        21.565945               69  \n",
       "35        19.327700               93  \n",
       "36        22.253988               62  \n",
       "37        19.910801               31  \n",
       "38        20.295073                6  \n",
       "39        20.909567               20  \n",
       "40        21.525798               59  \n",
       "41        19.387883               99  \n",
       "42        27.602355              146  \n",
       "43        20.504877               27  \n",
       "44        19.327700               93  \n",
       "45        20.771134              117  \n",
       "46        21.298122              127  \n",
       "47        21.964744               85  \n",
       "48        19.387883               99  \n",
       "49        20.898804              106  \n",
       "50        19.270703               93  \n",
       "51        20.401961              114  \n",
       "52        19.735501                6  \n",
       "53        21.238879               13  \n",
       "54        17.876241              106  \n",
       "55        21.185844               81  \n",
       "56        17.872045              119  \n",
       "57        19.955200               20  \n",
       "58        21.336588               27  \n",
       "59        20.277081               42  \n",
       "60        20.908372               93  \n",
       "61        20.757890               69  \n",
       "62         1.800000              150  \n",
       "63        22.271282              112  \n",
       "64        21.235819               59  \n",
       "65        27.539971              131  \n",
       "66        23.673825               85  \n",
       "67        21.634463               85  \n",
       "68        20.036217              136  \n",
       "69        22.601106              139  \n",
       "70        20.028979                9  \n",
       "71        22.622997               51  \n",
       "72        20.342320                2  \n",
       "73        19.275892               42  \n",
       "74        20.823304              127  \n",
       "75        20.161597               54  \n",
       "76        14.754321              148  \n",
       "77        18.883856              102  \n",
       "78        19.275892               42  \n",
       "79        21.513717              133  \n",
       "80        17.995833               85  \n",
       "81        21.630765               54  \n",
       "82        26.400947              145  \n",
       "83        27.184738              119  \n",
       "84        21.073443               72  \n",
       "85        19.493845              119  \n",
       "86        21.772689              131  \n",
       "87        19.239543               18  \n",
       "88        22.037468               64  \n",
       "89        21.288729               38  \n",
       "90        22.116962               73  \n",
       "91        21.513949               27  \n",
       "92        17.485994              106  \n",
       "93        20.740299               73  \n",
       "94        21.977488                4  \n",
       "95        22.118770               31  \n",
       "96        23.062741              141  \n",
       "97        21.238879               13  \n",
       "98        14.214078              147  \n",
       "99        22.022716              137  \n",
       "100       18.434750              114  \n",
       "101       20.453850               42  \n",
       "102       22.300000                5  \n",
       "103       19.454819                1  \n",
       "104       22.885803               59  \n",
       "105       22.284524              102  \n",
       "106       21.185844               81  \n",
       "107       21.089334              106  \n",
       "108       21.874414               50  \n",
       "109       17.881834               42  \n",
       "110       23.462523               54  \n",
       "111       21.058015               31  \n",
       "112       20.651634              105  \n",
       "113       21.926240               73  \n",
       "114       19.824480               20  \n",
       "115       21.092416               13  \n",
       "116       23.460818               38  \n",
       "117       22.666275              144  \n",
       "118       22.144074               11  \n",
       "119       20.093780               18  \n",
       "120       14.754321              148  \n",
       "121       21.000238              112  \n",
       "122       17.485994              106  \n",
       "123       20.563074               91  \n",
       "124       21.292252               42  \n",
       "125       20.505853              140  \n",
       "126       16.794047              114  \n",
       "127       20.295073                6  \n",
       "128       21.298826              129  \n",
       "129       21.989998              134  \n",
       "130       20.842265               51  \n",
       "131       20.145471               65  \n",
       "132       21.855205               10  \n",
       "133       19.461757               93  \n",
       "134       20.660106               31  \n",
       "135       21.298826              129  \n",
       "136       19.616575               78  \n",
       "137       19.781052               99  \n",
       "138       20.090794              143  \n",
       "139       22.241628               54  \n",
       "140       20.075109               20  \n",
       "141       21.058015               31  \n",
       "142       19.223943               42  \n",
       "143       20.006249               85  \n",
       "144       18.932512              117  \n",
       "145       21.761434               93  \n",
       "146       23.371778               31  \n",
       "147       21.989998              134  \n",
       "148       22.801096              125  \n",
       "149       22.741152               68  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "df = train_enh_stded\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "params={#\"cv\":[5,7,10,12],\n",
    "        #\"final_estimator\": [LogisticRegression(class_weight= {0:1,1:i},max_iter=2000,C=1.2000000000000004) \\\n",
    "        #                    for i in np.arange(3.5,6.5,0.5) ]\n",
    "        #\"final_estimator\": [LogisticRegression(class_weight= {0:1,1:4.5},max_iter=2000,C=i) \\\n",
    "        #                    for i in np.arange(0.7,1.5,0.1) ]\n",
    "        \"estimators\": [[i for i in estimators if np.random.rand() > 0.6] for i in range(150)]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(StackingClassifier(estimators=estimators,\n",
    "                                       cv=7,\n",
    "                                       final_estimator= LogisticRegression(class_weight= final_lr_weights,\n",
    "                                                                           max_iter=2000,\n",
    "                                                                           C=0.8\n",
    "                                                                          )), \n",
    "                                       \n",
    "                    param_grid = params, \n",
    "                    scoring = loss_function,\n",
    "                    cv=10)\n",
    "                   #verbose = 1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "res = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_estimator_, grid.best_score_)\n",
    "res\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22.023809</td>\n",
       "      <td>0.078075</td>\n",
       "      <td>0.343827</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-171.9</td>\n",
       "      <td>19.454819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>11.697997</td>\n",
       "      <td>0.047223</td>\n",
       "      <td>0.174580</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.3</td>\n",
       "      <td>20.342320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.663946</td>\n",
       "      <td>0.907740</td>\n",
       "      <td>0.215796</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.3</td>\n",
       "      <td>20.342320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>16.624000</td>\n",
       "      <td>0.082506</td>\n",
       "      <td>0.208226</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.7</td>\n",
       "      <td>21.977488</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>16.373527</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.204847</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-172.9</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>17.802411</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.207504</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>19.735501</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26.607392</td>\n",
       "      <td>0.130199</td>\n",
       "      <td>0.377038</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>20.295073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>30.103281</td>\n",
       "      <td>4.527205</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.1</td>\n",
       "      <td>20.295073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10.622375</td>\n",
       "      <td>0.067721</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-173.2</td>\n",
       "      <td>20.028979</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>16.717961</td>\n",
       "      <td>0.220108</td>\n",
       "      <td>0.192011</td>\n",
       "      <td>0.057382</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-173.5</td>\n",
       "      <td>21.855205</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>11.283880</td>\n",
       "      <td>0.385224</td>\n",
       "      <td>0.173312</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-173.8</td>\n",
       "      <td>22.144074</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.898372</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>0.174592</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-173.8</td>\n",
       "      <td>21.618511</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>16.601015</td>\n",
       "      <td>0.046072</td>\n",
       "      <td>0.210782</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.092416</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>16.680314</td>\n",
       "      <td>0.072946</td>\n",
       "      <td>0.206944</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.238879</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>16.686289</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.204673</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-173.9</td>\n",
       "      <td>21.238879</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.029744</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.1</td>\n",
       "      <td>20.042205</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.507589</td>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.171174</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-174.1</td>\n",
       "      <td>21.528818</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.338684</td>\n",
       "      <td>0.103812</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.2</td>\n",
       "      <td>19.239543</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.402329</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.2</td>\n",
       "      <td>20.093780</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>22.206022</td>\n",
       "      <td>0.081089</td>\n",
       "      <td>0.348265</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>20.075109</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.473724</td>\n",
       "      <td>0.060351</td>\n",
       "      <td>0.165792</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>22.991520</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.060865</td>\n",
       "      <td>0.073835</td>\n",
       "      <td>0.216202</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>21.688937</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>16.913673</td>\n",
       "      <td>0.439962</td>\n",
       "      <td>0.207221</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>19.955200</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>22.338609</td>\n",
       "      <td>0.388232</td>\n",
       "      <td>0.347016</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>19.824480</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.743629</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>0.169809</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>20.909567</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.458482</td>\n",
       "      <td>0.095058</td>\n",
       "      <td>0.168135</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.3</td>\n",
       "      <td>22.991520</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.349277</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.034372</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>20.504877</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.344757</td>\n",
       "      <td>0.172851</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.341275</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>22.611394</td>\n",
       "      <td>0.401519</td>\n",
       "      <td>0.351329</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.336588</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7.463664</td>\n",
       "      <td>0.022040</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.5</td>\n",
       "      <td>21.513949</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>17.808298</td>\n",
       "      <td>0.072345</td>\n",
       "      <td>0.213130</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>20.660106</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>26.677653</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.379080</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>19.910801</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.148275</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>23.371778</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.336050</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>21.058015</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.351031</td>\n",
       "      <td>0.031394</td>\n",
       "      <td>0.042241</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>22.415173</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.340004</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>21.058015</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>21.918261</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.6</td>\n",
       "      <td>22.118770</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10.435406</td>\n",
       "      <td>0.139609</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>21.288729</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.565913</td>\n",
       "      <td>0.677105</td>\n",
       "      <td>0.038640</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>23.460818</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.668487</td>\n",
       "      <td>0.075723</td>\n",
       "      <td>0.210029</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>20.464848</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.422458</td>\n",
       "      <td>0.243215</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-174.7</td>\n",
       "      <td>20.464848</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>29.355811</td>\n",
       "      <td>1.736490</td>\n",
       "      <td>0.390960</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-148.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.223943</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.609984</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.277081</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>17.529424</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.213070</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>17.881834</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.511933</td>\n",
       "      <td>0.153101</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.222759</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>28.260366</td>\n",
       "      <td>0.465883</td>\n",
       "      <td>0.384251</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-149.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.275892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>28.561059</td>\n",
       "      <td>0.420984</td>\n",
       "      <td>0.380764</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-149.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>19.275892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>28.144504</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>0.380145</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>20.453850</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16.746793</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-174.8</td>\n",
       "      <td>21.292252</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>16.394125</td>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.205983</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.9</td>\n",
       "      <td>21.874414</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>20.621899</td>\n",
       "      <td>0.109678</td>\n",
       "      <td>0.341510</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>22.622997</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.256063</td>\n",
       "      <td>0.575405</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>20.842265</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.769207</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>20.104726</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.481933</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>23.462523</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.614578</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>23.389955</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.358336</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>22.241628</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.591568</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>21.630765</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.586694</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-175.1</td>\n",
       "      <td>20.161597</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>26.723527</td>\n",
       "      <td>0.094741</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>22.885803</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.402036</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>21.525798</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>11.809794</td>\n",
       "      <td>0.055980</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-175.2</td>\n",
       "      <td>21.235819</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.365683</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.042184</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-175.4</td>\n",
       "      <td>22.253988</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.004849</td>\n",
       "      <td>0.752788</td>\n",
       "      <td>0.385608</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-175.4</td>\n",
       "      <td>17.505428</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12.002461</td>\n",
       "      <td>0.170282</td>\n",
       "      <td>0.176504</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-175.5</td>\n",
       "      <td>22.037468</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.949700</td>\n",
       "      <td>0.266497</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>20.145471</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.826047</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>20.145471</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375458</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-175.6</td>\n",
       "      <td>21.592591</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.531030</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-175.8</td>\n",
       "      <td>22.741152</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.338031</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.170039</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>20.757890</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.641372</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.165792</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>20.757890</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16.479936</td>\n",
       "      <td>0.163674</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-175.9</td>\n",
       "      <td>21.565945</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16.699623</td>\n",
       "      <td>0.269708</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.1</td>\n",
       "      <td>21.073443</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.509003</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>20.740299</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>16.532062</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.206722</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>21.926240</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7.592929</td>\n",
       "      <td>0.234298</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-127.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>20.740299</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6.137977</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>22.116962</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.479482</td>\n",
       "      <td>0.133666</td>\n",
       "      <td>0.167930</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-176.2</td>\n",
       "      <td>19.461757</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.970117</td>\n",
       "      <td>0.509622</td>\n",
       "      <td>0.374631</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>19.975235</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.265682</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>21.633539</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1.470770</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.3</td>\n",
       "      <td>19.616575</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>17.648201</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.213160</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.185844</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>17.689830</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.212837</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.185844</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.715888</td>\n",
       "      <td>0.079068</td>\n",
       "      <td>0.337473</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>21.744884</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17.827831</td>\n",
       "      <td>0.053075</td>\n",
       "      <td>0.215502</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>19.980991</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>12.162654</td>\n",
       "      <td>0.468353</td>\n",
       "      <td>0.177859</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-229.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>21.634463</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.757929</td>\n",
       "      <td>0.055073</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-227.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>21.964744</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10.496971</td>\n",
       "      <td>0.075052</td>\n",
       "      <td>0.169609</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>23.673825</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>21.778537</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>0.347962</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>17.995833</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.459732</td>\n",
       "      <td>0.056540</td>\n",
       "      <td>0.168546</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-132.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>23.673825</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>23.304129</td>\n",
       "      <td>0.995861</td>\n",
       "      <td>0.348271</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>20.006249</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12.253810</td>\n",
       "      <td>0.366250</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-176.6</td>\n",
       "      <td>20.563074</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.722246</td>\n",
       "      <td>0.263365</td>\n",
       "      <td>0.202473</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-176.6</td>\n",
       "      <td>20.819222</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.466545</td>\n",
       "      <td>0.157950</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>20.908372</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>26.874849</td>\n",
       "      <td>6.055256</td>\n",
       "      <td>0.341520</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.461757</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.514436</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.327700</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.493909</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.270703</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.122207</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>21.761434</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.520792</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.8</td>\n",
       "      <td>19.327700</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.612307</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>0.043457</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.781052</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.170853</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.387883</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.178113</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-176.9</td>\n",
       "      <td>19.387883</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>20.628272</td>\n",
       "      <td>0.318612</td>\n",
       "      <td>0.340096</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>18.883856</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10.365902</td>\n",
       "      <td>0.040477</td>\n",
       "      <td>0.164555</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>22.284524</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.444264</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>0.167179</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>21.913466</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>17.603315</td>\n",
       "      <td>0.047949</td>\n",
       "      <td>0.216387</td>\n",
       "      <td>0.008596</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-177.1</td>\n",
       "      <td>20.651634</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.517433</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.481651</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.146865</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>21.089334</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.489904</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.485994</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11.820202</td>\n",
       "      <td>0.066309</td>\n",
       "      <td>0.177736</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>20.898804</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20.445895</td>\n",
       "      <td>0.129050</td>\n",
       "      <td>0.335978</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-177.2</td>\n",
       "      <td>17.876241</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12.135676</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.178477</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-177.3</td>\n",
       "      <td>21.000238</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>20.727508</td>\n",
       "      <td>0.400496</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-177.3</td>\n",
       "      <td>22.271282</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12.258847</td>\n",
       "      <td>0.726106</td>\n",
       "      <td>0.182136</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-219.0</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>16.794047</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.589494</td>\n",
       "      <td>0.109068</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>20.401961</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>16.272473</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.205279</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.4</td>\n",
       "      <td>18.434750</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.568629</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-177.6</td>\n",
       "      <td>18.932512</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16.550430</td>\n",
       "      <td>0.272073</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-177.6</td>\n",
       "      <td>20.771134</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.225161</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.511976</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>[(LR, LogisticRegression(C=1.2, class_weight={...</td>\n",
       "      <td>{'estimators': [('LR', LogisticRegression(C=1....</td>\n",
       "      <td>-218.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>19.493845</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240803</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>26.677761</td>\n",
       "      <td>0.573716</td>\n",
       "      <td>0.381371</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>[(RF, RandomForestClassifier(class_weight={0: ...</td>\n",
       "      <td>{'estimators': [('RF', RandomForestClassifier(...</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>17.872045</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.226551</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-195.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-177.7</td>\n",
       "      <td>27.184738</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.384014</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.172627</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>[(LR_bis, LogisticRegression(C=1.2, max_iter=2...</td>\n",
       "      <td>{'estimators': [('LR_bis', LogisticRegression(...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-177.9</td>\n",
       "      <td>23.010650</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>27.433562</td>\n",
       "      <td>0.205625</td>\n",
       "      <td>0.382657</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-231.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-178.1</td>\n",
       "      <td>22.801096</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.251430</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>-201.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-178.2</td>\n",
       "      <td>27.650678</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>11.840588</td>\n",
       "      <td>0.054972</td>\n",
       "      <td>0.177862</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>[(ADA_2, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_2', AdaBoostClassifier(b...</td>\n",
       "      <td>-222.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-178.3</td>\n",
       "      <td>20.823304</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.594746</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.179112</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.3</td>\n",
       "      <td>21.298122</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.489912</td>\n",
       "      <td>0.322433</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.4</td>\n",
       "      <td>21.298826</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.479141</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-178.4</td>\n",
       "      <td>21.298826</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.255388</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.035718</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>21.772689</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-221.0</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-201.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-155.0</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>27.539971</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20.737981</td>\n",
       "      <td>0.136795</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>[(LDA, LinearDiscriminantAnalysis(priors=[0.35...</td>\n",
       "      <td>{'estimators': [('LDA', LinearDiscriminantAnal...</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-186.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-178.6</td>\n",
       "      <td>21.513717</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>25.083474</td>\n",
       "      <td>0.909619</td>\n",
       "      <td>0.200606</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.2</td>\n",
       "      <td>21.989998</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>18.086180</td>\n",
       "      <td>0.658769</td>\n",
       "      <td>0.214433</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>-179.2</td>\n",
       "      <td>21.989998</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>11.846477</td>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.177972</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>20.036217</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.162990</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>-202.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-172.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>22.022716</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.235789</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.205144</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-180.3</td>\n",
       "      <td>23.524668</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10.434697</td>\n",
       "      <td>0.089211</td>\n",
       "      <td>0.173383</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-223.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-205.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-170.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-180.7</td>\n",
       "      <td>22.601106</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>17.398432</td>\n",
       "      <td>0.258976</td>\n",
       "      <td>0.208468</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.1</td>\n",
       "      <td>20.505853</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.118742</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(LDA_bis, LinearDiscriminantAnalysis(shrinkag...</td>\n",
       "      <td>{'estimators': [('LDA_bis', LinearDiscriminant...</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-137.0</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-202.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-158.0</td>\n",
       "      <td>-181.9</td>\n",
       "      <td>23.062741</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.523239</td>\n",
       "      <td>0.169048</td>\n",
       "      <td>0.167592</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>[(LDA_bis, LinearDiscriminantAnalysis(shrinkag...</td>\n",
       "      <td>{'estimators': [('LDA_bis', LinearDiscriminant...</td>\n",
       "      <td>-238.0</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-182.2</td>\n",
       "      <td>26.076043</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7.545272</td>\n",
       "      <td>0.082314</td>\n",
       "      <td>0.043132</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>-189.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-162.0</td>\n",
       "      <td>-182.6</td>\n",
       "      <td>20.090794</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.178289</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-217.0</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>-183.8</td>\n",
       "      <td>22.666275</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>16.398293</td>\n",
       "      <td>0.469406</td>\n",
       "      <td>0.206567</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-246.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-194.0</td>\n",
       "      <td>-165.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>-185.7</td>\n",
       "      <td>26.400947</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.270118</td>\n",
       "      <td>0.131239</td>\n",
       "      <td>0.170939</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-245.0</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>-184.0</td>\n",
       "      <td>-187.0</td>\n",
       "      <td>-169.0</td>\n",
       "      <td>-186.1</td>\n",
       "      <td>27.602355</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.006875</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>0.040995</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>-185.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-198.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-201.4</td>\n",
       "      <td>14.214078</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-203.1</td>\n",
       "      <td>14.754321</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.031283</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>[(G_NB, GaussianNB(priors=[0.9, 0.099999999999...</td>\n",
       "      <td>{'estimators': [('G_NB', GaussianNB(priors=[0....</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>-209.0</td>\n",
       "      <td>-197.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-208.0</td>\n",
       "      <td>-207.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>-203.1</td>\n",
       "      <td>14.754321</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.199324</td>\n",
       "      <td>0.281303</td>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>[(ADA_1, AdaBoostClassifier(base_estimator=Dec...</td>\n",
       "      <td>{'estimators': [('ADA_1', AdaBoostClassifier(b...</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.0</td>\n",
       "      <td>-294.6</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "103      22.023809      0.078075         0.343827        0.001230   \n",
       "72       11.697997      0.047223         0.174580        0.005511   \n",
       "11       18.663946      0.907740         0.215796        0.006366   \n",
       "94       16.624000      0.082506         0.208226        0.005805   \n",
       "102      16.373527      0.145729         0.204847        0.004659   \n",
       "52       17.802411      0.053811         0.207504        0.005664   \n",
       "38       26.607392      0.130199         0.377038        0.007078   \n",
       "127      30.103281      4.527205         0.341620        0.026096   \n",
       "70       10.622375      0.067721         0.169517        0.005240   \n",
       "132      16.717961      0.220108         0.192011        0.057382   \n",
       "118      11.283880      0.385224         0.173312        0.001047   \n",
       "23       11.898372      0.042674         0.174592        0.005462   \n",
       "115      16.601015      0.046072         0.210782        0.010074   \n",
       "53       16.680314      0.072946         0.206944        0.005965   \n",
       "97       16.686289      0.063797         0.204673        0.004687   \n",
       "21       22.029744      0.044366         0.344463        0.005416   \n",
       "7        10.507589      0.063128         0.171174        0.002264   \n",
       "87        6.338684      0.103812         0.041271        0.007022   \n",
       "119       0.402329      0.007207         0.001453        0.000720   \n",
       "140      22.206022      0.081089         0.348265        0.006273   \n",
       "30       10.473724      0.060351         0.165792        0.006424   \n",
       "19       18.060865      0.073835         0.216202        0.011192   \n",
       "57       16.913673      0.439962         0.207221        0.007054   \n",
       "114      22.338609      0.388232         0.347016        0.006176   \n",
       "39       10.743629      0.053643         0.169809        0.004632   \n",
       "31       10.458482      0.095058         0.168135        0.007231   \n",
       "43        6.349277      0.025258         0.034372        0.006250   \n",
       "16        6.344757      0.172851         0.039059        0.007812   \n",
       "58       22.611394      0.401519         0.351329        0.005883   \n",
       "91        7.463664      0.022040         0.040128        0.007387   \n",
       "134      17.808298      0.072345         0.213130        0.006206   \n",
       "37       26.677653      0.090335         0.379080        0.006523   \n",
       "146       0.148275      0.007099         0.000000        0.000000   \n",
       "111       0.336050      0.007686         0.000000        0.000000   \n",
       "32        6.351031      0.031394         0.042241        0.005865   \n",
       "141       0.340004      0.007686         0.000800        0.000400   \n",
       "95       21.918261      0.059086         0.352108        0.007276   \n",
       "89       10.435406      0.139609         0.166160        0.006748   \n",
       "116       6.565913      0.677105         0.038640        0.007033   \n",
       "8        17.668487      0.075723         0.210029        0.006483   \n",
       "5        12.422458      0.243215         0.178342        0.012183   \n",
       "142      29.355811      1.736490         0.390960        0.014817   \n",
       "59        1.609984      0.009884         0.007649        0.006995   \n",
       "109      17.529424      0.058594         0.213070        0.009976   \n",
       "17       10.511933      0.153101         0.169517        0.004707   \n",
       "78       28.260366      0.465883         0.384251        0.007977   \n",
       "73       28.561059      0.420984         0.380764        0.006100   \n",
       "101      28.144504      0.107874         0.380145        0.009882   \n",
       "124      16.746793      0.511529         0.204576        0.005909   \n",
       "108      16.394125      0.073185         0.205983        0.004952   \n",
       "71       20.621899      0.109678         0.341510        0.008520   \n",
       "130       2.256063      0.575405         0.009374        0.007654   \n",
       "2         7.769207      0.151929         0.042650        0.006559   \n",
       "110       1.481933      0.006930         0.004683        0.007154   \n",
       "29        1.614578      0.004004         0.007096        0.000300   \n",
       "139       6.358336      0.030528         0.037079        0.006764   \n",
       "81        1.591568      0.004357         0.005497        0.002764   \n",
       "75        1.586694      0.006148         0.006596        0.000490   \n",
       "104      26.723527      0.094741         0.371938        0.004929   \n",
       "40        6.402036      0.059917         0.037081        0.006765   \n",
       "64       11.809794      0.055980         0.178112        0.010364   \n",
       "36        6.365683      0.028051         0.042184        0.007160   \n",
       "3        29.004849      0.752788         0.385608        0.007033   \n",
       "88       12.002461      0.170282         0.176504        0.007244   \n",
       "131       2.949700      0.266497         0.008323        0.007221   \n",
       "14        7.826047      0.081363         0.043181        0.004352   \n",
       "4         0.375458      0.007136         0.000000        0.000000   \n",
       "149       1.531030      0.021288         0.006248        0.007652   \n",
       "0        11.338031      0.616046         0.170039        0.007064   \n",
       "61       10.641372      0.363227         0.165792        0.006424   \n",
       "34       16.479936      0.163674         0.201546        0.004686   \n",
       "84       16.699623      0.269708         0.205486        0.005115   \n",
       "22        1.509003      0.011985         0.007958        0.002572   \n",
       "113      16.532062      0.052886         0.206722        0.006319   \n",
       "93        7.592929      0.234298         0.042577        0.005911   \n",
       "90        6.137977      0.029763         0.035988        0.005923   \n",
       "15       10.479482      0.133666         0.167930        0.009013   \n",
       "6        26.970117      0.509622         0.374631        0.010245   \n",
       "10        6.265682      0.051541         0.037496        0.007654   \n",
       "136       1.470770      0.012873         0.004685        0.007156   \n",
       "106      17.648201      0.059243         0.213160        0.009940   \n",
       "55       17.689830      0.119883         0.212837        0.003909   \n",
       "26       20.715888      0.079068         0.337473        0.006560   \n",
       "18       17.827831      0.053075         0.215502        0.005288   \n",
       "67       12.162654      0.468353         0.177859        0.006379   \n",
       "47       17.757929      0.055073         0.212648        0.006640   \n",
       "66       10.496971      0.075052         0.169609        0.008402   \n",
       "80       21.778537      0.065320         0.347962        0.005764   \n",
       "28       10.459732      0.056540         0.168546        0.009329   \n",
       "143      23.304129      0.995861         0.348271        0.004052   \n",
       "123      12.253810      0.366250         0.178333        0.005651   \n",
       "33       16.722246      0.263365         0.202473        0.005590   \n",
       "60       10.466545      0.157950         0.168857        0.005424   \n",
       "133      26.874849      6.055256         0.341520        0.014047   \n",
       "35        1.514436      0.006573         0.006246        0.007650   \n",
       "50        1.493909      0.012209         0.003122        0.006243   \n",
       "145       0.122207      0.011408         0.001563        0.004688   \n",
       "44        1.520792      0.007140         0.005484        0.007033   \n",
       "137       7.612307      0.026254         0.043457        0.006164   \n",
       "41        0.170853      0.008464         0.001562        0.004687   \n",
       "48        0.178113      0.010364         0.000000        0.000000   \n",
       "77       20.628272      0.318612         0.340096        0.003066   \n",
       "105      10.365902      0.040477         0.164555        0.008139   \n",
       "13       10.444264      0.121723         0.167179        0.007162   \n",
       "112      17.603315      0.047949         0.216387        0.008596   \n",
       "122       1.517433      0.014843         0.008689        0.003575   \n",
       "92        1.481651      0.006145         0.003125        0.006249   \n",
       "107       0.146865      0.007654         0.000000        0.000000   \n",
       "20        1.489904      0.011686         0.006696        0.000458   \n",
       "49       11.820202      0.066309         0.177736        0.006524   \n",
       "54       20.445895      0.129050         0.335978        0.009469   \n",
       "121      12.135676      0.074441         0.178477        0.003758   \n",
       "63       20.727508      0.400496         0.332787        0.006482   \n",
       "126      12.258847      0.726106         0.182136        0.012055   \n",
       "51       10.589494      0.109068         0.166401        0.005828   \n",
       "100      16.272473      0.171200         0.205279        0.004547   \n",
       "144      10.568629      0.237228         0.173741        0.004679   \n",
       "45       16.550430      0.272073         0.204773        0.001801   \n",
       "83        0.225161      0.006946         0.001562        0.004687   \n",
       "85        1.511976      0.023316         0.009370        0.007650   \n",
       "1         0.240803      0.007910         0.000000        0.000000   \n",
       "56       26.677761      0.573716         0.381371        0.020648   \n",
       "9         0.226551      0.008009         0.001562        0.004687   \n",
       "27       10.384014      0.078998         0.172627        0.009713   \n",
       "148      27.433562      0.205625         0.382657        0.007949   \n",
       "24        0.251430      0.005144         0.001562        0.004687   \n",
       "74       11.840588      0.054972         0.177862        0.006696   \n",
       "46       11.594746      0.065455         0.179112        0.009984   \n",
       "128       2.489912      0.322433         0.004859        0.004756   \n",
       "135       1.479141      0.014743         0.009368        0.007649   \n",
       "86        6.255388      0.031432         0.035718        0.006172   \n",
       "65        0.138462      0.008490         0.001562        0.004687   \n",
       "79       20.737981      0.136795         0.337677        0.008308   \n",
       "129      25.083474      0.909619         0.200606        0.010593   \n",
       "147      18.086180      0.658769         0.214433        0.006646   \n",
       "68       11.846477      0.107379         0.177972        0.005656   \n",
       "99        6.162990      0.062706         0.037079        0.006764   \n",
       "25       16.235789      0.041534         0.205144        0.006802   \n",
       "69       10.434697      0.089211         0.173383        0.005776   \n",
       "125      17.398432      0.258976         0.208468        0.006186   \n",
       "96        0.118742      0.007655         0.000000        0.000000   \n",
       "12       10.523239      0.169048         0.167592        0.009199   \n",
       "138       7.545272      0.082314         0.043132        0.005743   \n",
       "117       0.178289      0.031383         0.000800        0.000600   \n",
       "82       16.398293      0.469406         0.206567        0.004098   \n",
       "42       10.270118      0.131239         0.170939        0.002772   \n",
       "98        6.006875      0.027010         0.040995        0.006098   \n",
       "120       0.031383      0.000489         0.000700        0.000458   \n",
       "76        0.031283      0.001734         0.000700        0.000458   \n",
       "62        6.199324      0.281303         0.031796        0.001092   \n",
       "\n",
       "                                      param_estimators  \\\n",
       "103  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "72   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "11   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "94   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "102  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "52   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "38   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "127  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "70   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "132  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "118  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "23   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "115  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "53   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "97   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "21   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "7    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "87   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "119  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "140  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "30   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "19   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "57   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "114  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "39   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "31   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "43   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "16   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "58   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "91   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "134  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "37   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "146  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "111  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "32   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "141  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "95   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "89   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "116  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "8    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "5    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "142  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "59   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "109  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "17   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "78   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "73   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "101  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "124  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "108  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "71   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "130  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "2    [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "110  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "29   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "139  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "81   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "75   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "104  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "40   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "64   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "36   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "3    [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "88   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "131  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "14   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "4    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "149  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "0    [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "61   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "34   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "84   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "22   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "113  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "93   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "90   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "15   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "6    [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "10   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "136  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "106  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "55   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "26   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "18   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "67   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "47   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "66   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "80   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "28   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "143  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "123  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "33   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "60   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "133  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "35   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "50   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "145  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "44   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "137  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "41   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "48   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "77   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "105  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "13   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "112  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "122  [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "92   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "107  [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "20   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "49   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "54   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "121  [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "63   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "126  [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "51   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "100  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "144  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "45   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "83   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "85   [(LR, LogisticRegression(C=1.2, class_weight={...   \n",
       "1    [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "56   [(RF, RandomForestClassifier(class_weight={0: ...   \n",
       "9    [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "27   [(LR_bis, LogisticRegression(C=1.2, max_iter=2...   \n",
       "148  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "24   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "74   [(ADA_2, AdaBoostClassifier(base_estimator=Dec...   \n",
       "46   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "128  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "135  [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "86   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "65   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "79   [(LDA, LinearDiscriminantAnalysis(priors=[0.35...   \n",
       "129  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "147  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "68   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "99   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "25   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "69   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "125  [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "96   [(LDA_bis, LinearDiscriminantAnalysis(shrinkag...   \n",
       "12   [(LDA_bis, LinearDiscriminantAnalysis(shrinkag...   \n",
       "138  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "117  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "82   [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "42   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "98   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "120  [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "76   [(G_NB, GaussianNB(priors=[0.9, 0.099999999999...   \n",
       "62   [(ADA_1, AdaBoostClassifier(base_estimator=Dec...   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "103  {'estimators': [('RF', RandomForestClassifier(...             -215.0   \n",
       "72   {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "11   {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "94   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "102  {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "52   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "38   {'estimators': [('RF', RandomForestClassifier(...             -214.0   \n",
       "127  {'estimators': [('RF', RandomForestClassifier(...             -214.0   \n",
       "70   {'estimators': [('LR', LogisticRegression(C=1....             -218.0   \n",
       "132  {'estimators': [('LR', LogisticRegression(C=1....             -227.0   \n",
       "118  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "23   {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "115  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "53   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "97   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "21   {'estimators': [('G_NB', GaussianNB(priors=[0....             -222.0   \n",
       "7    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "87   {'estimators': [('LDA', LinearDiscriminantAnal...             -216.0   \n",
       "119  {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "140  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "30   {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "19   {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "57   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "114  {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "39   {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "31   {'estimators': [('RF', RandomForestClassifier(...             -224.0   \n",
       "43   {'estimators': [('LDA', LinearDiscriminantAnal...             -220.0   \n",
       "16   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "58   {'estimators': [('LR', LogisticRegression(C=1....             -228.0   \n",
       "91   {'estimators': [('LDA', LinearDiscriminantAnal...             -220.0   \n",
       "134  {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "37   {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "146  {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "111  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "32   {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "141  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "95   {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "89   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "116  {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "8    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "5    {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "142  {'estimators': [('LR', LogisticRegression(C=1....             -223.0   \n",
       "59   {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "109  {'estimators': [('RF', RandomForestClassifier(...             -216.0   \n",
       "17   {'estimators': [('G_NB', GaussianNB(priors=[0....             -222.0   \n",
       "78   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "73   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "101  {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "124  {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "108  {'estimators': [('LDA', LinearDiscriminantAnal...             -226.0   \n",
       "71   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "130  {'estimators': [('LR', LogisticRegression(C=1....             -220.0   \n",
       "2    {'estimators': [('LDA', LinearDiscriminantAnal...             -217.0   \n",
       "110  {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "29   {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "139  {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "81   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "75   {'estimators': [('LDA', LinearDiscriminantAnal...             -217.0   \n",
       "104  {'estimators': [('LDA', LinearDiscriminantAnal...             -225.0   \n",
       "40   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "64   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "36   {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "3    {'estimators': [('RF', RandomForestClassifier(...             -210.0   \n",
       "88   {'estimators': [('LR', LogisticRegression(C=1....             -221.0   \n",
       "131  {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "14   {'estimators': [('LDA', LinearDiscriminantAnal...             -218.0   \n",
       "4    {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "149  {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "0    {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "61   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "34   {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "84   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "22   {'estimators': [('G_NB', GaussianNB(priors=[0....             -207.0   \n",
       "113  {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "93   {'estimators': [('G_NB', GaussianNB(priors=[0....             -207.0   \n",
       "90   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "15   {'estimators': [('RF', RandomForestClassifier(...             -216.0   \n",
       "6    {'estimators': [('LR', LogisticRegression(C=1....             -225.0   \n",
       "10   {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "136  {'estimators': [('LR', LogisticRegression(C=1....             -219.0   \n",
       "106  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "55   {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "26   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "18   {'estimators': [('LDA', LinearDiscriminantAnal...             -225.0   \n",
       "67   {'estimators': [('LDA', LinearDiscriminantAnal...             -229.0   \n",
       "47   {'estimators': [('LDA', LinearDiscriminantAnal...             -227.0   \n",
       "66   {'estimators': [('LR_bis', LogisticRegression(...             -226.0   \n",
       "80   {'estimators': [('G_NB', GaussianNB(priors=[0....             -211.0   \n",
       "28   {'estimators': [('LR_bis', LogisticRegression(...             -226.0   \n",
       "143  {'estimators': [('LR', LogisticRegression(C=1....             -224.0   \n",
       "123  {'estimators': [('G_NB', GaussianNB(priors=[0....             -219.0   \n",
       "33   {'estimators': [('LDA', LinearDiscriminantAnal...             -223.0   \n",
       "60   {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "133  {'estimators': [('RF', RandomForestClassifier(...             -221.0   \n",
       "35   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "50   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "145  {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "44   {'estimators': [('LR', LogisticRegression(C=1....             -217.0   \n",
       "137  {'estimators': [('LR', LogisticRegression(C=1....             -219.0   \n",
       "41   {'estimators': [('LR', LogisticRegression(C=1....             -216.0   \n",
       "48   {'estimators': [('LR', LogisticRegression(C=1....             -216.0   \n",
       "77   {'estimators': [('G_NB', GaussianNB(priors=[0....             -211.0   \n",
       "105  {'estimators': [('LDA', LinearDiscriminantAnal...             -230.0   \n",
       "13   {'estimators': [('LR_bis', LogisticRegression(...             -218.0   \n",
       "112  {'estimators': [('G_NB', GaussianNB(priors=[0....             -219.0   \n",
       "122  {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "92   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "107  {'estimators': [('LR', LogisticRegression(C=1....             -222.0   \n",
       "20   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -207.0   \n",
       "49   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -220.0   \n",
       "54   {'estimators': [('RF', RandomForestClassifier(...             -210.0   \n",
       "121  {'estimators': [('ADA_2', AdaBoostClassifier(b...             -221.0   \n",
       "63   {'estimators': [('RF', RandomForestClassifier(...             -225.0   \n",
       "126  {'estimators': [('RF', RandomForestClassifier(...             -219.0   \n",
       "51   {'estimators': [('LDA', LinearDiscriminantAnal...             -222.0   \n",
       "100  {'estimators': [('G_NB', GaussianNB(priors=[0....             -214.0   \n",
       "144  {'estimators': [('G_NB', GaussianNB(priors=[0....             -216.0   \n",
       "45   {'estimators': [('LR', LogisticRegression(C=1....             -226.0   \n",
       "83   {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "85   {'estimators': [('LR', LogisticRegression(C=1....             -218.0   \n",
       "1    {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "56   {'estimators': [('RF', RandomForestClassifier(...             -212.0   \n",
       "9    {'estimators': [('LR_bis', LogisticRegression(...             -221.0   \n",
       "27   {'estimators': [('LR_bis', LogisticRegression(...             -224.0   \n",
       "148  {'estimators': [('LDA', LinearDiscriminantAnal...             -231.0   \n",
       "24   {'estimators': [('G_NB', GaussianNB(priors=[0....             -220.0   \n",
       "74   {'estimators': [('ADA_2', AdaBoostClassifier(b...             -222.0   \n",
       "46   {'estimators': [('G_NB', GaussianNB(priors=[0....             -225.0   \n",
       "128  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "135  {'estimators': [('LDA', LinearDiscriminantAnal...             -224.0   \n",
       "86   {'estimators': [('LDA', LinearDiscriminantAnal...             -221.0   \n",
       "65   {'estimators': [('G_NB', GaussianNB(priors=[0....             -221.0   \n",
       "79   {'estimators': [('LDA', LinearDiscriminantAnal...             -228.0   \n",
       "129  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -226.0   \n",
       "147  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -226.0   \n",
       "68   {'estimators': [('G_NB', GaussianNB(priors=[0....             -223.0   \n",
       "99   {'estimators': [('G_NB', GaussianNB(priors=[0....             -217.0   \n",
       "25   {'estimators': [('G_NB', GaussianNB(priors=[0....             -235.0   \n",
       "69   {'estimators': [('G_NB', GaussianNB(priors=[0....             -223.0   \n",
       "125  {'estimators': [('ADA_1', AdaBoostClassifier(b...             -224.0   \n",
       "96   {'estimators': [('LDA_bis', LinearDiscriminant...             -217.0   \n",
       "12   {'estimators': [('LDA_bis', LinearDiscriminant...             -238.0   \n",
       "138  {'estimators': [('G_NB', GaussianNB(priors=[0....             -225.0   \n",
       "117  {'estimators': [('G_NB', GaussianNB(priors=[0....             -217.0   \n",
       "82   {'estimators': [('ADA_1', AdaBoostClassifier(b...             -246.0   \n",
       "42   {'estimators': [('G_NB', GaussianNB(priors=[0....             -245.0   \n",
       "98   {'estimators': [('G_NB', GaussianNB(priors=[0....             -232.0   \n",
       "120  {'estimators': [('G_NB', GaussianNB(priors=[0....             -236.0   \n",
       "76   {'estimators': [('G_NB', GaussianNB(priors=[0....             -236.0   \n",
       "62   {'estimators': [('ADA_1', AdaBoostClassifier(b...             -294.0   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "103             -136.0             -172.0             -182.0   \n",
       "72              -136.0             -175.0             -182.0   \n",
       "11              -136.0             -175.0             -182.0   \n",
       "94              -134.0             -185.0             -179.0   \n",
       "102             -134.0             -186.0             -179.0   \n",
       "52              -143.0             -179.0             -170.0   \n",
       "38              -135.0             -187.0             -180.0   \n",
       "127             -135.0             -187.0             -180.0   \n",
       "70              -137.0             -180.0             -176.0   \n",
       "132             -136.0             -172.0             -178.0   \n",
       "118             -125.0             -184.0             -180.0   \n",
       "23              -127.0             -179.0             -181.0   \n",
       "115             -139.0             -175.0             -181.0   \n",
       "53              -139.0             -180.0             -180.0   \n",
       "97              -139.0             -180.0             -180.0   \n",
       "21              -141.0             -181.0             -181.0   \n",
       "7               -131.0             -182.0             -181.0   \n",
       "87              -134.0             -184.0             -178.0   \n",
       "119             -133.0             -184.0             -177.0   \n",
       "140             -144.0             -167.0             -172.0   \n",
       "30              -135.0             -192.0             -180.0   \n",
       "19              -127.0             -179.0             -181.0   \n",
       "57              -142.0             -168.0             -183.0   \n",
       "114             -143.0             -176.0             -171.0   \n",
       "39              -138.0             -181.0             -176.0   \n",
       "31              -135.0             -192.0             -180.0   \n",
       "43              -133.0             -184.0             -177.0   \n",
       "16              -129.0             -177.0             -175.0   \n",
       "58              -143.0             -179.0             -175.0   \n",
       "91              -130.0             -180.0             -180.0   \n",
       "134             -134.0             -176.0             -176.0   \n",
       "37              -144.0             -171.0             -182.0   \n",
       "146             -123.0             -182.0             -187.0   \n",
       "111             -127.0             -179.0             -178.0   \n",
       "32              -127.0             -180.0             -178.0   \n",
       "141             -127.0             -179.0             -178.0   \n",
       "95              -138.0             -185.0             -177.0   \n",
       "89              -130.0             -182.0             -180.0   \n",
       "116             -123.0             -182.0             -188.0   \n",
       "8               -135.0             -176.0             -176.0   \n",
       "5               -135.0             -176.0             -176.0   \n",
       "142             -148.0             -166.0             -175.0   \n",
       "59              -132.0             -183.0             -179.0   \n",
       "109             -142.0             -180.0             -181.0   \n",
       "17              -143.0             -185.0             -184.0   \n",
       "78              -149.0             -168.0             -175.0   \n",
       "73              -149.0             -168.0             -175.0   \n",
       "101             -144.0             -189.0             -176.0   \n",
       "124             -130.0             -182.0             -180.0   \n",
       "108             -137.0             -176.0             -183.0   \n",
       "71              -135.0             -190.0             -180.0   \n",
       "130             -128.0             -176.0             -174.0   \n",
       "2               -132.0             -184.0             -179.0   \n",
       "110             -129.0             -197.0             -172.0   \n",
       "29              -129.0             -197.0             -172.0   \n",
       "139             -127.0             -180.0             -179.0   \n",
       "81              -132.0             -187.0             -183.0   \n",
       "75              -130.0             -181.0             -179.0   \n",
       "104             -132.0             -183.0             -194.0   \n",
       "40              -130.0             -178.0             -176.0   \n",
       "64              -131.0             -177.0             -177.0   \n",
       "36              -127.0             -180.0             -180.0   \n",
       "3               -143.0             -190.0             -186.0   \n",
       "88              -127.0             -180.0             -176.0   \n",
       "131             -130.0             -181.0             -179.0   \n",
       "14              -130.0             -181.0             -179.0   \n",
       "4               -130.0             -185.0             -176.0   \n",
       "149             -128.0             -181.0             -185.0   \n",
       "0               -135.0             -180.0             -188.0   \n",
       "61              -135.0             -180.0             -188.0   \n",
       "34              -138.0             -186.0             -187.0   \n",
       "84              -137.0             -183.0             -192.0   \n",
       "22              -127.0             -198.0             -185.0   \n",
       "113             -139.0             -185.0             -187.0   \n",
       "93              -127.0             -198.0             -185.0   \n",
       "90              -134.0             -190.0             -192.0   \n",
       "15              -138.0             -188.0             -190.0   \n",
       "6               -145.0             -179.0             -182.0   \n",
       "10              -128.0             -184.0             -180.0   \n",
       "136             -137.0             -177.0             -184.0   \n",
       "106             -135.0             -176.0             -181.0   \n",
       "55              -135.0             -176.0             -181.0   \n",
       "26              -140.0             -186.0             -186.0   \n",
       "18              -141.0             -181.0             -187.0   \n",
       "67              -144.0             -184.0             -186.0   \n",
       "47              -135.0             -171.0             -181.0   \n",
       "66              -132.0             -200.0             -185.0   \n",
       "80              -143.0             -197.0             -184.0   \n",
       "28              -132.0             -200.0             -185.0   \n",
       "143             -144.0             -183.0             -170.0   \n",
       "123             -137.0             -197.0             -178.0   \n",
       "33              -135.0             -185.0             -183.0   \n",
       "60              -137.0             -181.0             -183.0   \n",
       "133             -142.0             -187.0             -186.0   \n",
       "35              -133.0             -174.0             -178.0   \n",
       "50              -136.0             -177.0             -183.0   \n",
       "145             -131.0             -187.0             -184.0   \n",
       "44              -133.0             -174.0             -178.0   \n",
       "137             -134.0             -174.0             -179.0   \n",
       "41              -133.0             -184.0             -182.0   \n",
       "48              -133.0             -184.0             -182.0   \n",
       "77              -140.0             -196.0             -189.0   \n",
       "105             -138.0             -188.0             -187.0   \n",
       "13              -134.0             -199.0             -191.0   \n",
       "112             -137.0             -197.0             -183.0   \n",
       "122             -141.0             -199.0             -184.0   \n",
       "92              -141.0             -199.0             -184.0   \n",
       "107             -130.0             -180.0             -182.0   \n",
       "20              -141.0             -199.0             -184.0   \n",
       "49              -137.0             -197.0             -175.0   \n",
       "54              -144.0             -196.0             -188.0   \n",
       "121             -136.0             -193.0             -179.0   \n",
       "63              -142.0             -195.0             -188.0   \n",
       "126             -152.0             -180.0             -183.0   \n",
       "51              -136.0             -185.0             -184.0   \n",
       "100             -141.0             -193.0             -189.0   \n",
       "144             -141.0             -193.0             -189.0   \n",
       "45              -143.0             -184.0             -187.0   \n",
       "83              -126.0             -215.0             -195.0   \n",
       "85              -134.0             -180.0             -181.0   \n",
       "1               -126.0             -215.0             -195.0   \n",
       "56              -142.0             -196.0             -186.0   \n",
       "9               -126.0             -215.0             -195.0   \n",
       "27              -133.0             -200.0             -193.0   \n",
       "148             -140.0             -189.0             -194.0   \n",
       "24              -126.0             -216.0             -201.0   \n",
       "74              -137.0             -197.0             -178.0   \n",
       "46              -142.0             -196.0             -181.0   \n",
       "128             -135.0             -182.0             -187.0   \n",
       "135             -135.0             -182.0             -187.0   \n",
       "86              -136.0             -192.0             -194.0   \n",
       "65              -126.0             -215.0             -201.0   \n",
       "79              -142.0             -186.0             -193.0   \n",
       "129             -145.0             -197.0             -185.0   \n",
       "147             -145.0             -197.0             -185.0   \n",
       "68              -142.0             -194.0             -188.0   \n",
       "99              -129.0             -202.0             -191.0   \n",
       "25              -140.0             -200.0             -175.0   \n",
       "69              -136.0             -205.0             -194.0   \n",
       "125             -144.0             -196.0             -188.0   \n",
       "96              -137.0             -211.0             -202.0   \n",
       "12              -138.0             -209.0             -188.0   \n",
       "138             -142.0             -191.0             -188.0   \n",
       "117             -136.0             -212.0             -200.0   \n",
       "82              -143.0             -212.0             -185.0   \n",
       "42              -133.0             -209.0             -196.0   \n",
       "98              -185.0             -213.0             -209.0   \n",
       "120             -190.0             -213.0             -209.0   \n",
       "76              -190.0             -213.0             -209.0   \n",
       "62              -294.0             -294.0             -300.0   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "103             -171.0             -159.0             -179.0   \n",
       "72              -171.0             -159.0             -179.0   \n",
       "11              -171.0             -159.0             -179.0   \n",
       "94              -172.0             -156.0             -177.0   \n",
       "102             -172.0             -161.0             -175.0   \n",
       "52              -167.0             -161.0             -181.0   \n",
       "38              -172.0             -160.0             -184.0   \n",
       "127             -172.0             -160.0             -184.0   \n",
       "70              -177.0             -157.0             -179.0   \n",
       "132             -174.0             -157.0             -180.0   \n",
       "118             -175.0             -170.0             -173.0   \n",
       "23              -176.0             -171.0             -175.0   \n",
       "115             -177.0             -156.0             -178.0   \n",
       "53              -176.0             -156.0             -177.0   \n",
       "97              -176.0             -156.0             -177.0   \n",
       "21              -165.0             -166.0             -180.0   \n",
       "7               -182.0             -161.0             -173.0   \n",
       "87              -171.0             -170.0             -181.0   \n",
       "119             -175.0             -168.0             -177.0   \n",
       "140             -178.0             -161.0             -184.0   \n",
       "30              -172.0             -160.0             -184.0   \n",
       "19              -174.0             -172.0             -180.0   \n",
       "57              -168.0             -160.0             -181.0   \n",
       "114             -177.0             -161.0             -182.0   \n",
       "39              -177.0             -157.0             -179.0   \n",
       "31              -172.0             -160.0             -184.0   \n",
       "43              -175.0             -169.0             -177.0   \n",
       "16              -176.0             -169.0             -180.0   \n",
       "58              -177.0             -161.0             -178.0   \n",
       "91              -170.0             -167.0             -187.0   \n",
       "134             -179.0             -165.0             -182.0   \n",
       "37              -174.0             -158.0             -180.0   \n",
       "146             -171.0             -164.0             -187.0   \n",
       "111             -174.0             -169.0             -177.0   \n",
       "32              -173.0             -168.0             -178.0   \n",
       "141             -174.0             -169.0             -177.0   \n",
       "95              -166.0             -164.0             -182.0   \n",
       "89              -177.0             -167.0             -175.0   \n",
       "116             -172.0             -163.0             -187.0   \n",
       "8               -179.0             -165.0             -182.0   \n",
       "5               -179.0             -165.0             -182.0   \n",
       "142             -174.0             -161.0             -185.0   \n",
       "59              -172.0             -169.0             -185.0   \n",
       "109             -175.0             -162.0             -179.0   \n",
       "17              -170.0             -162.0             -181.0   \n",
       "78              -167.0             -162.0             -185.0   \n",
       "73              -167.0             -162.0             -185.0   \n",
       "101             -167.0             -161.0             -180.0   \n",
       "124             -177.0             -167.0             -176.0   \n",
       "108             -167.0             -159.0             -183.0   \n",
       "71              -166.0             -164.0             -181.0   \n",
       "130             -175.0             -171.0             -181.0   \n",
       "2               -171.0             -180.0             -184.0   \n",
       "110             -168.0             -169.0             -184.0   \n",
       "29              -169.0             -169.0             -184.0   \n",
       "139             -173.0             -168.0             -178.0   \n",
       "81              -165.0             -170.0             -183.0   \n",
       "75              -177.0             -171.0             -178.0   \n",
       "104             -165.0             -165.0             -179.0   \n",
       "40              -175.0             -170.0             -181.0   \n",
       "64              -179.0             -165.0             -183.0   \n",
       "36              -174.0             -169.0             -178.0   \n",
       "3               -175.0             -161.0             -180.0   \n",
       "88              -178.0             -174.0             -183.0   \n",
       "131             -173.0             -172.0             -178.0   \n",
       "14              -173.0             -172.0             -178.0   \n",
       "4               -181.0             -170.0             -180.0   \n",
       "149             -168.0             -168.0             -190.0   \n",
       "0               -177.0             -162.0             -179.0   \n",
       "61              -177.0             -162.0             -179.0   \n",
       "34              -178.0             -160.0             -176.0   \n",
       "84              -167.0             -159.0             -184.0   \n",
       "22              -184.0             -171.0             -176.0   \n",
       "113             -173.0             -166.0             -176.0   \n",
       "93              -184.0             -171.0             -176.0   \n",
       "90              -169.0             -162.0             -184.0   \n",
       "15              -173.0             -163.0             -180.0   \n",
       "6               -176.0             -159.0             -181.0   \n",
       "10              -181.0             -168.0             -177.0   \n",
       "136             -167.0             -164.0             -182.0   \n",
       "106             -171.0             -163.0             -185.0   \n",
       "55              -171.0             -163.0             -185.0   \n",
       "26              -173.0             -165.0             -181.0   \n",
       "18              -173.0             -165.0             -175.0   \n",
       "67              -174.0             -160.0             -178.0   \n",
       "47              -171.0             -164.0             -187.0   \n",
       "66              -168.0             -174.0             -176.0   \n",
       "80              -175.0             -161.0             -180.0   \n",
       "28              -168.0             -174.0             -176.0   \n",
       "143             -182.0             -165.0             -181.0   \n",
       "123             -171.0             -175.0             -178.0   \n",
       "33              -176.0             -164.0             -181.0   \n",
       "60              -171.0             -164.0             -183.0   \n",
       "133             -173.0             -167.0             -181.0   \n",
       "35              -177.0             -174.0             -186.0   \n",
       "50              -166.0             -170.0             -186.0   \n",
       "145             -174.0             -165.0             -189.0   \n",
       "44              -177.0             -174.0             -186.0   \n",
       "137             -172.0             -170.0             -185.0   \n",
       "41              -169.0             -172.0             -184.0   \n",
       "48              -169.0             -172.0             -184.0   \n",
       "77              -180.0             -162.0             -180.0   \n",
       "105             -167.0             -162.0             -176.0   \n",
       "13              -166.0             -173.0             -174.0   \n",
       "112             -171.0             -175.0             -178.0   \n",
       "122             -182.0             -172.0             -174.0   \n",
       "92              -182.0             -172.0             -174.0   \n",
       "107             -179.0             -172.0             -182.0   \n",
       "20              -182.0             -172.0             -174.0   \n",
       "49              -171.0             -180.0             -178.0   \n",
       "54              -180.0             -162.0             -180.0   \n",
       "121             -172.0             -184.0             -176.0   \n",
       "63              -183.0             -162.0             -179.0   \n",
       "126             -169.0             -165.0             -182.0   \n",
       "51              -177.0             -170.0             -183.0   \n",
       "100             -172.0             -163.0             -180.0   \n",
       "144             -172.0             -163.0             -180.0   \n",
       "45              -182.0             -160.0             -178.0   \n",
       "83              -166.0             -165.0             -186.0   \n",
       "85              -179.0             -169.0             -186.0   \n",
       "1               -166.0             -165.0             -186.0   \n",
       "56              -174.0             -169.0             -181.0   \n",
       "9               -166.0             -165.0             -186.0   \n",
       "27              -170.0             -173.0             -175.0   \n",
       "148             -170.0             -166.0             -180.0   \n",
       "24              -165.0             -165.0             -186.0   \n",
       "74              -171.0             -183.0             -178.0   \n",
       "46              -186.0             -171.0             -177.0   \n",
       "128             -170.0             -170.0             -191.0   \n",
       "135             -170.0             -170.0             -191.0   \n",
       "86              -184.0             -164.0             -185.0   \n",
       "65              -168.0             -165.0             -186.0   \n",
       "79              -174.0             -166.0             -183.0   \n",
       "129             -191.0             -174.0             -177.0   \n",
       "147             -191.0             -174.0             -177.0   \n",
       "68              -173.0             -181.0             -178.0   \n",
       "99              -182.0             -172.0             -179.0   \n",
       "25              -188.0             -163.0             -179.0   \n",
       "69              -180.0             -174.0             -183.0   \n",
       "125             -188.0             -184.0             -176.0   \n",
       "96              -178.0             -167.0             -183.0   \n",
       "12              -188.0             -162.0             -184.0   \n",
       "138             -189.0             -178.0             -184.0   \n",
       "117             -178.0             -177.0             -181.0   \n",
       "82              -194.0             -165.0             -179.0   \n",
       "42              -192.0             -169.0             -177.0   \n",
       "98              -197.0             -200.0             -198.0   \n",
       "120             -197.0             -200.0             -208.0   \n",
       "76              -197.0             -200.0             -208.0   \n",
       "62              -294.0             -294.0             -294.0   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "103             -162.0             -182.0             -161.0           -171.9   \n",
       "72              -161.0             -180.0             -161.0           -172.3   \n",
       "11              -161.0             -180.0             -161.0           -172.3   \n",
       "94              -161.0             -179.0             -161.0           -172.7   \n",
       "102             -156.0             -181.0             -161.0           -172.9   \n",
       "52              -166.0             -179.0             -162.0           -173.1   \n",
       "38              -158.0             -181.0             -160.0           -173.1   \n",
       "127             -158.0             -181.0             -160.0           -173.1   \n",
       "70              -164.0             -183.0             -161.0           -173.2   \n",
       "132             -165.0             -180.0             -166.0           -173.5   \n",
       "118             -176.0             -176.0             -159.0           -173.8   \n",
       "23              -175.0             -176.0             -158.0           -173.8   \n",
       "115             -164.0             -183.0             -162.0           -173.9   \n",
       "53              -164.0             -183.0             -160.0           -173.9   \n",
       "97              -164.0             -183.0             -160.0           -173.9   \n",
       "21              -164.0             -181.0             -160.0           -174.1   \n",
       "7               -175.0             -176.0             -159.0           -174.1   \n",
       "87              -172.0             -174.0             -162.0           -174.2   \n",
       "119             -177.0             -175.0             -158.0           -174.2   \n",
       "140             -167.0             -184.0             -162.0           -174.3   \n",
       "30              -155.0             -181.0             -160.0           -174.3   \n",
       "19              -175.0             -177.0             -158.0           -174.3   \n",
       "57              -167.0             -186.0             -166.0           -174.3   \n",
       "114             -166.0             -183.0             -161.0           -174.3   \n",
       "39              -164.0             -184.0             -164.0           -174.3   \n",
       "31              -155.0             -181.0             -160.0           -174.3   \n",
       "43              -177.0             -175.0             -158.0           -174.5   \n",
       "16              -178.0             -180.0             -160.0           -174.5   \n",
       "58              -163.0             -183.0             -158.0           -174.5   \n",
       "91              -178.0             -175.0             -158.0           -174.5   \n",
       "134             -176.0             -179.0             -158.0           -174.6   \n",
       "37              -165.0             -185.0             -164.0           -174.6   \n",
       "146             -174.0             -175.0             -162.0           -174.6   \n",
       "111             -177.0             -176.0             -169.0           -174.6   \n",
       "32              -177.0             -176.0             -164.0           -174.6   \n",
       "141             -177.0             -176.0             -169.0           -174.6   \n",
       "95              -165.0             -181.0             -160.0           -174.6   \n",
       "89              -175.0             -180.0             -160.0           -174.7   \n",
       "116             -174.0             -175.0             -162.0           -174.7   \n",
       "8               -176.0             -179.0             -158.0           -174.7   \n",
       "5               -176.0             -179.0             -158.0           -174.7   \n",
       "142             -167.0             -185.0             -164.0           -174.8   \n",
       "59              -171.0             -177.0             -162.0           -174.8   \n",
       "109             -169.0             -180.0             -164.0           -174.8   \n",
       "17              -161.0             -180.0             -160.0           -174.8   \n",
       "78              -169.0             -185.0             -164.0           -174.8   \n",
       "73              -169.0             -185.0             -164.0           -174.8   \n",
       "101             -165.0             -184.0             -159.0           -174.8   \n",
       "124             -175.0             -180.0             -160.0           -174.8   \n",
       "108             -164.0             -186.0             -168.0           -174.9   \n",
       "71              -164.0             -181.0             -162.0           -175.0   \n",
       "130             -179.0             -177.0             -169.0           -175.0   \n",
       "2               -170.0             -171.0             -162.0           -175.0   \n",
       "110             -172.0             -186.0             -153.0           -175.1   \n",
       "29              -172.0             -185.0             -153.0           -175.1   \n",
       "139             -177.0             -175.0             -169.0           -175.1   \n",
       "81              -170.0             -181.0             -159.0           -175.1   \n",
       "75              -180.0             -176.0             -162.0           -175.1   \n",
       "104             -169.0             -179.0             -161.0           -175.2   \n",
       "40              -178.0             -183.0             -159.0           -175.2   \n",
       "64              -178.0             -181.0             -160.0           -175.2   \n",
       "36              -177.0             -176.0             -168.0           -175.4   \n",
       "3               -166.0             -180.0             -163.0           -175.4   \n",
       "88              -176.0             -182.0             -158.0           -175.5   \n",
       "131             -182.0             -176.0             -167.0           -175.6   \n",
       "14              -182.0             -176.0             -167.0           -175.6   \n",
       "4               -173.0             -179.0             -160.0           -175.6   \n",
       "149             -178.0             -176.0             -161.0           -175.8   \n",
       "0               -177.0             -175.0             -164.0           -175.9   \n",
       "61              -177.0             -175.0             -164.0           -175.9   \n",
       "34              -169.0             -183.0             -158.0           -175.9   \n",
       "84              -172.0             -176.0             -169.0           -176.1   \n",
       "22              -171.0             -182.0             -161.0           -176.2   \n",
       "113             -168.0             -182.0             -158.0           -176.2   \n",
       "93              -171.0             -182.0             -161.0           -176.2   \n",
       "90              -173.0             -179.0             -158.0           -176.2   \n",
       "15              -168.0             -181.0             -165.0           -176.2   \n",
       "6               -171.0             -183.0             -162.0           -176.3   \n",
       "10              -177.0             -179.0             -167.0           -176.3   \n",
       "136             -178.0             -186.0             -169.0           -176.3   \n",
       "106             -171.0             -188.0             -170.0           -176.4   \n",
       "55              -171.0             -188.0             -170.0           -176.4   \n",
       "26              -167.0             -182.0             -157.0           -176.4   \n",
       "18              -173.0             -177.0             -167.0           -176.4   \n",
       "67              -171.0             -182.0             -157.0           -176.5   \n",
       "47              -171.0             -188.0             -170.0           -176.5   \n",
       "66              -162.0             -181.0             -161.0           -176.5   \n",
       "80              -166.0             -180.0             -168.0           -176.5   \n",
       "28              -162.0             -181.0             -161.0           -176.5   \n",
       "143             -176.0             -183.0             -157.0           -176.5   \n",
       "123             -169.0             -183.0             -159.0           -176.6   \n",
       "33              -178.0             -177.0             -164.0           -176.6   \n",
       "60              -167.0             -188.0             -170.0           -176.8   \n",
       "133             -161.0             -180.0             -170.0           -176.8   \n",
       "35              -177.0             -183.0             -169.0           -176.8   \n",
       "50              -178.0             -186.0             -169.0           -176.8   \n",
       "145             -175.0             -176.0             -165.0           -176.8   \n",
       "44              -177.0             -183.0             -169.0           -176.8   \n",
       "137             -183.0             -184.0             -169.0           -176.9   \n",
       "41              -178.0             -182.0             -169.0           -176.9   \n",
       "48              -178.0             -182.0             -169.0           -176.9   \n",
       "77              -168.0             -181.0             -163.0           -177.0   \n",
       "105             -173.0             -180.0             -169.0           -177.0   \n",
       "13              -162.0             -187.0             -166.0           -177.0   \n",
       "112             -169.0             -183.0             -159.0           -177.1   \n",
       "122             -171.0             -180.0             -162.0           -177.2   \n",
       "92              -171.0             -180.0             -162.0           -177.2   \n",
       "107             -174.0             -183.0             -168.0           -177.2   \n",
       "20              -171.0             -180.0             -162.0           -177.2   \n",
       "49              -169.0             -186.0             -159.0           -177.2   \n",
       "54              -168.0             -181.0             -163.0           -177.2   \n",
       "121             -170.0             -184.0             -158.0           -177.3   \n",
       "63              -161.0             -182.0             -156.0           -177.3   \n",
       "126             -172.0             -184.0             -168.0           -177.4   \n",
       "51              -179.0             -177.0             -161.0           -177.4   \n",
       "100             -172.0             -181.0             -169.0           -177.4   \n",
       "144             -173.0             -182.0             -167.0           -177.6   \n",
       "45              -171.0             -183.0             -162.0           -177.6   \n",
       "83              -163.0             -185.0             -155.0           -177.7   \n",
       "85              -178.0             -183.0             -169.0           -177.7   \n",
       "1               -163.0             -185.0             -155.0           -177.7   \n",
       "56              -165.0             -182.0             -170.0           -177.7   \n",
       "9               -163.0             -185.0             -155.0           -177.7   \n",
       "27              -165.0             -181.0             -165.0           -177.9   \n",
       "148             -170.0             -180.0             -161.0           -178.1   \n",
       "24              -163.0             -185.0             -155.0           -178.2   \n",
       "74              -170.0             -183.0             -164.0           -178.3   \n",
       "46              -158.0             -182.0             -165.0           -178.3   \n",
       "128             -179.0             -181.0             -165.0           -178.4   \n",
       "135             -179.0             -181.0             -165.0           -178.4   \n",
       "86              -172.0             -178.0             -159.0           -178.5   \n",
       "65              -163.0             -185.0             -155.0           -178.5   \n",
       "79              -177.0             -178.0             -159.0           -178.6   \n",
       "129             -156.0             -182.0             -159.0           -179.2   \n",
       "147             -156.0             -182.0             -159.0           -179.2   \n",
       "68              -167.0             -184.0             -165.0           -179.5   \n",
       "99              -179.0             -183.0             -166.0           -180.0   \n",
       "25              -171.0             -179.0             -173.0           -180.3   \n",
       "69              -170.0             -181.0             -161.0           -180.7   \n",
       "125             -171.0             -182.0             -158.0           -181.1   \n",
       "96              -185.0             -181.0             -158.0           -181.9   \n",
       "12              -173.0             -181.0             -161.0           -182.2   \n",
       "138             -184.0             -183.0             -162.0           -182.6   \n",
       "117             -193.0             -183.0             -161.0           -183.8   \n",
       "82              -173.0             -185.0             -175.0           -185.7   \n",
       "42              -184.0             -187.0             -169.0           -186.1   \n",
       "98              -208.0             -180.0             -192.0           -201.4   \n",
       "120             -207.0             -179.0             -192.0           -203.1   \n",
       "76              -207.0             -179.0             -192.0           -203.1   \n",
       "62              -294.0             -294.0             -294.0           -294.6   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "103       19.454819                1  \n",
       "72        20.342320                2  \n",
       "11        20.342320                2  \n",
       "94        21.977488                4  \n",
       "102       22.300000                5  \n",
       "52        19.735501                6  \n",
       "38        20.295073                6  \n",
       "127       20.295073                6  \n",
       "70        20.028979                9  \n",
       "132       21.855205               10  \n",
       "118       22.144074               11  \n",
       "23        21.618511               11  \n",
       "115       21.092416               13  \n",
       "53        21.238879               13  \n",
       "97        21.238879               13  \n",
       "21        20.042205               16  \n",
       "7         21.528818               16  \n",
       "87        19.239543               18  \n",
       "119       20.093780               18  \n",
       "140       20.075109               20  \n",
       "30        22.991520               20  \n",
       "19        21.688937               20  \n",
       "57        19.955200               20  \n",
       "114       19.824480               20  \n",
       "39        20.909567               20  \n",
       "31        22.991520               20  \n",
       "43        20.504877               27  \n",
       "16        21.341275               27  \n",
       "58        21.336588               27  \n",
       "91        21.513949               27  \n",
       "134       20.660106               31  \n",
       "37        19.910801               31  \n",
       "146       23.371778               31  \n",
       "111       21.058015               31  \n",
       "32        22.415173               31  \n",
       "141       21.058015               31  \n",
       "95        22.118770               31  \n",
       "89        21.288729               38  \n",
       "116       23.460818               38  \n",
       "8         20.464848               38  \n",
       "5         20.464848               38  \n",
       "142       19.223943               42  \n",
       "59        20.277081               42  \n",
       "109       17.881834               42  \n",
       "17        20.222759               42  \n",
       "78        19.275892               42  \n",
       "73        19.275892               42  \n",
       "101       20.453850               42  \n",
       "124       21.292252               42  \n",
       "108       21.874414               50  \n",
       "71        22.622997               51  \n",
       "130       20.842265               51  \n",
       "2         20.104726               51  \n",
       "110       23.462523               54  \n",
       "29        23.389955               54  \n",
       "139       22.241628               54  \n",
       "81        21.630765               54  \n",
       "75        20.161597               54  \n",
       "104       22.885803               59  \n",
       "40        21.525798               59  \n",
       "64        21.235819               59  \n",
       "36        22.253988               62  \n",
       "3         17.505428               62  \n",
       "88        22.037468               64  \n",
       "131       20.145471               65  \n",
       "14        20.145471               65  \n",
       "4         21.592591               65  \n",
       "149       22.741152               68  \n",
       "0         20.757890               69  \n",
       "61        20.757890               69  \n",
       "34        21.565945               69  \n",
       "84        21.073443               72  \n",
       "22        20.740299               73  \n",
       "113       21.926240               73  \n",
       "93        20.740299               73  \n",
       "90        22.116962               73  \n",
       "15        19.461757               73  \n",
       "6         19.975235               78  \n",
       "10        21.633539               78  \n",
       "136       19.616575               78  \n",
       "106       21.185844               81  \n",
       "55        21.185844               81  \n",
       "26        21.744884               81  \n",
       "18        19.980991               81  \n",
       "67        21.634463               85  \n",
       "47        21.964744               85  \n",
       "66        23.673825               85  \n",
       "80        17.995833               85  \n",
       "28        23.673825               85  \n",
       "143       20.006249               85  \n",
       "123       20.563074               91  \n",
       "33        20.819222               91  \n",
       "60        20.908372               93  \n",
       "133       19.461757               93  \n",
       "35        19.327700               93  \n",
       "50        19.270703               93  \n",
       "145       21.761434               93  \n",
       "44        19.327700               93  \n",
       "137       19.781052               99  \n",
       "41        19.387883               99  \n",
       "48        19.387883               99  \n",
       "77        18.883856              102  \n",
       "105       22.284524              102  \n",
       "13        21.913466              102  \n",
       "112       20.651634              105  \n",
       "122       17.485994              106  \n",
       "92        17.485994              106  \n",
       "107       21.089334              106  \n",
       "20        17.485994              106  \n",
       "49        20.898804              106  \n",
       "54        17.876241              106  \n",
       "121       21.000238              112  \n",
       "63        22.271282              112  \n",
       "126       16.794047              114  \n",
       "51        20.401961              114  \n",
       "100       18.434750              114  \n",
       "144       18.932512              117  \n",
       "45        20.771134              117  \n",
       "83        27.184738              119  \n",
       "85        19.493845              119  \n",
       "1         27.184738              119  \n",
       "56        17.872045              119  \n",
       "9         27.184738              119  \n",
       "27        23.010650              124  \n",
       "148       22.801096              125  \n",
       "24        27.650678              126  \n",
       "74        20.823304              127  \n",
       "46        21.298122              127  \n",
       "128       21.298826              129  \n",
       "135       21.298826              129  \n",
       "86        21.772689              131  \n",
       "65        27.539971              131  \n",
       "79        21.513717              133  \n",
       "129       21.989998              134  \n",
       "147       21.989998              134  \n",
       "68        20.036217              136  \n",
       "99        22.022716              137  \n",
       "25        23.524668              138  \n",
       "69        22.601106              139  \n",
       "125       20.505853              140  \n",
       "96        23.062741              141  \n",
       "12        26.076043              142  \n",
       "138       20.090794              143  \n",
       "117       22.666275              144  \n",
       "82        26.400947              145  \n",
       "42        27.602355              146  \n",
       "98        14.214078              147  \n",
       "120       14.754321              148  \n",
       "76        14.754321              148  \n",
       "62         1.800000              150  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res = res.sort_values(\"mean_test_score\", ascending=False) #.iloc[103].params\n",
    "#res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimators': [('RF',\n",
       "   RandomForestClassifier(class_weight={0: 1, 1: 5}, criterion='entropy',\n",
       "                          max_features=0.16, max_leaf_nodes=45, n_estimators=1000,\n",
       "                          n_jobs=-1, random_state=0)),\n",
       "  ('ADA_2',\n",
       "   AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight={0: 1,\n",
       "                                                                          1: 4},\n",
       "                                                            max_depth=2),\n",
       "                      learning_rate=0.3, n_estimators=28, random_state=0)),\n",
       "  ('LR_bis',\n",
       "   LogisticRegression(C=1.2, max_iter=2000, random_state=0, solver='liblinear')),\n",
       "  ('LDA_bis', LinearDiscriminantAnalysis(shrinkage='auto', solver='eigen')),\n",
       "  ('G_NB_bis', GaussianNB()),\n",
       "  ('RF_bis',\n",
       "   RandomForestClassifier(criterion='entropy', max_features=0.16,\n",
       "                          max_leaf_nodes=45, n_estimators=1000, n_jobs=-1,\n",
       "                          random_state=0))]}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[103].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -171.9 std =  19.45481945431517\n"
     ]
    }
   ],
   "source": [
    "# evaluating the stacking model\n",
    "\n",
    "cv_result = compute_cv(stack, X, y, 10, scorer=loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**getting the stacking predictions on a .txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predictions of the stacking model\n",
    "\n",
    "stack  = stack.fit(X, y)\n",
    "y_pred = stack.predict(df_test)\n",
    "if len(y_pred[y_pred==0]) >1: \n",
    "    y_pred+=1\n",
    "get_txt(y_pred, filename = f\"Stacking_Predictions_{int(abs(cv_result.mean()))}pnt.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Soft-voting (weighted average**)\n",
    "\n",
    "Puoi anche dare pesi diversi a ciascun calssifier.\n",
    "\n",
    "Contro: fitta il voting ensemble su un df, quindi puoi usare solo un df (quindi, siccome svc richiedere standardizzazione, devi usare standardizzazione su tutto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[('lr', clf_1), ('rf', clf_2), ('bnb', clf_3), ('svc', clf_4), ('c', clf_5), ('c2', clf_6)],\n",
    "    voting='soft')\n",
    "\n",
    "classifiers = [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6, ensemble_clf]\n",
    "labels =  [i for i in range(len(classifiers))] \n",
    "for clf, label in zip(classifiers, labels):\n",
    "    scores = cross_val_score(clf, X, y, scoring=loss_function, cv=10)\n",
    "    print(\"Score : %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "# getting the predictions of the soft-voting model\n",
    "\n",
    "ensemble_clf.fit(X,y)\n",
    "y_pred = ensemble_clf.predict(df_test)\n",
    "if len(y_pred[y_pred==0]) >1: \n",
    "    y_pred+=1\n",
    "#get_txt(y_pred, filename = \"Soft-Voting_Predictions.txt\")\n",
    "# score=259 on website\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Variable Importance\n",
    "\n",
    "references:\n",
    "- https://www.kaggle.com/deepdivelm/feature-engineering-lightgbm-exploring-performance\n",
    "- https://scikit-learn.org/stable/modules/ensemble.html\n",
    "- https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python\n",
    "- https://www.kaggle.com/dlarionov/feature-engineering-xgboost\n",
    "\n",
    "\n",
    "**[flaw](https://scikit-learn.org/stable/modules/ensemble.html#random-forest-feature-importance):** this rf feature importance metric favors high cardinality features: features with many unique values\n",
    "\n",
    "\n",
    "**note:** requires having ran the rf and adaboost models in the model optimization section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -177.0 std =  21.014280858501916\n"
     ]
    }
   ],
   "source": [
    "#fitto il best model (e faccio feature importances )\n",
    "df = train_enh_pre_stded\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "class_weights = {1:1, 2:5}\n",
    "RF = RandomForestClassifier(n_estimators= 1000,\n",
    "                            #n_jobs=-1,\n",
    "                            random_state=10,\n",
    "                            class_weight= class_weights,\n",
    "                            #min_samples_leaf = 50,\n",
    "                            #min_samples_split =3,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features= 0.16) #'log2'\n",
    "\n",
    "cv_result = compute_cv(RF, X, y, 10, loss_function)\n",
    "#cv_result, _, _  = k_folds_upsampling(RF, df, 7, ratio=0, k_neighbors=800)\n",
    "\n",
    "RF.fit(X,y)\n",
    "feature_importances[\"rf\"] = RF.fit(X, y).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cols.shape, feature_importances[\"rf\"].shape, feature_importances[\"ada_d1\"].shape, feature_importances[\"ada_d2\"].shape)\n",
    "cols = df.drop(\"y\",axis=1).columns.values\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "                                   'Random_Forest': feature_importances[\"rf\"],\n",
    "                                   #'AdaBoost_(d=1)': feature_importances[\"ada_d1\"],\n",
    "                                   #'AdaBoost_(d=2)': feature_importances[\"ada_d2\"]\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           0.19343328724070377,
           0.0891597615815423,
           0.13331356962357352,
           0.05743417013350284,
           0.08380700141531781,
           0.004277589428638834,
           0.009795921170681418,
           0.005055580475377733,
           0.004974542169178626,
           0.0075788105318837125,
           0.08131841679549957,
           0.04499887691336288,
           0.04492785121234663,
           0.012235016641894964,
           0.010740875189996673,
           0.03021064675023297,
           0.0070308598775814055,
           0.04851192849789609,
           0.006496290440908197,
           0.028473967409638895,
           0.009829490278009579,
           0.06875341352209371,
           0.007004458127868609,
           0.010637674572269325
          ],
          "colorscale": [
           [
            0,
            "rgb(12,51,131)"
           ],
           [
            0.25,
            "rgb(10,136,186)"
           ],
           [
            0.5,
            "rgb(242,211,56)"
           ],
           [
            0.75,
            "rgb(242,143,56)"
           ],
           [
            1,
            "rgb(217,30,30)"
           ]
          ],
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "time",
          "chargesMonth",
          "chargesTotal",
          "avg_surprise",
          "avg_expenditure",
          "col0_Male",
          "col1_Yes",
          "col2_Yes",
          "col3_No phone service",
          "col3_Yes",
          "col4_Fiber optic",
          "col4_No",
          "col5_Yes",
          "col6_Yes",
          "col7_Yes",
          "col8_Yes",
          "col9_Yes",
          "col10_No internet service",
          "col10_Yes",
          "col11_Yes",
          "col12_Credit card (automatic)",
          "col12_Electronic check",
          "col12_Mailed check",
          "col13_1"
         ],
         "type": "scatter",
         "x": [
          "time",
          "chargesMonth",
          "chargesTotal",
          "avg_surprise",
          "avg_expenditure",
          "col0_Male",
          "col1_Yes",
          "col2_Yes",
          "col3_No phone service",
          "col3_Yes",
          "col4_Fiber optic",
          "col4_No",
          "col5_Yes",
          "col6_Yes",
          "col7_Yes",
          "col8_Yes",
          "col9_Yes",
          "col10_No internet service",
          "col10_Yes",
          "col11_Yes",
          "col12_Credit card (automatic)",
          "col12_Electronic check",
          "col12_Mailed check",
          "col13_1"
         ],
         "y": [
          0.19343328724070377,
          0.0891597615815423,
          0.13331356962357352,
          0.05743417013350284,
          0.08380700141531781,
          0.004277589428638834,
          0.009795921170681418,
          0.005055580475377733,
          0.004974542169178626,
          0.0075788105318837125,
          0.08131841679549957,
          0.04499887691336288,
          0.04492785121234663,
          0.012235016641894964,
          0.010740875189996673,
          0.03021064675023297,
          0.0070308598775814055,
          0.04851192849789609,
          0.006496290440908197,
          0.028473967409638895,
          0.009829490278009579,
          0.06875341352209371,
          0.007004458127868609,
          0.010637674572269325
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Random_Forest feature importance"
        },
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": {
          "text": "Feature Importance"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"63675b11-017c-4563-b914-d904eb878253\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"63675b11-017c-4563-b914-d904eb878253\")) {                    Plotly.newPlot(                        \"63675b11-017c-4563-b914-d904eb878253\",                        [{\"marker\": {\"color\": [0.19343328724070377, 0.0891597615815423, 0.13331356962357352, 0.05743417013350284, 0.08380700141531781, 0.004277589428638834, 0.009795921170681418, 0.005055580475377733, 0.004974542169178626, 0.0075788105318837125, 0.08131841679549957, 0.04499887691336288, 0.04492785121234663, 0.012235016641894964, 0.010740875189996673, 0.03021064675023297, 0.0070308598775814055, 0.04851192849789609, 0.006496290440908197, 0.028473967409638895, 0.009829490278009579, 0.06875341352209371, 0.007004458127868609, 0.010637674572269325], \"colorscale\": [[0.0, \"rgb(12,51,131)\"], [0.25, \"rgb(10,136,186)\"], [0.5, \"rgb(242,211,56)\"], [0.75, \"rgb(242,143,56)\"], [1.0, \"rgb(217,30,30)\"]], \"showscale\": true, \"size\": 25, \"sizemode\": \"diameter\", \"sizeref\": 1}, \"mode\": \"markers\", \"text\": [\"time\", \"chargesMonth\", \"chargesTotal\", \"avg_surprise\", \"avg_expenditure\", \"col0_Male\", \"col1_Yes\", \"col2_Yes\", \"col3_No phone service\", \"col3_Yes\", \"col4_Fiber optic\", \"col4_No\", \"col5_Yes\", \"col6_Yes\", \"col7_Yes\", \"col8_Yes\", \"col9_Yes\", \"col10_No internet service\", \"col10_Yes\", \"col11_Yes\", \"col12_Credit card (automatic)\", \"col12_Electronic check\", \"col12_Mailed check\", \"col13_1\"], \"type\": \"scatter\", \"x\": [\"time\", \"chargesMonth\", \"chargesTotal\", \"avg_surprise\", \"avg_expenditure\", \"col0_Male\", \"col1_Yes\", \"col2_Yes\", \"col3_No phone service\", \"col3_Yes\", \"col4_Fiber optic\", \"col4_No\", \"col5_Yes\", \"col6_Yes\", \"col7_Yes\", \"col8_Yes\", \"col9_Yes\", \"col10_No internet service\", \"col10_Yes\", \"col11_Yes\", \"col12_Credit card (automatic)\", \"col12_Electronic check\", \"col12_Mailed check\", \"col13_1\"], \"y\": [0.19343328724070377, 0.0891597615815423, 0.13331356962357352, 0.05743417013350284, 0.08380700141531781, 0.004277589428638834, 0.009795921170681418, 0.005055580475377733, 0.004974542169178626, 0.0075788105318837125, 0.08131841679549957, 0.04499887691336288, 0.04492785121234663, 0.012235016641894964, 0.010740875189996673, 0.03021064675023297, 0.0070308598775814055, 0.04851192849789609, 0.006496290440908197, 0.028473967409638895, 0.009829490278009579, 0.06875341352209371, 0.007004458127868609, 0.010637674572269325]}],                        {\"autosize\": true, \"hovermode\": \"closest\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Random_Forest feature importance\"}, \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": {\"text\": \"Feature Importance\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('63675b11-017c-4563-b914-d904eb878253');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Feature_Importance_plot(feature_dataframe, \"Random_Forest\") \n",
    "#Feature_Importance_plot(feature_dataframe, \"AdaBoost_(d=1)\")\n",
    "#Feature_Importance_plot(feature_dataframe, \"AdaBoost_(d=2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" LR feature importance \"\"\"\n",
    "exclusion_list = []\n",
    "exclusion_list = []  #, \"chargesMonth\", \"chargesTotal\", \"time\"]\n",
    "\n",
    "# senza time charges total diventa proxy di time e quindi predice churn, \n",
    "# con time probablmente cattura il costo del servizio\n",
    "# 2 fattori: prezzi maggiori portano ad andarsene, prezzi maggiori implicano più servizi\n",
    "df = train_enh_pre_stded[[col for col in train_enh_stded.columns if col not in exclusion_list ]] \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "\n",
    "# get feature imporatnce over 10 fits\n",
    "importances = []\n",
    "for i in range(0,10):\n",
    "        LR_stded = LogisticRegression(max_iter=2000,\n",
    "                                random_state=i+10,\n",
    "                                solver = 'liblinear',  \n",
    "                                class_weight= weights) \n",
    "        LR_stded.fit(X, y)\n",
    "        importances.append(LR_stded.coef_[0])\n",
    "\n",
    "# get mean feature importance\n",
    "num_arrays = len(importances)\n",
    "arr_len = importances[0].shape[0]\n",
    "importance = np.zeros(arr_len)\n",
    "for arr in importances:\n",
    "    importance += arr\n",
    "importance = importance/num_arrays        \n",
    "\n",
    "# preparations for plotting\n",
    "#importance = LR_stded.coef_[0]\n",
    "x =df.columns.drop(\"y\")\n",
    "y =importance\n",
    "df = pd.DataFrame({_x:_y for _x,_y in zip(x,y)}, index=[0])\n",
    "df = df.T.sort_values(df.index[-1], ascending=False).T\n",
    "x = df.columns\n",
    "y = df.values[0]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(17, 8))\n",
    "plt.title('Logistic Regression Feature Importance')\n",
    "plt.figure(figsize=[15,10])\n",
    "ax.bar(x,y,align='center')\n",
    "canc = plt.setp(ax.get_xticklabels(), rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" confirming sign interpretation \"\"\"\n",
    "exclusion_list = []\n",
    "exclusion_list = [i for i in train_enh_pre_stded.columns if i not in [\"y\", \"time\"]]  #, \"chargesMonth\", \"chargesTotal\", \"time\"]\n",
    "\n",
    "# senza time charges total diventa proxy di time e quindi predice churn, \n",
    "# con time probablmente cattura il costo del servizio\n",
    "# 2 fattori: prezzi maggiori portano ad andarsene, prezzi maggiori implicano più servizi\n",
    "df = train_enh_pre_stded[[col for col in train_enh_stded.columns if col not in exclusion_list ]] \n",
    "X, y = create_X_y(df)\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "\n",
    "# get feature imporatnce over 10 fits\n",
    "importances = []\n",
    "for i in range(0,10):\n",
    "        LR_stded = LogisticRegression(max_iter=2000,\n",
    "                                random_state=i+10,\n",
    "                                solver = 'liblinear',  \n",
    "                                class_weight= weights) \n",
    "        LR_stded.fit(X, y)\n",
    "        importances.append(LR_stded.coef_[0])\n",
    "\n",
    "# get mean feature importance\n",
    "num_arrays = len(importances)\n",
    "arr_len = importances[0].shape[0]\n",
    "importance = np.zeros(arr_len)\n",
    "for arr in importances:\n",
    "    importance += arr\n",
    "importance = importance/num_arrays        \n",
    "\n",
    "# preparations for plotting\n",
    "#importance = LR_stded.coef_[0]\n",
    "x =df.columns.drop(\"y\")\n",
    "y =importance\n",
    "df = pd.DataFrame({_x:_y for _x,_y in zip(x,y)}, index=[0])\n",
    "df = df.T.sort_values(df.index[-1], ascending=False).T\n",
    "x = df.columns\n",
    "y = df.values[0]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(17, 8))\n",
    "plt.title('Logistic Regression Feature Importance')\n",
    "plt.figure(figsize=[15,10])\n",
    "ax.bar(x,y,align='center')\n",
    "canc = plt.setp(ax.get_xticklabels(), rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6055444 , 0.3944556 ],\n",
       "       [0.22525583, 0.77474417],\n",
       "       [0.19328964, 0.80671036],\n",
       "       ...,\n",
       "       [0.35065438, 0.64934562],\n",
       "       [0.57750367, 0.42249633],\n",
       "       [0.65069602, 0.34930398]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_stded.predict_proba(df.drop(\"y\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.075011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.279118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.952547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>1.210987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1.619201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-0.421869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.557845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.884416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time\n",
       "0     0.680309\n",
       "1    -1.075011\n",
       "2    -1.279118\n",
       "3    -0.544333\n",
       "4    -0.952547\n",
       "...        ...\n",
       "3995  1.210987\n",
       "3996  1.619201\n",
       "3997 -0.421869\n",
       "3998  0.557845\n",
       "3999  0.884416\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_enh_pre_stded[[col for col in train_enh_stded.columns if col not in exclusion_list ]] \n",
    "X, y = create_X_y(df)\n",
    "df.drop(\"y\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling\\downsampling trials\n",
    "note: using ratio=0 means no oversampling is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(y_true, y_predict):\n",
    "    \"\"\" Crea un custom scorer da passare al cv_scores di SkLearn \"\"\"\n",
    "    \n",
    "    # sottrai, così da avere zero se la predizione è corretta, 1 se FN e -1 se FP\n",
    "    score_arr = y_predict - y_true\n",
    "    score_arr[score_arr==-1] = 5\n",
    "    #print(\"errori da 5 su errori totali: \", round(len(score_arr[score_arr==5])/len(score_arr) ,2) )\n",
    "    \n",
    "    return np.sum(score_arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds_upsampling(model, train_df, k=10, thr=0.5, ratio=0.5, k_neighbors=5):\n",
    "    \"\"\" requires model.predict_proba, assumes l=2 with y={1,2} \"\"\"\n",
    "    \n",
    "    X, y = create_X_y(train_df)\n",
    "    kf = KFold(n_splits=k)\n",
    "    \n",
    "    cv_scores = []\n",
    "    y_tr_y_pr = []\n",
    "    y_probs   = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # smote upsampling\n",
    "            if ratio> 0:                \n",
    "                sm = imblearn.over_sampling.SMOTE(random_state=0, sampling_strategy=ratio,k_neighbors=k_neighbors)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)    \n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            proba = model.predict_proba(X_test)\n",
    "            y_pred = np.array([1 if i[0]> thr else 2 for i in proba ])\n",
    "\n",
    "            score = custom_scorer(y_test, y_pred)\n",
    "            cv_scores.append(score)\n",
    "            y_tr_y_pr.append([y_test, y_pred])\n",
    "            y_probs.append(proba)\n",
    "    \n",
    "    cv_scores = np.array(cv_scores)\n",
    "    print(\"mean = \", cv_scores.mean(), \"std =\", cv_scores.std())\n",
    "    print(\"normalized_mean = \", cv_scores.mean()/len(y_test), \"test obs in k-fold = \", len(y_test))\n",
    "    return cv_scores, y_tr_y_pr, y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  252.57142857142858 std = 16.378183597676017\n",
      "normalized_mean =  0.44233174881160875 test obs in k-fold =  571\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" upsampling \"\"\"\n",
    "df = train_enh_stded #[[i for i in train_enh_dum.columns if i!=\"avg_surprise2\"]]\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        #C = 0.7,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "cv_result, _, _  = k_folds_upsampling(LR, df, 7, ratio=0.5, k_neighbors=800)\n",
    "\n",
    "LR.fit(X, y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(df, LR)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = LR.predict(df_test)\n",
    "get_txt(y_pred, filename = \"LR_Predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  0.7206113833003231 std =  0.015154569568627653\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" downsampling + upsampling \"\"\"\n",
    "df = train_enh_dum.copy(deep=True) #[[i for i in train_enh_dum.columns if i!=\"avg_surprise2\"]]\n",
    "df_test = test_enh_dum\n",
    "\n",
    "# da 1500 in poi peggiora in remoto, da 800 e 1200 migliora\n",
    "df = df.sort_values(\"y\")\n",
    "df = df.iloc[1130:,:]\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        #C = 0.7,\n",
    "                        random_state=100,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "cv_result = compute_cv(LR, X, y, 10, \"balanced_accuracy\")\n",
    "#cv_result, _, _  = k_folds_upsampling(LR, df, 7, ratio=0.8, k_neighbors=800)\n",
    "\n",
    "#ratio = 1\n",
    "#k_neighbors = 30\n",
    "#sm = imblearn.over_sampling.SMOTE(random_state=0, sampling_strategy=ratio,k_neighbors=k_neighbors)\n",
    "#X, y = sm.fit_resample(X, y)    \n",
    "\n",
    "LR.fit(X, y)\n",
    "fpr, tpr, roc_auc = find_ROC_Score(df, LR)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = LR.predict(df_test)\n",
    "get_txt(y_pred, filename = \"LR_Predictions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  162.1 std = 21.84696775298577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[160.4,  93.6],\n",
       "       [ 13.7,  92.3]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" confusion matrix \"\"\"\n",
    "df = train_enh_stded \n",
    "df = df.sort_values(\"y\")\n",
    "df = df.iloc[400:,:]\n",
    "\n",
    "weights = {1:1, 2:4.25}\n",
    "LR = LogisticRegression(max_iter=2000,\n",
    "                        #C = 0.7,\n",
    "                        random_state=0,\n",
    "                        solver = 'liblinear',  # liblinear good for small datasets\n",
    "                        class_weight= weights) \n",
    "\n",
    "cv_scores, y_tr_y_pr, _ = custom_k_folds(LR, df)\n",
    "\n",
    "conf_matrices = np.zeros((2,2))\n",
    "for i in range(len(y_tr_y_pr)):\n",
    "    conf_matrix = confusion_matrix(y_tr_y_pr[i][0], y_tr_y_pr[i][1])\n",
    "    conf_matrices += conf_matrix     \n",
    "               \n",
    "conf_matrices/len(y_tr_y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  -145.9 std =  21.97930845135943\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" fit \"\"\"\n",
    "\n",
    "df = train_enh_dum\n",
    "X, y = create_X_y(df)\n",
    "\n",
    "\n",
    "prior_l = 0.35 \n",
    "priors = [prior_l, 1-prior_l]\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis(solver = \"eigen\",\n",
    "                                shrinkage=\"auto\",\n",
    "                                priors=priors) #priors=priors\n",
    "\n",
    "cv_result = compute_cv(LDA, X, y, 10, scorer=loss_function)\n",
    "\n",
    "LDA.fit(X,y)\n",
    "\n",
    "fpr, tpr, roc_auc = find_ROC_Score(df, LDA)\n",
    "plot_ROC(fpr, tpr, roc_auc)\n",
    "\n",
    "y_pred = LDA.predict(df_test)\n",
    "get_txt(y_pred, filename = \"LDA_Predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'chargesMonth',\n",
       " 'chargesTotal',\n",
       " 'avg_surprise',\n",
       " 'avg_surprise2',\n",
       " 'avg_expenditure',\n",
       " 'col3_No',\n",
       " 'col3_No phone service',\n",
       " 'col3_Yes',\n",
       " 'col4_DSL',\n",
       " 'col4_Fiber optic',\n",
       " 'col4_No',\n",
       " 'col5_No',\n",
       " 'col5_No internet service',\n",
       " 'col5_Yes',\n",
       " 'col6_No',\n",
       " 'col6_No internet service',\n",
       " 'col6_Yes',\n",
       " 'col7_No',\n",
       " 'col7_No internet service',\n",
       " 'col7_Yes',\n",
       " 'col8_No',\n",
       " 'col8_No internet service',\n",
       " 'col8_Yes',\n",
       " 'col9_No',\n",
       " 'col9_No internet service',\n",
       " 'col9_Yes',\n",
       " 'col10_No',\n",
       " 'col10_No internet service',\n",
       " 'col10_Yes',\n",
       " 'col11_No',\n",
       " 'col11_Yes',\n",
       " 'col12_Bank transfer (automatic)',\n",
       " 'col12_Credit card (automatic)',\n",
       " 'col12_Electronic check',\n",
       " 'col12_Mailed check',\n",
       " 'col13_0',\n",
       " 'col13_1']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "X_train, X_test, y_train, y_test = tt_split(dset_enh_dum, test_size=0.18)\n",
    "\n",
    "RF_class_weights  = {1:1, 2:5}\n",
    "RF = RandomForestClassifier(n_estimators= 1000,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0,\n",
    "                            class_weight= RF_class_weights,\n",
    "                            max_leaf_nodes = 45,\n",
    "                            criterion='entropy',\n",
    "                            max_features=\"log2\")\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "result = permutation_importance(\n",
    "    RF, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "\n",
    "feature_names = [f'{dset_enh_dum.drop(\"y\",axis=1).columns[i]}' for i in range(len(dset_enh_dum.columns)-1)]\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAALICAYAAACJhQBYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACM00lEQVR4nOzdd7xsVXn/8c8XEAuKSERFEEGDGrsEuzHYRWPX2AsaldhTVIxJsEWxxxaxi12xYsSuV2NBAaVafiKioKiIBURRwef3x9qHO/dwzr3nzt17z5zD5/16zeuc2TOznzVr9pkz8+y1npWqQpIkSZIkaZ5tNesGSJIkSZIkbYoJDEmSJEmSNPdMYEiSJEmSpLlnAkOSJEmSJM09ExiSJEmSJGnumcCQJEmSJElzzwSGJEmLJPm3JG+cdTsuSuzz6SU5Mck+s27HxiS5ZZLvJfltkntu4r67J6kk23TX1yX5h1EaumE79kly2grv+6wk7xi6TZJ0UWcCQ5LUqySnJPl990Vl4XLlHvZ5+77auClV9fyqGv0L01IuKl+M5qnPx7S5x3aStyZ53uS2qrpOVa3rvXH9eg7w6qq6dFV9eNaNkSStTiYwJElDuFv3RWXh8pNZNmbhTO5qs1rbvVb5emyRqwInzroRkqTVzQSGJGkUSS6b5E1JTk/y4yTPS7J1d9vVk3wuyZlJfpHknUl26G57O7Ab8NFuNMfTlhraPXkmuxu18P4k70hyFvCIjcVfoq0XjHqYGM6+X5JTk/wqyf5JbpzkuCS/TvLqicc+IsmXk7wqyW+SfCfJ7SZuv3KSw5L8MslJSR69KO5ku/cH/g24f/fcj+3ut1+Sbyc5O8nJSR47sY99kpyW5F+S/Lx7vvtN3H7JJC9N8sOufV9Kcsnutpsl+Ur3nI6dnJbQPa+Tu5g/SPLgZfpugxECi1+rJE/v+v/sJN9d6Jtl+vzhSX7UHRPPXPQcDulei293x8SyQ/27fT2pa/8vkrw4yVYTtz+y28+vknwyyVUXPfbxSb4HfG+if5820b/3THKXJP+ve13/bSX9kSWO7W77oUl+2r0+X0xynW77Y4AHA0/r7v/RbvvksX/xJP+d5Cfd5b+TXHwlx8YS/bapY/V9Sd7WvZYnJtl7mf18H7jaxPO8eBaNPMmUI426xx2a9jdzdpLjk1wjyTO653hqkjuu8Dldsnu9fpXkW8CNl+iPDyQ5o/sbeNLmtleStGVMYEiSxnIIcB7wl8CNgDsCC1MGArwAuDLwV8BVgGcBVNVDgR+xflTHi1YY7x7A+4EdgHduIv5K3BTYE7g/8N/AM4HbA9cB/j7J3y6678nA5YEDgQ8m2bG77d3Aad1zvS/w/EwkOBa1+03A84H3ds/9Bt19fg78HbA9sB/w8iR7TezjSsBlgV2ARwGvSXK57raXAH8N3ALYEXga8OckuwAfA57Xbf9X4ANJdkqyHfBKYN+qukz32GM2o+8ASHJN4AnAjbv93Ak4ZSMPuRVwTeB2wH8m+atu+4HA7rQvxXcAHrKC8PcC9gb2ovXxI7s23ZOWJLo3sBPwf7TXaNI9aa/ptbvrVwIuQevf/wTe0LXhr4G/6dp6tU01aCPH9sdpx9oVgG/Qjl+q6vXd7y/q7n+3JXb7TOBmwA2BGwA3Af594vaNHRuLbepYvTvwHtqxehjw6sU76Np99UXP8w/LxJvW3YC3A5cDvgl8kvYZdxfa1JXXTdx3Y8/pQODq3eVOwMMXHtQlvD4KHNvt93bAU5LcqefnIknaCBMYkqQhfDjtLP6vk3w4yRWBfYGnVNU5VfVz4OXAAwCq6qSq+nRV/aGqzgBeBvzt8rtfka9W1Yer6s+0L/rLxl+h51bVuVX1KeAc4N1V9fOq+jHtS++NJu77c+C/q+pPVfVe4LvAXZNchfal/Ondvo4B3gg8dKl2V9Xvl2pIVX2sqr5fzReAT9G+OC/4E/CcLv7hwG+Ba3Zfwh4JPLmqflxV51fVV7ovlA8BDq+qw7vYnwaOAu7S7fPPwHWTXLKqTq+qaaYDnA9cHLh2kotV1SlV9f2N3P/ZVfX7qjqW9sVxIYHz98Dzq+pXVXUaLbmyKS+sql9W1Y9oCagHdtsfC7ygqr5dVefREkY3nByF0d3+y4nX40/Af1XVn2hf4C8PvKKqzu765UTg+ito05Kq6s3dvv5AS+TdIMllV/jwB9Ne+593f0vPZsPja8ljY/FOVnisfqk7Xs6nJRBusHg/I/m/qvpk9/odSktEHTTx+uyeZIcVPKe/p72uv6yqU9nwuLoxsFNVPaeq/lhVJ9MSV5vzHiJJ2kImMCRJQ7hnVe3QXe5Jm/9+MeD0hcQG7azoFQCSXCHJe9KmFpwFvIP2pXBLnDrx+0bjr9DPJn7//RLXLz1x/cdVVRPXf0g743tl4JdVdfai23ZZpt1LSrJvkiO6YfC/piUZJvvrzO7L3ILfde27PG3kwFJJg6sC95tIPP2a9mVv56o6hzbyZH9aH34sybU21c7Fquok4Cm0L+U/717zjRV4/ekSzwFaP0720yb7bNF9Fl4PaM/7FRPP+Ze0EUEbe03O7L60Q3vtYePHw4ol2TrJQUm+3/0tnNLdtNK/hyvTnt+CyecKyx8bS+1nU8fq4tfnEplNnZDFff+LJV6fS7Pp57T4uJrsx6sCV1709/FvwBX7eQqSpJUwgSFJGsOpwB+Ay08kNravqut0t78AKOD6VbU9bTRAJh5fG+6Oc4BLLVxJq2Wx06L7TD5mU/H7tkuSyfbvBvyku+yY5DKLbvvxMu2+0PWunsEHaFNBrlhVOwCHs2F/LecXwLm0IfKLnQq8faJ/dqiq7arqIIDuDPcdgJ2B79DOPi9lg9eGNmVh/ZOpeldV3Yr2hbCAF66g3YudDuw6cf0qK3jM5H0WXg9oz/uxi573JavqK5PNnqKNCzbaH0vs+0G0KS63p0312L3bnmXuv9hPaH27YPK5bo6VHKtbYlP9MoRNPafTufBxsuBU4AeLjpPLVNVdkCSNxgSGJGlwVXU6bZrDS5Nsn2SrtMKdC9NELkMbyv7rrhbDUxft4me0egcL/h/tbO9dk1yMNsf/4lsQv29XAJ6U5GJJ7ker63F4Nyz9K8ALklwiyfVpdQjeuZF9/Yw2BH7hf/a2tOd6BnBekn1p9Tw2qZtO82bgZV1Bwq2T3LxLirwDuFuSO3XbL5FW9HHXJFdMcveuFsYfaK/V+cuEOQa4S5Idk1yJNuICaDUwkty2i3cu7ez4cvvZmPcBz0hyue54ecIKHvPU7v5XAZ4MvLfbfnC3r4VCmZftXrO+HMMy/dFZfGxfhtbHZ9K+4D9/E/df7N3Av3e1Sy5Pq9Gx2cUxpzxWN8cxwAO6v5G9afUoBrWC5zR5XO0KPHHi4V8HzkorQnvJ7m/kukk2KPQpSRqWCQxJ0lgeRvvy/S3gV7RClTt3tz2bVlzxN7RCkh9c9NgX0L6U/TrJv1bVb4DH0eav/5h2NnfZVShWEL9vX6MVYfwF8F/AfavqzO62B9LOqv8E+BBwYFdvYjmHdj/PTPKNbvj7k2hftn5FO2N/2Ga07V+B44EjadMlXghs1X25uwdtWPwZtDPOT6V9VtgK+Jeuzb+k1Sd53DL7fzutXsUptKTReyduuzhwEK1ffkpL9Pwbm+85tNf7B8BnaK/lpgpDfgQ4mvbF+WO0AqlU1YdoffCebsrGCbR6KX3ZWH/AomMbeBtt6sKPacfqEYvu/yZaDZFfJ/nwEvGeR6tdchztdf5Gt20am3usbo7/oI0E+hXt7/9dPe13Uzb2nJ5N6/sf0F6rty88qJuScjdacdQf0I7hN9JGyUiSRpINp+hKkqQtkeQRwD900yQ0giT/CDygqpYcUZOkgD27GhySJGmVcgSGJElaVZLsnOSW3VSga9JGh3xo1u2SJEnDmkWlaEmSpC2xLW0VmT2AX9OWyvyfWTZIkiQNb6ZTSJLcGXgFsDXwxoVK5xO3p7v9LrTluR5RVd/oCnC9jVax+s/A66vqFd1jngU8mjZ/F+DfunXOJUmSJEnSKjWzERjdknevAe5AK8R1ZJLDqupbE3fbl1YEbU/gpsBru5/nAf/SJTMuAxyd5NMTj315Vb1krOciSZIkSZKGNcspJDcBTqqqkwGSvIdW/XwygXEP4G3VhokckWSHJDt3y+GdDlBVZyf5NrDLoseu2OUvf/nafffdp38mkiRJkiSpF0cfffQvqmqnxdtnmcDYhbZE24LTaKMrNnWfXeiSFwBJdgduRFuybsETkjyMtozYv1TVrxYHT/IY4DEAu+22G0cdddTUT0SSJEmSJPUjyQ+X2j7LVUiyxLbFBTk2ep8klwY+ADylqs7qNr+Wtq74DWmJjpcuFbyqXl9Ve1fV3jvtdKHEjiRJkiRJmiOzTGCcBlxl4vquwE9Wep8kF6MlL95ZVR9cuENV/ayqzq+qPwNvoE1VkSRJkiRJq9gsExhHAnsm2SPJtsADgMMW3ecw4GFpbgb8pqpO71YneRPw7ap62eQDkuw8cfVewAnDPQVJkiRJkjSGmdXAqKrzkjwB+CRtGdU3V9WJSfbvbj8YOJy2hOpJtGVU9+sefkvgocDxSY7pti0sl/qiJDekTTU5BXjsKE9IkiRJkiQNJm2Bj4u2vffeuyziKUmSJEnS7CU5uqr2Xrx9llNIJEmSJEmSVsQEhiRJkiRJmnsmMCRJkiRJ0twzgSFJkiRJkuaeCQxJkiRJkjT3TGBIkiRJkqS5ZwJDkiRJkiTNPRMYkiRJkiRp7pnAkCRJkiRJc88EhiRJkiRJmnsmMCRJkiRJ0twzgSFJkiRJkuaeCQxJkiRJkjT3TGBIkiRJkqS5ZwJDkiRJkiTNPRMYkiRJkiRp7pnAkCRJkiRJc88ExhT22Wcf9tlnn1k3Q5IkSZKkiwwTGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7M01gJLlzku8mOSnJAUvcniSv7G4/Lsle3farJPl8km8nOTHJkyces2OSTyf5XvfzcmM+J0mSJEmS1L+ZJTCSbA28BtgXuDbwwCTXXnS3fYE9u8tjgNd2288D/qWq/gq4GfD4icceAHy2qvYEPttdlyRJkiRJq9gsR2DcBDipqk6uqj8C7wHuseg+9wDeVs0RwA5Jdq6q06vqGwBVdTbwbWCXiccc0v1+CHDPgZ+HJEmSJEka2CwTGLsAp05cP431SYgV3yfJ7sCNgK91m65YVacDdD+vsFTwJI9JclSSo84444xpn4MkSZIkSRrBLBMYWWJbbc59klwa+ADwlKo6a3OCV9Xrq2rvqtp7p5122pyHSpIkSZKkkc0ygXEacJWJ67sCP1npfZJcjJa8eGdVfXDiPj9LsnN3n52Bn/fcbkmSJEmSNLJZJjCOBPZMskeSbYEHAIctus9hwMO61UhuBvymqk5PEuBNwLer6mVLPObh3e8PBz4y3FOQJEmSJElj2GZWgavqvCRPAD4JbA28uapOTLJ/d/vBwOHAXYCTgN8B+3UPvyXwUOD4JMd02/6tqg4HDgLel+RRwI+A+430lCRJkiRJ0kBmlsAA6BIOhy/advDE7wU8fonHfYml62NQVWcCt+u3pZIkSZIkaZZmOYVEkiRJkiRpRUxgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae5tM+sGzLvdD/jYhbb99OQzl70N4JSD7jpomyRJkiRJuqhxBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXNvpgmMJHdO8t0kJyU5YInbk+SV3e3HJdlr4rY3J/l5khMWPeZZSX6c5JjucpcxnoskSZIkSRrOzBIYSbYGXgPsC1wbeGCSay+6277Ant3lMcBrJ257K3DnZXb/8qq6YXc5vNeGS5IkSZKk0c1yBMZNgJOq6uSq+iPwHuAei+5zD+Bt1RwB7JBkZ4Cq+iLwy1FbLEmSJEmSZmKWCYxdgFMnrp/Wbdvc+yzlCd2UkzcnudxSd0jymCRHJTnqjDPO2Jx2S5IkSZKkkc0ygZElttUU91nstcDVgRsCpwMvXepOVfX6qtq7qvbeaaedNrFLSZIkSZI0S7NMYJwGXGXi+q7AT6a4zwaq6mdVdX5V/Rl4A22qiiRJkiRJWsVmmcA4EtgzyR5JtgUeABy26D6HAQ/rViO5GfCbqjp9YztdqJHRuRdwwnL3lSRJkiRJq8M2swpcVecleQLwSWBr4M1VdWKS/bvbDwYOB+4CnAT8Dthv4fFJ3g3sA1w+yWnAgVX1JuBFSW5Im2pyCvDYsZ6TJEmSJEkaxswSGADdEqeHL9p28MTvBTx+mcc+cJntD+2zjZIkSZIkafZmOYVEkiRJkiRpRUxgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkubfiBEaS7YZsiCRJkiRJ0nI2mcBIcosk3wK+3V2/QZL/GbxlkiRJkiRJnZWMwHg5cCfgTICqOha49ZCNkiRJkiRJmrSiKSRVdeqiTecP0BZJkiRJkqQlbbOC+5ya5BZAJdkWeBLddBJJkiRJkqQxrGQExv7A44FdgNOAG3bXJUmSJEmSRrHJERhV9QvgwSO0RZIkSZIkaUkrWYXkRUm2T3KxJJ9N8oskDxmjcZIkSZIkSbCyKSR3rKqzgL+jTSG5BvDUQVslSZIkSZI0YSUJjIt1P+8CvLuqfjlgeyRJkiRJki5kJauQfDTJd4DfA49LshNw7rDNkiRJkiRJWm+TIzCq6gDg5sDeVfUn4BzgHkM3TJIkSZIkacFKRmBAW0L1DkkuMbHtbQO0R5IkSZIk6UI2mcBIciCwD3Bt4HBgX+BLmMCQJEmSJEkjWUkRz/sCtwN+WlX7ATcALj5oqyRJkiRJkiasJIHx+6r6M3Beku2BnwNXG7ZZkiRJkiRJ662kBsZRSXYA3gAcDfwW+PqQjZIkSZIkSZq0yQRGVT2u+/XgJJ8Atq+q44ZtliRJkiRJ0nqbnEKS5iFJ/rOqTgF+neQmwzdNkiRJkiSpWUkNjP8Bbg48sLt+NvCawVqkmdhnn33YZ599Zt0MSZIkSZKWtJIaGDetqr2SfBOgqn6VZNuB2yVJkiRJknSBlYzA+FOSrYECSLIT8OdBWyVJkiRJkjRhJQmMVwIfAq6Q5L+ALwHPH7RVkiRJkiRJEzY6hSTJVsAPgKcBtwMC3LOqvj1C2yRJkiRJkoBNJDCq6s9JXlpVNwe+M1KbJEmSJEmSNrCSKSSfSnKfJBm8NZIkSZIkSUtYySok/wxsB5yX5FzaNJKqqu0HbZkkSZIkSVJnkwmMqrrMGA2RJEmSJElaziankCS5V5LLTlzfIck9B22VJEmSJEnShJXUwDiwqn6zcKWqfg0cOFiLJEmSJEmSFllJAmOp+6ykdoYkSZIkSVIvVpLAOCrJy5JcPcnVkrwcOHrohkmSJEmSJC1YSQLjicAfgfcChwLnAo8fslGSJEmSJEmTVrIKyTnAASO0RZIkSZIkaUmbTGAkuQbwr8Duk/evqtsO1yxJkiRJkqT1VlKM81DgYOCNwPnDNkeSJEmSJOnCVpLAOK+qXjt4SyRJkiRJkpaxkiKeH03yuCQ7J9lx4TJ4yyRJkiRJkjorGYHx8O7nUye2FXC1/psjSZIkSZJ0YStZhWSPMRoiSZIkSZK0nGUTGEluW1WfS3LvpW6vqg8O1yxJkiRJkqT1NjYC42+BzwF3W+K2AkxgSJIkSZKkUSybwKiqA7uf+43XHEmSJEmSpAtbySokg0ly5yTfTXJSkgOWuD1JXtndflySvSZue3OSnyc5YdFjdkzy6STf635eboznIkmSJEmShjOzBEaSrYHXAPsC1wYemOTai+62L7Bnd3kM8NqJ294K3HmJXR8AfLaq9gQ+212XJEmSJEmr2EqWUR3KTYCTqupkgCTvAe4BfGviPvcA3lZVBRyRZIckO1fV6VX1xSS7L7HfewD7dL8fAqwDnt5nw6/0oIP63J0kSZIkSdqETY7ASHKpJP+R5A3d9T2T/F0PsXcBTp24flq3bXPvs9gVq+p0gO7nFZa6U5LHJDkqyVFnnHHGZjVckiRJkiSNayVTSN4C/AG4eXf9NOB5PcTOEttqivtMpapeX1V7V9XeO+20Ux+7lCRJkiRJA1lJAuPqVfUi4E8AVfV7lk4sbK7TgKtMXN8V+MkU91nsZ0l2Buh+/nwL2ylJkiRJkmZsJQmMPya5JN3IhyRXp43I2FJHAnsm2SPJtsADgMMW3ecw4GHdaiQ3A36zMD1kIw4DHt79/nDgIz20VZIkSZIkzdBKEhgHAp8ArpLknbSVPZ62pYGr6jzgCcAngW8D76uqE5Psn2T/7m6HAycDJwFvAB638Pgk7wa+ClwzyWlJHtXddBBwhyTfA+7QXZckSZIkSavYJlchqapPJ/kGcDPa1JEnV9Uv+gheVYfTkhST2w6e+L2Axy/z2Acus/1M4HZ9tE+SJEmSJM2HlaxCci/gvKr6WFX9L3BeknsO3jJJkiRJkqTOiqaQVNVvFq5U1a9p00okSZIkSZJGsZIExlL32eTUE0mSJEmSpL6sJIFxVJKXJbl6kqsleTlw9NANkyRJkiRJWrCSBMYTgT8C7wUOBc5lmcKakiRJkiRJQ1jJKiTnAAeM0BZJkiRJkqQlbTKBkeQawL8Cu0/ev6puO1yzJEmSJEmS1ltJMc5DgYOBNwLnD9scSZIkSZKkC1tJAuO8qnrt4C2RJEmSJElaxkqKeH40yeOS7Jxkx4XL4C2TJEmSJEnqrGQExsO7n0+d2FbA1fpvjiRJw9pnn30AWLdu3UzbIUmSpM2zklVI9hijIZIkSZIkSctZyQgMklwXuDZwiYVtVfW2oRolSZIkSZI0aSXLqB4I7ENLYBwO7At8CTCBIUmSJEmSRrGSIp73BW4H/LSq9gNuAFx80FZJkiRJkiRNWEkC4/dV9WfgvCTbAz/HAp6SJEmSJGlEK6mBcVSSHYA3AEcDvwW+PmSjJEmSJEmSJq1kFZLHdb8enOQTwPZVddywzZIkSZIkSVpvpauQXB/YfeH+Sf6yqj44YLskSZIkSZIusJJVSN4MXB84Efhzt7kAExiSJEmSJGkUKxmBcbOquvbgLZEkSZIkSVrGSlYh+WoSExiSJEmSJGlmVjIC4xBaEuOnwB+AAFVV1x+0ZZIkSZIkSZ2VJDDeDDwUOJ71NTAkSZIkSZJGs5IExo+q6rDBWyJJkiRJkrSMlSQwvpPkXcBHaVNIAHAZVUmSJEmSNJaVJDAuSUtc3HFim8uoSpIkSZKk0Ww0gZFka+AXVfXUkdojSZIkSZJ0IRtdRrWqzgf2GqktkiRJkiRJS1rJFJJjkhwGHAqcs7DRGhiSJEmSJGksK0lg7AicCdx2Yps1MCRJkiRJ0mg2mcCoqv3GaIgkSZIkSdJyNloDAyDJrkk+lOTnSX6W5ANJdh2jcZIkSZIkSbCCBAbwFuAw4MrALsBHu22SJEmSJEmjWEkCY6eqektVnddd3grsNHC7JEmSJEmSLrCSBMYvkjwkydbd5SG0op6SJEmSJEmjWMkqJI8EXg28nLb6yFe6bVqldj/gYxfa9tOTz1z2NoBTDrrroG2SJEmSJGljlk1gJHlhVT0duGlV3X3ENkmSJEmSJG1gY1NI7pLkYsAzxmqMJEmSJEnSUjY2heQTwC+A7ZKcBYQ2hSRAVdX2I7RPkiRJkiRp+REYVfXUqros8LGq2r6qLjP5c8Q2SpIkSZKki7iNrkKSZGtgu5HaIkmSJEmStKSNJjCq6nzgd0kuO1J7JEmSJEmSLmQly6ieCxyf5NPAOQsbq+pJg7VKkiRJkiRpwkoSGB/rLpIkSZIkSTOxyQRGVR2S5JLAblX13RHaJEmSJEmStIGN1sAASHI34BjasqokuWGSwwZulyRJkiRJ0gU2mcAAngXcBPg1QFUdA+wxWIskSZIkSZIWWUkC47yq+s2ibTVEYyRJkiRJkpaykiKeJyR5ELB1kj2BJwFfGbZZkiRJkiRJ661kBMYTgesAfwDeDZwFPGXANkmSJEmSJG1gJauQ/A54ZpIXtqt19vDNkiRJkiRJWm8lq5DcOMnxwHHA8UmOTfLXwzdNkiRJkiSpWUkNjDcBj6uq/wNIcivgLcD1h2yYJEmSJEnSgpXUwDh7IXkBUFVfApxGIkmSJEmSRrOSERhfT/I6WgHPAu4PrEuyF0BVfWPA9kmSJEmSJK0ogXHD7ueBi7bfgpbQuG2fDZIkSZIkSVpsJauQ3GaMhkiSJEmSJC1nJTUwJEmSJEmSZsoEhiRJkiRJmnsmMCRJkiRJ0txbSRFPktwC2H3y/lX1toHaJEmSJEmStIFNJjCSvB24OnAMcH63uQATGJIkSZIkaRQrGYGxN3DtqqqhGyNJkiRJkrSUldTAOAG40tANkSRJkiRJWs5KRmBcHvhWkq8Df1jYWFV3H6xVkiRJkiRJE1aSwHjW0I2QJKlvux/wsSW3//TkMzd6+ykH3XWwNkmSJGl6m0xgVNUXxmiIJEmSJEnScjZZAyPJzZIcmeS3Sf6Y5PwkZ43ROEmSJEmSJFhZEc9XAw8EvgdcEviHbtsWS3LnJN9NclKSA5a4PUle2d1+XJK9NvXYJM9K8uMkx3SXu/TRVkmSJEmSNDsrqYFBVZ2UZOuqOh94S5KvbGngJFsDrwHuAJwGHJnksKr61sTd9gX27C43BV4L3HQFj315Vb1kS9soSZIkSZLmw0oSGL9Lsi1wTJIXAacD2/UQ+ybASVV1MkCS9wD3ACYTGPcA3lZVBRyRZIckOwO7r+CxkiRJkiRpjVjJFJKHdvd7AnAOcBXgPj3E3gU4deL6ad22ldxnU499Qjfl5M1JLrdU8CSPSXJUkqPOOOOMaZ+DJEmSJEkawSYTGFX1QyDAzlX17Kr656o6qYfYWSrcCu+zsce+Frg6cEPaaJGXLhW8ql5fVXtX1d477bTTihosSZIkSZJmYyWrkNwNOAb4RHf9hkkO6yH2abTRHAt2BX6ywvss+9iq+llVnV9VfwbeQJuqIkmSJEmSVrGVTCF5Fi0J8GuAqjqGVoNiSx0J7Jlkj67GxgOAxYmRw4CHdauR3Az4TVWdvrHHdjUyFtwLOKGHtkqSJEmSpBlaSRHP86rqN8lSszamV1XnJXkC8Elga+DNVXVikv272w8GDgfuApwE/A7Yb2OP7Xb9oiQ3pE0pOQV4bK8NlyRJkiRJo1tJAuOEJA8Ctk6yJ/AkYIuXUQWoqsNpSYrJbQdP/F7A41f62G77Q/tomyRJkiRJmh8rmULyROA6wB+AdwNnAU8ZsE2SJEmSJM3cPvvswz777DPrZqizyREYVfU74JndRZIkSZIkaXTLJjA2tdJIVd29/+ZIUv8Wsubr1q2baTskSZIkTW9jIzBuDpxKmzbyNaDfKp6SJEmSJEkrtLEExpWAOwAPBB4EfAx498RqH5IkSZIkSaNYtohnVZ1fVZ+oqocDN6MtZbouyRNHa50kSZIkSRKbKOKZ5OLAXWmjMHYHXgl8cPhmSZIkSZIkrbexIp6HANcFPg48u6pOGK1VkiRJkiRJEzY2AuOhwDnANYAnJRfU8AxQVbX9wG2TJEmSJEkCNpLAqKpl62NIkiRJkiSNySSFJEmSJEmaeyYwJEmSJEnS3DOBIUmSpLm1zz77sM8++8y6GZKkOWACQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLm3jazboDmw5UedNCsmyBJkiRJ0rIcgSFJkiRJkuaeCQxJkiRJkjT3TGBIkiRJkqS5ZwJDkiRJkiTNPRMYkiRJkiRp7pnAkCRJkiRJc88EhiT1aJ999mGfffaZdTMkSZKkNccEhiRJkiRJmnsmMCRJkiRJ0twzgSFJkiRJkuaeCQxJkiRJkjT3TGBIkiRJkqS5ZwJDkiRJkiTNPRMYkiRJkjQDLr8ubZ5tZt0ASerT7gd87ELbfnrymcveBnDKQXcdtE2SJEmStpwJDEmSJM3ccknmjSWhTUBL82dhRMm6detm2g6tTSYwJEkXKVd60EGzboIkSdKaN0QyywSGRmVGVpIkSdKWGuJ7hVOR559FPCVJkiRJ0twzgSFJWpbV0SVJkjQvTGBIkiRJkqS5ZwJDkiRJkiTNPRMYWrMc+i5JkiRJa4cJDEmSJEmSNPdMYEiaGUfJSFK/fF+VJK1lJjAkSZIkSZoxk9CbZgJDkiRJkiTNPRMYkiRJkrTGeXZfa8E2s26AJEmSJElavXY/4GMX2vbTk89c9jaAUw6662bHcQSGJEmSpKl5Zl/SWByBIUlTWC6TvLFM8zRZZklrw8KXu3Xr1s20HZIkrWaOwJAkSZIkSXPPBIYkSZIkSZp7TiGRJEmSJG0Wp9NqFhyBIUmSJEmS5p4JDEmSJEmSNPdMYEiSJEmSpLlnAkOSJEkXefvss88Fy91KkuaTCQxJkiRJki4iVnPC1gSGJEmSJEmaey6jKq0SC1nSdevWzbQdkiTpomuppTE3tmwmuHSmdFF1pQcd1Ps+Z5rASHJn4BXA1sAbq+qgRbenu/0uwO+AR1TVNzb22CQ7Au8FdgdOAf6+qn41xvPRhvwHJ0mSJGlL+b1CC2Y2hSTJ1sBrgH2BawMPTHLtRXfbF9izuzwGeO0KHnsA8Nmq2hP4bHddkiRJkiStYrOsgXET4KSqOrmq/gi8B7jHovvcA3hbNUcAOyTZeROPvQdwSPf7IcA9B34e0pqzmgv7SJIkSVqbZjmFZBfg1InrpwE3XcF9dtnEY69YVacDVNXpSa6wVPAkj6GN6mC33XZbtpFjDT1abujTxkzbtrGe01Jx9jnixQCs67ENy/XdxoaVTdsHY71OYw2TG7PvxjLWcbdcP/Qda5pjDlbncbcx08QZ81id5XvDvMQZM9ZqjDPW39Ja/Jsd67PDau67WX+OHPPz3cbMe9/N+rjr+/PdmH+zs/x8t9q/v4xlrPbNcgRGlthWK7zPSh67UVX1+qrau6r23mmnnTbnoZIkSZIkaWSzHIFxGnCVieu7Aj9Z4X223chjf5Zk5270xc7Az3tttSRJkiRJUxpz9MpaM8sRGEcCeybZI8m2wAOAwxbd5zDgYWluBvymmx6yscceBjy8+/3hwEeGfiKSJEkaxrp161xCXJIEzHAERlWdl+QJwCdpS6G+uapOTLJ/d/vBwOG0JVRPoi2jut/GHtvt+iDgfUkeBfwIuN+IT0uSJEmSJA1gllNIqKrDaUmKyW0HT/xewONX+thu+5nA7fptqSRJkiRJmqVZTiGRJEmSJElakZmOwJAkTeen7zoAgCs96KAZt0SSdFFnjRJN8niYf6v5NTKBoVXPKr6SJEnqkycKpPlkAkO6CDP5I0m6KFrq/5//+yRp/pnAkLTmjTlMbjUPyZO05S5KiWHPUEuSxmYRT0mSJEmSNPccgSFJkrQKOQ1CknRR4wgMSdJc+Om7DrhgSLokSUvxf4V00WYCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkaZVzSLUkSbooMIEhSZIkSZLmnquQSJIkSWvQwsisKz3ooBm3RFq91q1bN+smaIIJDEkX4hu1pIsKv+BJkrR6OIVEkiRJkiTNPUdgSHPolIPueqFt+xzxYgDWLXHbauVIj/lyUTnuNP8cFSFJkpZiAkOj8gurJEmSLoo8UdAvv1dcNJnAkCRJkiRpxkzKbJo1MCRJkiRJ0txzBIYkSVoRa1NoLfPMpyTNPxMYkiRJki6SlqpLAdamkOaVU0gkSZIkSdLcM4EhSZIkSZLmnlNI5pzzjSVJkrQxToOQdFHhCAxJkiRJkjT3TGBIkiRJkqS55xQSSZpjDguWpLXHKcKSNB1HYEiSJEmSpLnnCAxJkiRJWiMcvam1zASGJEnSwNatWzfrJkiStOo5hUSSJEmSJM09R2BozfJslyRJkiStHSYwJEmStCzn00uS5oUJDEnSqPwyJEmSpGlYA0PaQj991wEXrOcuSZIkSRqGIzAkSdIGHCUjrQ3WA5O01pjAkCRJM7NUssREiSRJWopTSCRJkiRJ0txzBIYkSauEUzu0KU4ZkCStZSYwpFXCD6WSND2TP9LqMuu/WT93SfPJKSSSJEmSJGnumcCQJEmSJElzzykkc2LWw+QkSZIkSZpnjsCQJEmSJElzzwSGJEmSJEmaeyYwJEmSJEnS3DOBIUmSJEmS5p4JDEmSJEmSNPdMYEiSJEmSpLnnMqqSJEnSAE456K5Lbt/niBcDsG6Z2yVJS3MEhiRJkiRJmnuOwJCkVWjdunWzboIugjzuJEnSLDkCQ5IkSZIkzT0TGJIkDeCn7zqAn77rgFk3Q5Ikac0wgSFJkiRJkuaeCQxJkiRJkjT3TGBIkiRJkqS55yokkiRprrjaiSRJWoojMCRJkiRJ0twzgSFJkiRJkuaeU0gkScsacyi/0wak1cW/WUnS2ByBIUmSJEmS5p4jMOacZzckSZIkSXIEhiRJkiRJWgUcgSFthlMOuuuFtu1zxIsBWLfEbZIkSZKkfpjAkCRplXO6oSRJuigwgSFJki6yTP5IkrR6WANDkiRJkiTNPRMYkiRJkiRp7s0kgZFkxySfTvK97ufllrnfnZN8N8lJSQ7Y1OOT7J7k90mO6S4Hj/WcJEmSJEnScGY1AuMA4LNVtSfw2e76BpJsDbwG2Be4NvDAJNdeweO/X1U37C77D/kkJEmSJGla69atsxaPtBlmVcTzHsA+3e+HAOuApy+6z02Ak6rqZIAk7+ke960VPl6SpFG4xLIkjcMv+9JF26xGYFyxqk4H6H5eYYn77AKcOnH9tG7bph6/R5JvJvlCkr9ZrgFJHpPkqCRHnXHGGVvyXCRJkiRJ0sAGG4GR5DPAlZa46Zkr3cUS22oTjzkd2K2qzkzy18CHk1ynqs660I6qXg+8HmDvvffe1H4lSZKkXjiKQJKmM1gCo6puv9xtSX6WZOeqOj3JzsDPl7jbacBVJq7vCvyk+33Jx1fVH4A/dL8fneT7wDWAo7b8GUmSJEmSpFmZ1RSSw4CHd78/HPjIEvc5EtgzyR5JtgUe0D1u2ccn2akr/kmSqwF7AicP8gwkSZIkSdJoZpXAOAi4Q5LvAXforpPkykkOB6iq84AnAJ8Evg28r6pO3NjjgVsDxyU5Fng/sH9V/XKk5yRJkiRJkgYyk1VIqupM4HZLbP8JcJeJ64cDh2/G4z8AfKDXxkqSJEmSpJmb1QgMSZIkSZKkFZvJCAxJkiRJ0nhc/UZrgSMwJEmSJEnS3DOBIUmSJEmS5p4JDEmSJEmSNPdMYEiSJEmSpLlnAkOSJEmSJM09ExiSJEmSJGnumcCQJEmSJElzzwSGJEmSJEmaeyYwJEmSJEnS3DOBIUmSJEmS5t42s26AJElr0bp162bdBEmSpDXFERiSJEmSJGnumcCQJEmSJElzzwSGJEmSJEmae9bAkLaQ89wlSZIkaXiOwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzT0TGJIkSZIkae6ZwJAkSZIkSXPPBIYkSZIkSZp7JjAkSZIkSdLcM4EhSZIkSZLmngkMSZIkSZI090xgSJIkSZKkuWcCQ5IkSZIkzb1U1azbMHNJzgB+uJkPuzzwiwGaM8tYay3OmLHWWpwxY621OGPGWmtxxoy11uKMGWutxRkz1lqLM2astRZnzFhrLc6YsdZanDFjGWf+Y817nKtW1U6LN5rAmFKSo6pq77UUa63FGTPWWoszZqy1FmfMWGstzpix1lqcMWOttThjxlprccaMtdbijBlrrcUZM9ZaizNmLOPMf6zVGscpJJIkSZIkae6ZwJAkSZIkSXPPBMb0Xr8GY621OGPGWmtxxoy11uKMGWutxRkz1lqLM2astRZnzFhrLc6YsdZanDFjrbU4Y8Zaa3HGjGWc+Y+1KuNYA0OSJEmSJM09R2BIkiRJkqS5ZwJDkiRJkiTNPRMYkrSFkmyXZKuJ61sludQs27SaJLlVkv2633dKsses27Ra2HfTs++mZ99Nz76TVo8kf73EtrsNEGfHJbb53rAMExhzKsnWSa6cZLeFy6zb1Ickl0xyzYFjXGyJbZcfMuZakOQaST6b5ITu+vWT/PsIcS+X5PpDx5mId9MBdvtZYDJhcSngMwPEWXOSHAg8HXhGt+liwDtGiDvqcTcE+2569t307LvpreW+S3KZJJcecP9XTPKmJB/vrl87yaMGinXLJNt1vz8kycuSXHWIWF2MoftulOeT5ApJ7pXk8UkemeQmkyd3eoxziST3TfKKJIcmeVuSpyW5Tt+xgDckud5E7AcCQ3w2/miS7SfiXBv46ABx1gQTGJthrC94SZ4I/Az4NPCx7vK/Pcc4O8lZS1zOTnJWn7EmYt4NOAb4RHf9hkkO63H/t0lyGvCTJJ9KsvvEzZ/qK85EvLGOh4sleVKS93eXJy6VpOnBG2gfqv4EUFXHAQ8YIA5J1iXZvss4Hwu8JcnLhoi1hEMH2Oclquq3C1e63wcZgTHW8TDicXcv4O7AOQBV9RPgMgPEGe24s++2KI59N30c+276OPbd9HGul+SbwAnAt5IcneS6fccB3gp8Erhyd/3/AU8ZIA7Aa4HfJbkB8DTgh8Db+g4yYt8N+ny6z9+fpH1f2RfYGbg27Yv+8UmePfnlfAtjPQv4MnBz4GvA64D3AecBByX5dPpN1t0XOCTJXyV5NPA44I497n/B82lJjEunjfo4FHhI30GS3CnJa5McluQj3e937jvORuL/Zx/72aaPnVyEvAF4Ku2Phao6Lsm7gOf1HOfJwDWr6sye93uBqhrkH+YmPAu4CbCua8Mxi5IMW+pFwJ2q6sQk9wU+neShVXUEkB7jLBjreHgt7SzN/3TXH9pt+4ee41yqqr6ebNBV5/UcY8Flq+qsJP8AvKWqDkxy3ECxFhviWDgnyV5V9Q24YMjh7weIA+MdD2PF+WNVVZKCNh2n5/1PGuu4s++mZ99Nz76bnn03vdcB/1xVnwdIsg9tycRb9Bzn8lX1viTPAKiq85Kc33OMBed1r9M9gFdU1ZuSPHyAOGP13dDP5y7Ao6vqR4tvSLIN8HfAHYAP9BDryKp61jK3vSzJFYDeRq1X1clJHgB8GDgVuGNV9f75rqo+1iVNP0VLat6zqr7XZ4wk/w1cg5a8Oq3bvCvwpCT7VtWT+4y3jH8AnrOlOzGBsXnG+oJ3KvCbAfa7rO4P/hIL15d6E+rBeVX1m0X916dtq+pEgKp6f5JvAx9McgAwxHrBYx0PN66qG0xc/1ySYweI84skV6frqy4JdPoAcQC2SbIz8PfAMweKsZwhjoWnAIcm+Ul3fWfg/gPEgfGOh7HivC/J64AdurMbj6QlB4cw1nFn303PvpuefTc9+2562y18AQeoqnUDJWbOSfIXrP+McjOG+6x8dpcoeSjwN0m2piW4+jZW3w36fKrqqRu57Tzal/++Yn1sE7f/HPj5lsZJcjwbfl7cEdga+FoSqqqXUR5JXrUozvbAycATuzhP6iNO5y5VdY0l2vBe2oimXhIYWX4kf4BL9hHDBMbmGfQLXpJ/7n49GViX5GPAHxZur6ohhv7dHXgpbUjez4GrAt8GhphHdkKSBwFbJ9kTeBLwlR73/6ckV6qqnwJ0IzFuR5t+c/Ue4ywY6wv/+UmuXlXf7+JcDRjirMPjaZn/ayX5MfADBhi+1nkObSjol6vqyO459ZZpTvJRlk5UBPiLvuIs6J7DtYBrdjG+U1V/6jtOZ6zjYZQ4VfWSJHcAzqL1339W1af7jtMZ9LibYN9Nz76bnn03Pftueicn+Q/g7d31h9A+P/Ttn4HDgKsn+TKwE214/xDuDzwIeGRV/TStDt2LB4gzVt+N8nySPB94UVX9urt+OeBfqmqI6dWfBu63KNZ7qupOPYX4u572sylHLbp+9ICxzk1yk6r6+qLtNwbO7THOr2lJ4Z8tviHJqX0ESNUQJyPXpu7Nf2Fo16/ovuBV1Sk97f/AjdxcVbXFQ26WiHkscFvgM1V1oyS3AR5YVY8ZINalaGcB7kj7kvdJ4LlV1csfTZLbA2dU1bGLtu8APL6q/quPOBP7Xep4eHBV/bDnOLcD3kJLbIWWZNpvMmvfc7ztgK2q6uwh9j+GJH+7sdur6gs9xbltVX0uyb2XifPBPuIsijnK8TBinD2A0xfeB5JcErhiX++rs2DfTc++m559Nz37bnrdF8dnA7ei9d0XgWdV1a8GiLUN608UfHfAEwWkFbncs6o+031+3brvz0Uj990Yz+ebVXWjRdu+UVV79RlnI7EutK2HODcDTlzoqySXAa5dVV/rOc52wLlVdX53fWvg4lX1ux5j7EWbGncZ1k8huQotofq4quoleZLkecBhSyRKSPLCqnr6FgepKi+beQG2Ay4z4P7vt5JtPcU6qvt5LO1LK8DXR+jDrYHtB9z/JWl1RIZs/4vHOB66GBcHrg/cgPaGNkSM5wM7TFy/HPC8gWJdg7Zyxwnd9esD/z5g/10MuBFwhZ73++zu51uWuLx5NR8PY8WhnX3YduL6trQ5rqv6uLPv7Dv7zr67qPTdGBfaKNEdJq5fjvala4hYjwaOBL7fXd8T+Oys+2Denw9w3OTfDu2z+IkDPaejgd0mrl8V+MYAcb5Jd8K/u77VQHGOAC49cf3SwFcG6rsrAX8N7A1caYnbrzNE3D7jOAJjM3Rn8h8G7M7E9Jvqd37SktnKATOYnwHuCbwAuDxtGsmNq6rvAkKkFbjcnzYs82jgssDLqqrXYWxpq528hPYhYY8kNwSeU1V37znO56rqtn3uc9H+b72x26vqiz3H+2aNlzn/Al0B1IWYSU6oql6qbyc5GHhVtWlElwW+SjvudgT+tare3UeciXh7VNUPNrVtC2OMcjzM4Lg7pqpuuGjbsbXhfPS+Yg193Nl30+/fvpt+//bd9Pu376bf/1tYvqZUVVWvS5wu03cX+tzSVyxa0fmvTfTd8VV1vY0+cOX7H73vGPD5TMR5Gm2VnYXn90jamfgX9Rmni3Vn2ijohRG1twYeU1Wf7DnOUsfdcdVTDYxNxLnQtjEM9dm/zzjWwNg8h9MyZMcDf+5750n2pVXy3SXJKydu2p7hVoO4B221hH8CHkxLKjx7oFjXrlYR+8G0vnw6LZHR9zy8Z3Hh1U726DkGwDfTloE9lG5JtC5eX9MGliqKVLSzQ7vSRoH0aeskF6+qP8AFQ1sv3nOMBUMXQP2bqtq/+30/4P9V1T2TXAn4ONBrAoNWWXvxm/D7aRnuvox1PIx93J2R5O5VdRhAWpX0X/QcY8HQx519Nz37bnr23fTsu+n97xLbdqMVte673wC2SpLqzrx2Q+y3HSAOwB+q6o8LfddNXenzjO/YfTf08wGgql6UVvzydrQpMc/tO6EwEesT3ZSIm3Wx/qmqhvhbOjnJk2hTL6Ato3ryAHHGXM1uUwZbbaGvOCYwNs8lquqfN323qf2ENrzw7mxYxOVsWoJhCP9ZbS7Sn4FDoM1PoiUX+naxtCWC7gm8uqr+lG4psZ4ttdrJEHF2BM6k1RCZjNNLAqOq7jZ5PcmtaDVETgee0EeMRd4BfHbizMAj6Y6JAQxdAPWPE7/fgZZkolrxqt6CpBXuvA5w2WxYB2N7Jlb16cNYx8MMjrv9gXcmeTXtn9mptJFuQxj0uLPvpmffTc++m559N72qumBJzLSaYP9GOwt+EPCmvuJM+CRtFZeDac9pf+ATfQZIslVV/Rn4QpJ/Ay6ZVnT1ccBH+4ozVt+N9XwmVdXHaSeKBpHkWlX1nS55Ae27E8BuSXZbSAD0aH/glcC/0467zwK91wlk3NXsNmWs6RnTx5l27slF8UJLIjyadlDtuHAZIM7FRnxOF5rHBRw3UKwnAT+mjb5YKJL1fwPEeROt2vJxtHl+rwIOnvXxswXP53a00SSfB+4wcKx9adNvXgrcaYD9P412duFqwGeA33XHxJeA3XuM83laBekb0aohX6nbvg1thZC+4tyDNlTyTDasf/FK4Bar+XgY87jr4l2agWrJjHXc2Xf2nX1n312U+g74K9rJjxOBRwDbDNhnWwH/SBvd+AHgsbRClH3GOBa4eRfr0bSTH+/vfk/PsQbvu7GeD/Cl7ufZtIKQC5ezgbN6fk6v735+fonL54Y6/sa40Oq1XRe4HiN+F1yiHb3X+Og7jjUwNkOSxwP/RftCtNBxVVVX6znOLWnTIK5K+8KVvuMk+UdaBvZqwPcnbroMbcmtoZbPXNyObaqtEd3nPgdd7WQizpJzGKvqkT3t/6605/EbWjHNL/ex31lK8hrglrRVYb6cgVY8SXINWhLhSsB/V9Vbu+13Au5YVf/Sc7ybV9VX+9znEjFGOR5GjPOQqnpH1i8fvYHqcdnoEY87+276OPbd9HHsu+nj2HfTxzmUVgTwJcD7WLTsbFX9ss94Y0hyU9pJr2OBp9UAq4F0cUbpu7GezywkucTiz/VLbeshzjVo00euWFXXTXJ94O5V9bye41yKtlTwVavq0Un2pC1GsNR0o0ElOaKqbjbPcUxgbIYk3wduWsPMsZqM8x3aaI+jmXhTq6oze4xxWVoF5xcAB0zcdHbf/3TG/Me9ROytge2q6qwB9n2fiauXAO4F/KR6Kuqa5M+0ZY6OZelESS9FSZN8qapuleTsRXEWEmfb9xFnIt5etH+o36H9U7ignkz1P/RvFN0Q0FfQ5mIWrWjoP1VVb/MkRzwexorz2Kp6XZZZPrqqeq3FM8ZxZ99tUQz7bvoY9t30Mey76WOcwsTJvIXN68P0c9Ityfuq6u/Taiss9Rr1XUwxtGkD/0qbCjHZd319vjuFEfquizX485mI9faqeuimtvUUa5QFDzJwMdyJOO+lfe97WJcouSTw1eq5iGeSrQCq6s9JtqWN+DhlgO9+g8axBsbmOZE2FG9ov6k2h2wwVfUb2hmHBya5AfA33U3/B/SdNd+u+3mZnve7pCyx2kmS3lc7qYk5jF3cd9OGa/blNj3ua1lVdavu5yivT1V9I8kzaUNAL5if2/3sbVWXJLehzWG+Vrfp27TaK+v6ijHhXcBraEksgAfQCoXetMcYoxwPY8Wpqtd1v/5PVZ0xQrwxjjv7bnr23fTsu+nZd9PH2H0l90tynao6cQtCPbn7+XdbsI/NsSNwY+AM2mfI3ov2j9h3MMLzmXCdyStpxUL7LGZOWjH2XWj1PG7E+sTP9sCl+ozVGboY7oKrV9X9kzwQoKp+n/RYtA1Ick/gdcCfk+xPq71yDnCNJP9YVb3URRklTs3BnJ/VcgE+BPy/7kV55cJlgDgH0VbmuDltZYO9gL0Gek5PAk4AntNdjgeeOECcrWlnpMd4nY7pfj4YeBltTtkgdT0Wxb0mcNIYz3FR3A/0tJ9XADcfuK1XAN4OfBm4wYBx7gr8gLYCyQ2AG9KKkp4M3GWAeF9bYtsRYx8LfR4PY8UBvgd8CngUcLmB2jrKcWff2Xf2nX1n312oPb3Mp6eNTN5l4LbuT5tWvT8917yYRd+N9XyAZ9DqXZzHhvUvzgRe0HOsh9PqXZzNhvUvDgPuPcBz+zgtCfiN7vp9gY8PEOcrwCUn4lwd+HrPMb5Jm1q9R/caXbPbflXgqNUUxxEYm+fD3WVoC2dt957Y1uvZ6Qn/QJsWcw5csALJV2lDD3tTVecnuTvw8j73u4xRVjtZYsrFTxlm9ZZN6Wuo4TeA/+jm+30IeG9VHdXTvhccQUvQPay6d7OBPBW4Z1UdO7HtmCRH0Y7tw3uO9/kkBwDvoR0T9wc+lmRHGH0ucK81eYaOU1V7JrkJbdTKM5N8C3hPVb2jj/13xjruVsq+m559Nz37bnr23fT6Oou8PfCpJL+k/a99f1X9rKd9L/gb2omcn2/sTj2NjFiJLe27UZ5PVb0AeEGSF1TVM6bdzwpjHQIckuQ+tWgk9EAeD7weuFaSH9NOjg1RJ/BA2qo6V0nyTlodm0f0HaSqfgqQ5EdV9d1u2w8XpnysljjWwLiI6+YU3ri6ojdJLgEcWVXXGyDWfwGXBd5LG0oE9F/3IG295qfT5rTelba29juq6m82+sBVqu85f92X7vvQPmDtVlV79rjvnWoFw2eTfKCq7rOp+23k8d+pqmtt7m1bEO8HG7m5qudCv5toS+9zQMeKk+TytFFTD66qrXvc7yjH3Wa0x76bvj323fTtse+mb499N317+v6Mcn3aSYL7AKdV1e372vdmtGHV/p8dOk6Sy9FWALxgKfmq+mIf+14i1l1p01YmYz1noFiDFMNdFOMvaLXUQhvF22vNxSTfBP66Wl2Km1TV17vtWwPHVk91PcaI4wiMFdhEAaGqqhv0HO+ytEzcrbtNXwCeU61uRV8x3lpVj6At+fi1JB/qbronw6zfDXCL7ufkm0vvI0uqamF6z4IfdvUQepXks1V1u01tW4X+klY3YnfgW33ueCUfqjpb+oX/nClvm0pV7dH3Pi8qkmxPqx3yANqQyQ8BN+kzxojH3ajsu+nZd9Oz76Zn3/Xi57QRr2fSpsvMQq+1CeZAL88nyT/QapbsChxD+zL+VQYYQZ7kYFrNi9sAb6RN7fj6AHEuTkuW7Q5ss1CWYqBEySWAX9G+n187Sd/Jn8cA2wLnLiQVOlehjdpaNXFMYKzMQgGhb9OGpi8I8KIB4r2ZVpfi77vrD6UlGu7dY4zrQ1sBJMk64Fa057NfVX2zxzgXqKpBi2VlE6ud0M509BHnErQ3zct3mebJAkJX7iPG5japl5206UP3ps2XfC9t6dlf97HvKWzp0LCrJzlsie1hgA9t3ZSlf2R90nEdrWL1n/qOtZLmrLI4x9Km5j2nBl6KdgXGGpJo303PvpuefTc9+256f+xjJ0n+kTbyYifg/cCjq6rXkyybYVX13Qr09XyeTCsYekRV3SbJtYBeV9iZcIuqun6S46rq2UleCnxwgDgfoS16cDTwhwH2D1zwGfz+tAUjFgqtFtBbAqOqjlxm+ynAKaspjgmMFaiq07tf/7Kqfjh5W/fH2berLxrW9+wkx/Qc41KLqvd+qfuZJHv1Pa2j2/Ff0EaW3Ir2R/kl2j/xvpaHHWu1k8cCT6ElKyb76SzaShRj2+K6G2kp5d/S5koOukzwSO6xkdteMkC819KKxf5Pd/2h3bZ/GCDWBZJcYYm5rWPVYenjuNsa+FBVLZd0XPWS/MUS73H23fTsu+nZd9Oz75bQfXa4CW1ViAJ+Qis8eMEX4qq6WU/hdgOeUlXH9LS/uZTkWlX1Hei178ZyblWdm4QkF6+q7yS55kCxft/9/F2SK9NG5AwxGnbXqrrzAPtd7J60YpeDJUk2JsnHq2rf1RLHBMYKdFnfxwFXS3LcxE2XoVV57tvvk9yqqr7Uxb8l6/9Q+7IL8FKWPqswVMHQ99AyiQvJmQfTzvT3Mn+x2hrrWwNnVdVgxUKr6hXAK5I8sap6LXY6KW2pqANpmdj/BJ5I67tvA09eSKxV1ae2NFZVVZJ7VtVzt3RfPdmis11V9YUVBelvDvCNF00l+1ySY5e99xS62iQbbAK+vpCIrK5Q6JYeD0nuXFWf6H6/LG3k0o1po8L+qbqiaT0dd+enLeM8L7bouEtyEPCSqvpFkr2B99GWEbsYraDeF8C+W/LByTdoZ8/eXVXfX+5+9t0SD27H2ouBH9NWA3gz7Uvl/wMeszCq0r5b4sHJpYGn0f637ko74/194OCqeuvC/ey7JR6c3JGWtP8e7diD1od/meRxffTZRKytgLvVwAUiN8OQIyM+RUvWjKmv53Nakh1oo4w+neRXtKTWEP63i/Vi2snEok0l6dtXklyvqo4fYN+TTqadCBtylMdydU5CW61v1cSxiOcKdB/iLwe8ADhg4qaza4DVBZLcEDiEVvAywC+BR9SGKypsaYxvVtWN+trfCmMeXVV/vWjbUVW193KPmTLO54ecrpLktlX1uSRLTumpql6GsCX5BPAx2siSBwHvBN5NG11w+6ra2CiDaeK9BnjrckO/xpTkjn1++NlInF7+DrovX/db+OKV5Gq0Cul9Fi77M/DDRZt3BU6jx0Khk8W8kryRNtf4DbTpRX9bVffsI85EvJfSCn4dyobFfYcYCrqptmzRcZfk+OoKICf5PPC0qjoybWWfdw3wXjeTvltqVEkPffcD4AO0qZM/pb3XvbeqBvnwu8aOu6/Tkt070Ka1/lNVvT/J7YDnVdXN+2npBfHWUt99hFaH4jO0Y2872smWfwd+XFX/1ktD18dbS333bWDfblj45PY9gMOr6q+2sImL470TeEZV/ajP/S4RZ5OjSnqI8crlbgIeXlXb9xVrI224YKTHQPv/W9r3mE9U1aBTYbo6FZeofmsFLtQ93Ib2N3syLbkQ2meu6/cU51VdnF2AGwCfZSKJUVVP6iNOF+t8Wl3FpZKXN6uqS66WOCYw5lhasSeq6qwB9j2LBMZLgKNoZyWhFdy5TlUd2HOcQVc7SfLsqjowyVuWuLmq6pE9xbngNUpbhmi3iduOqaob9hFnYp/fAq5Jm592Dj2/SXcxVjSqZCzpqfJ290XhLbR/cKGtdb1fVX1+S/c9EeNfaaOVnrpwJiDJD6rnAqKLEhgbHGcDHXeD/h11MVY0qqSHON8BrltV5yU5oiaG/04mN/oyUt8tOaqEdqboglElPcSZPO7+BnggLWn2bdqojNf3EWci3hh9t6JRJT3E2dj/it7/14/UdysaVdJDnGMnR88lObKqbtyd8f9W9b9i1Rh9t6JRJT3E+R7wV1V13qLt29L67i/7itXt93O09+2vs+Fnu7v3GGPZUSVAb6NKkpwN/AtLn21/aVVdvo84m2jDBu8VPe73crRijReM8u/r8/eiOFvTVhrcfVGsvurdXXVjt9eikgJbEOfhm4hzSB9xulgnAPeqqu8tcdupVXWV1RLHKSRzJMsUn8z6ire9/FF2LjSfc+FNp6qOW+L+fXgs8M/A27vrWwPndM+7esw4D7rayULCpar262N/GzG5VvLbNnJbXwaf+wa8lfWjSj5PG1VyV9qokoPZeO2KuVVVn02yJy0BFOA71fM8xqp6SZL3AC9PciotETREBvoK3d9kgO2TZOLMU+/H3Qh/RwDPp62vDm3q3OnA3WhfkF9Hm3vah9cAh3df+j+R5L9pX2BvR6vI3quR+u6uVbUw8vDFwP0nR5UAvY4qAaiq/wP+L8kTgTvQCpv1msAYqe8uRxsV8fkkQ44qObf74nVZYGE64Ie7M6Dn9xxrrL77H9aPKvkKLdF4hy5Z/D9AX6NKzkk3ZTfJ3WgjXqm2/F/vBZFH6rt30kaV3IlFo0qSXKPHUSVvBo7s/i+d2m27Cm2FlSFWsxuqGOSkV9BGuJ4yuXFhVAnQ16iSI4ETquori29I8qyeYmxqpMcOfcWZiPdc4BG0kzmThSiHmJb+UeBc4PiJWL1ZSFAkuRlwYnXLpya5DHBtLjwidto4h3T73Y5WQ+T87vrWwMX7iDHhWSz/Oe6JqymOIzDmSDdE/Bjg46wfpnSBqur9zTttBZK705JZxwBnAF+onotMdR8ErjL00L8xLJdoWtBj9vc5wIuq6reLtv8lcFBV3bePOIv2fStgz6p6S5KdgEtX1Q963P+oo0o2pz2rSfdB+5nA7lV1pZ73vXhE1P9U1Rnd6JkXVdXDeo53DVrB0ytW1XWTXB+4e1U9r8cYo40qSVuyeX/gGrT31dNo84HfXD2vSjNS340yqiTJe6rqAX3sa4Xxxj7uBhtVklZX4UW0D/H/RFsR6eG0M8iPqapea3WN1HejjCrp+u4NtOTz8cCjquq73f+/B1Zblr03I/XdaKNKkvwV7cTDLrTPrKcBh9VAq4N0Z8X3rKrPJLkUsPXCF8ue9j/KqJK0mlbnVtXv+tjfRuKMOtIjyXeB69XAU0a6WMdVjyOENxLnm8BeCydyur+jo6rHKcLdfo+gJc9+212/NPCpqrrFxh950WQCY46k1b54AHBn2nI97wY+WwO+SAsfBNLWbr5KtakRg7wpZIkaGEPIwKudTHzBuyZtOOPCcp13A75YVYOuPDGU7nntTauCfI20qs6HVtUte4xxwQerJM+rqn+fuG3Qf0ZZYsWOjFRrYwhJLklbseiEWbdlSyT5Am156tdNfGE5oaqu22OM02jTRgI8ntZvCx9GRvkQNISR+u6JtPe2g2jLBO/A+lElV6uqh/YVa0wj9d2Fpqh1Z9XuQBvJMsbZ+N6N1Hdfpf0fvyxt5agnT4wqeWn1XE9mLCP13Vdo9XcWRpU8oaru1N323aoaalWIQSV5NPAYYMequno36vHgqrpdjzGeQRu1stSokvdV1Qv6ijWGtGk3/77MSI8fVP9TUD8A/OPiz1pDSFt29LNDf4Zb6iTHEJ8blonT9wmWsU7ADh7HKSRzpNrSUMcAByS5Be1szauSPL2qDtvYY7fANkl2pr1hP3OgGAuOSHLjGr5I5NCrnTwbIMmnaFnZhWFlz6IV5urFWG80E+4F3Ihuadiq+kk3VK5PH0ly6ar67aLkxV/S5jb3IiOt2NHFCm2ZrVM3eecti7PcFLM7wur6x7PIparq69lwtPZ5y915Sm9g/fLKhwCXBxZGlRzTV5C12HdV9aq0+ayTo0quSRtV0udZ4zXXdyzxnlZtePAnWD+laYut0b7bn/WjSu4E/GOSt9KNKukryBrtu38E3pC2fOXxwKMAulEloyz1nmGWZHw8rQ7K1wCq6ntJrtBngKp6QZIP00aV3Jz1o0oePNSoksV67rv70qZZXEjfyYvOC4Bvdv8zJgtR9lanZMIRwIe6ERF/ggvqtvVdAPXkJE+ijZyCtirlyT3HgDadba/q6oUk+Wv6X4Gy78/0M4tjAmMOdf9kbgRcj/bGOWQm8znAJ4EvV5vXfDVa8aIh3AZ4bJIfMlCRyM6OteFyoM9Lcs+eY0Bb5mpymNwfacWE+jLWG82CP1ZVJVk4M71d3wGq6j+X2X4S7R9tX37Bhecn7sL6pbZ6WbEDLliC9sPA0KOL1sw/nkV+keTqdPU8ktyXVqOiN7XM9Luq+inQ55SYNdd3ANWK0fZWkHYZa67varwpMWux746lJS4WPLm79G2t9t1Nlth+BtDblJiMtCTjhD9U1R8Xkj9JtmGAOlBV9W3aNK/BjNV3NcBKiZtwCPBCBqpLschLaUmm44ccqU5Lpr6StjJR0VYJ6S2JOuEpwKFJFmok7Uyr/9Sb5T4L9W2MOE4hmSNJ9qMdrJcA3k8brjb4MKyxZJmKvtVTJd+JOGOtdvJM2siVD9He1O5Fe82e32ecsaStcrEnbXjzC4BH0pZ+fFWPMcYavjbKih0T8eZmCdrVpkuavp5WfPdXwA+Ah9SiImpbGGPss6yjsO+mZ99Nz76b3lrqu4y0JONEvBcBv6YlnZ9IOxP+raoaevTwQvzeRkaM3XfLtKH3UTJJvlBVf9vnPjcS65O0ZXyHTpSMJsnF2LAYfK91sybi7Aq8Crgl66faP7mqTlstcUxgzJG0Ip7HAwuFLjd4cYYYgpURCkpNxFpyuabqubBnWtGi7VhffX1r1i+51evwsm6I1626q1+snpZ2WxRjlDeaLtYdgDvS3jw/WVWf7nn/G00i9Zm17frt5bR5rAcCx1ZVbyMvFsUafAnaiVir/h/PMvG2A7aqHguyTex7tOOui2ffTR/Pvps+nn03fTz7bvPjjLIk48Q+t6JNh7ngMwrwxj7Pvm9iZMT/VtXOPcUZaznLUZ7PRLyX0aaOHMaGU0iGWEb1rbTRtAsLHyzEWpXJzTEl+TRtFbGFVSEfQpsmdYfVEscExhxJK061rKr6wgAxBy8oNRHreNoHg9BGmewBfLeqrtNjjFFXO0kryHZFNlyDuu+EzFhvNBcs4dTNnb0m8PGhMsBjyYArdkzEGGV0URdr1f/jWRTnycBbgLNptSr2Ag6oVVpcFey7LWHfTc++m559t/m66S/HV9V3l7jtnlX14QFj70irPXVcz/sdZWTEWH03g1EyS001rKrqfRnV5RJ1Y02TWM0yQsHQweNUlZc5vtDWkb/+gPs/svv5zYltx4z03PaiJU763u/RI7X/ibRaCycCx9FGzxw3QJwLvR5DvEa0lW8uRasVcSptasw7B+q7Xbv9/xz4GfAB2oeRoV6rS9KWghzyeLgVsF/3+07AHgPFGet4GCvOsd3PO9HO2twA+MZAfTfKcWff2Xf2nX13Uem7sS7AOmB7YEfaSOWjgZf1HOME2jKtS9126qz74KL+fJZ5HpcBLj3rdqymC/AZWpJ26+7yENqKLqsmjkU851CSdcDdaWf1j6FVy/9CVW10XuOURikCt5Sq+kaSGw+w67FWO3kybcnRXpZn3YhfJHkIbVldaKvTDBEzVfW7JI8CXlVVL0pb/3oIb6Gd7bpfd/0h3bZeznYtNwc4Pa/YMbHfA+mWoKU9j4sB76ANR+7bWMfDaMdd9/MuwFuq6tgkS50t6sOgx90E+2569t307Lvp2XebaQZ1Si5bVWcl+Qda3x2YpNcRGMCzgK2Wue2JfQUZse+exQjPZ0GSy9Km7N662/QF4DlV9ZsBYl2XNmJqx+76L4CHVdWJPcd5PvCiqvp1d/1ywL/UxEp6W7j/5ab5AMNMv6HVuHs1bZp1AV8BhljWe7A4TiGZQ0m+WVU36t6kr7LwJl3DzKcfvKDURKzJN+ytaKs27Fjd+uQ9xvkWbbm/QVc76YbK3aGq+l4CbXGc3WhvADdn/RvAk6r/qSrfpBXFejnwqKo6McnxVXW9PuN0sY6pAYevzWD+9DF0S9DW+qlYQ/3NjnU8jBXnLbRRP3vQzkZuDayrqt5XdRlx2KR9N30c+276OPbd9HHsu83f/9j/Z4+n1b84BHhmtZXzBvk/O7Sx+24sST5AG/VxSLfpocANqureA8T6Cu04+Hx3fR/g+VV1i57jfHPhc93Etm9U1UYTD5ux/4VpN5egnQg7lva95frA16rqVss9dgtiHgI8pap+1V3fEXhJVT1ytcRxBMZ82ibJzrQVLgatrlxVJwO3z4AFpSZMLld2HvC/tCGNfet77fHlnAysS/Ixhi0g9Fzg4YvfAGiZzT49GXgG8KEueXE1hls6cdCzXTP45z/4ErQTxjoexorzKNqycSd3I4D+gmHOBMB4Z1ntu+nZd9Oz76Zn322mGfyffQ6tcOeXuuTF1YALFcHcEmONjBir72YwSubqVXWfievP7k7wDGG7heQFQFWtG+iz19ZJLl5VfwBIckng4n3tvKpu0+33PcBjav3KedcF/rWvOItcf+G9rmvDL5PcaGMPmLc4JjDm08Kb9JeHepNesPjNrRvJ+BtaHYlj+ow1+YadVk360lV1bp8xFkINsM+l/Ki7bNtdhjLKG01VfRH44sT1k4En9R2nM8rwtYxXWf59SV4H7JDk0bTn94aeYyxY9f94JlVbAu0bE9fPZJgvKDDesEn7bnr23fTsu+nZd1Ma6/9sVR0KHDpx/WTgPss/YiqX2fRd+jNC3436fIDfJ7lVVX0JIMktgd8PFOvkJP/BhoV3fzBAnHcAn+1GTxXt7+qQjT9kKtdaSF4AVNUJSW44QByArZJcblHCdoicwGBxTGDMoZHepBfs3V0+2l2/K3AksH+SQ6vqRX0FSvIuYH/a8qZHA5dN8rKqenFfMTofY4nVToDeVjuB9QmZJNtV1Tmbuv8WGOuNZkxjne0aZf50Vb0kbQnas2jTl/6zel6CdsKq/8czQ2Mdd/bd9Oy76dl307PvpjdWnZLBzWBUyaB9N4Pnsz/wtrRaGNCmpj98oFiPBJ4NfLC7/kXgEX0HqVYP7njgdrTvFc+tqk/2HQf4dpI30hImRTsWvj1AHICXAl9J8v4u1t8D/7Wa4qz2N+c1Kck1gNcCV6yq6ya5PnD3qnreAOH+Atirqn7bxT4QeD+tAM/RQG8JDODa1QowPRg4HHh6F6PXBEYtqtmQViDnsX3G6PZ7c+BNwKWB3ZLcAHhsVT2u51BjvdGMaaxRBDtV1Vsmrr81yVMGiANtFZpL0l6j4zdx3y2x6v/xzNBYx519Nz37bnr23fTsu+mN+X92FCOO3hyl70Z8PmdV1Q2SbA/Qfebfo+cYC25fVRuMEk5yPyZOAPelqj4OfLzv/S6yH/CPtOnc0BIyrx0iUFW9LclRwG1pSZl7V9W3VlOc5SrTarbeQKtF8CeAautcP2CgWLsBf5y4/ifgqlX1eybqOvTkYkkuBtwT+EhV/YkRpntUq+A7xGon/01bCu3MLs6xrK+83JuqehttBM7PgDNobwBv3/ij5t5WaZWcgUHPdv0iyUOSbN1dHsIAw3XTCu5+Hbg3cF/aSjh9n+UCxjsexoqT5EL7XGpbT0Y57uy76dl307PvpmffbZGx/s9e6IvwgF+O30Jb5vbKtKKrH+229W2UvmO85/MBaImLqjqr2/b+AeJA+560km1TSbIwDebsJGdNXM5OctamHr+5uin1BwMHVNW9qurlNcw0+4V436qqV1fVq4ZIXgwdxxEY8+lSVfX1bLiy1lArXbyL9mXrI931uwHvTiuE0/cB/TrgFFqF3S8muSptyH2vsvRqJ2f0HQegqk5d9DqdP1Ccb9H/67GBkUf+jHW2a6z5008FbtTNZyatMNtXgDcPEGuU42HEOBtM7UqyNe1vdgijnWW176Zn303PvpuefTe1sf7PfgBYvPLD+xmm/8YaVTJW3w36fJJci3ZsXzbJ5Ioj29Omcvcmyb60ZYh3SfLKRbF6+65U3eofVTVKHZEkd6eNSN8W2COt/sVzquruY8RfbUxgzKdfJLk63eiEJPcFTu87SNo377fSpnPcija8Z/+qOqq7y4P7jFdVrwQueLNJ8iPgNhPXH15VfRTGGWu1k1OT3AKoJNvSCl4ONV9tDG+gfRF/HbSRP2l1S3pPYIw1fI3x5gCfBkyu4HM2cGrPMdaUJM8A/g24ZHc2YyET+Efa0s69G/G4G5R9Nz37bnr23fTWeN8N+n92zC/HE9ba6jdDP59rAn8H7EA7EbrgbODRPcYB+AlwFHB32jT0yVj/1HMs4IJE4xWZ+N5cPS+xDBwI3ARY1+3/mCS79xxjzUjVWAs2aKXSVh15PXALWgGcHwAPqapTBoh1dA2w/vg00uO6yhP7XFjtZIiRHpcHXgHcnjbS45O0OYVDVRQfVJIjq+rGmVjzOj2uGT8LWXr97gtt24L9L4z2uSFwPeAjtMTjPYCvV9X+fcRZy5K8oKp6G/Z5UWLfTc++m559N7212Hcj/J+9B23q8d1p0yAWnA28p6q+0kecRTF3o42MuDnrR0Y8qe8vrUP33cQ+x3o+N6+qr/a5z43E2qaqhhqdPhnnibTkws+AP3ebq6qu33Ocr1XVTRd9Bj+u7zhrhSMw5lC1VUdu303j2Kqqzt7UY7bAEUluXFVHDhhjpbLpu6xgJyOtdlJVv6DnUSozNsrIn5ENXVl+YbTP97vLgo8scV8t7ZndmaE9quq5Sa4C7FxVX591w1YB+2569t307LvprcW+G/T/bFV9BPjImF+OWXur34z1fB6TtpT8BqpqiJpg30tyobPwVXW1nuM8GbjmCCcnT0jyIGDrJHvSRnX3npxbK0xgzKFFNRzoaiz8Bji6qo7pOdxtgMcm+SFwDi2J0HtmcYX6Gg40ymon3UiZVwA3o7X9q8A/dQmo1ejxtJE/10ryY7qRP7Nt0hYbdA5wjb9E2Vr0GtpZjdvSPmT9tts2ROHdtca+m559Nz37bnprse/GqrVxZpLPMk6drrW2+s1Yz+d/J36/BHAv2pSPIey9KNb9gB0HiHMq7TvY0J4IPJO2gMK7aaO6nztC3FXJBMZ82ru7fLS7flfgSGD/JIdWVZ9Lm+7b4762VC8jMNhwtZNXV9WflsrS9uBdtA8e9+quP4D2pnPTAWINbuSRP6MYeg5wkv+uqqck+ShLJOAsvrQiN62qvZJ8E6CqftXVlNGm2XfTs++mZ99Nb8313Yi1Nkar08VIIyNG7Luxns8G9eaSvBv4TN9xuliLR0T8d9rKIf/Zc6iTgXVJPsbE6oxV9bI+g1TV72gJjGf2ud+1ygTGfPoLYK+q+i1AkgNplZZvTRtJ0FsCo6p+2MW4AsMVQ1qpL/e0n1FWO6HVkJlc/uwdSZ4wQJxRJLk4bRm53YFtupE/VNVzZtisLVbDVpZ/W/fzJQPt/6LgT12BrIWpSzuxfp6pNs6+m559Nz37bnprsu8G/j+7YMwV+tba6jejPZ9F9gR2G2LHSSZr5m1FO/E7xIohP+ou23aXXi13AmyBJ8KWZgJjPu1Gq0y94E/AVavq90n+sMxjppK2bM9LaWtD/xy4Km0ljets7HFTxvrnJTZfMDWmqnr58l/jrXby+SQHAO+hvfncH/hYl9mmqn7ZQ4wxfYTu9WAiy6yNOgi4Y1V9IckzquoFs27QKvRK4EPAFZL8F3Bf4N9n26RVw76bnn03Pftuevbd9Ear0zXiyIhRjPV8kpxNe33S/fwpbRr3EF468ft5tBOXf993kIWpwkku0662k8s98gTYFFyFZA4l+Q/atISFQoB3o1Vefinw+qrqrXBkkmNpb2ifqaobJbkN8MCqekxfMSZivYulp8ZcC+h7aszG2tHLaidJfrCRm2uAQkKDSnJCVV131u1YTRZVi+59FZ2LirRl8m5H+9Dz2apazcsRj8q+m559Nz37bnr23XQy4gp90oIk1wXezvr6Gr8AHlZVJ86uVTKBMWfSxsbtClwBuBXtH9yXquqogeIdVVV7d4mMG1XVn5N8vapuMkCsTwL3mZgac2na1Jh70UZhXLvvmMu044IvnVovyeuBV1XV8bNuy2oxmbQwgTG9jLPG+ppk303PvpuefTc9+27LrKU6XWtRksvRpo5cMC29qr44UKy70kaMT8bqddpzkq8Az6yqz3fX9wGeX1W36Gn/76uqv09yPEvXUnMZ1SU4hWTOVFUl+XBV/TVtKP/Qft0lEr4IvDPJzxluTuFoU2M2oZesXZLnAs+qqvO769sDr6iq/frY/wzcCnhEN7LkD8x2RZrV4mpJDqP11cLvF3Du4qZlwzXWz2f90FOPu02w76Zn303PvpuefTe9tVqnay1J8g+0ZUd3BY6hrdL3VdpI775jHQxcijZF/I206VhDLEe83ULyAqCq1nVJtL48ufv5dz3uc80zgTGfjkhy46o6coRY9wDOBf4JeDBwWWCofwbvoj23yakx7+7eCMacW9jXaifbAF9Psh9wJeBV3WW1mqcVaVaLe0z87jzG6Yy1xvpaZN9Nz76bnn03Pftuetbpmn9Ppi0JfERV3aabLjXUcvO3qKrrJzmuqp6d5KXABweIc3I3tX+haP9DaNOXelFVp3c/f9jXPi8KTGDMp9sAj03yQ+AcBjwTXlXnTFzto7DlxmI9N8nhrJ8as//E1Jje6nqsQC+rnVTVM9LWJP8abT7mravqpD72PQtV9cMkNwD+ptv0f1V17CzbNO+q6gsruV+SD1TVfYZuzyo11hrra5F9Nz37bnr23fTsu+ntWlV3nnUjtFHnVtW5SUhy8ar6TpJrDhTr993P3yW5MnAmsMcAcR5JS8IsJEe+CPQ+0jrJzWgnQf+KttrJ1sA5VbV937HWAhMY82m0M+FJ7g28kFZzI6xPlvT+B5PkFcB7q+oVfe97UZxRVjtJcmvgFbQRK9cDXp3kkVX1kz72P7YkTwYezfo36XckeX1VreZRJfNiVRV0Hdkoa6yvUfbd9Oy76dl307PvpveVJNezTtdcOy3JDsCHgU8n+RUw1Gfi/+1ivRj4Bm0q1hv6DNDVqzm0qm7f536X8WrgAcChtAUPHgb85QhxVyUTGHNoYRhRkiswUZhmIC8C7jZSFexvAP+e5Bq0ZcTeO1Bx0r1ZerWT/ZP0udrJS4D7LSxF1SWDPkdbVWU1ehRw04VROUleSJu7aAJjy1kteXmDrrG+xtl307PvpmffTc++m551uuZcVd2r+/VZST5Pm5b+iYFiPbf79QNJ/he4RFX1Orqpqs5P8rskl+1738vEOynJ1l1tvbd0BUS1BBMYcyjJ3WlLpl4Z+DlwVeDbtEq7ffvZWEt4VdUhwCFJdqQVYnphkt2qas+eQ/0FsNfEaicH0lY7uTVt7mRfCYybLxTwBKiqDyZZ0ZSCORVaUbEFCwXGpEF0Zzf2rKqHzLotq419Nz37bnr23fTsu+l1K/TtD1gnYA4lufTCZ+4Fi6fYLnWfKWPdqqq+tCjWH+hGNHUF9XerqhO2NFbnXOD4JJ+mTetfiPmknva/4HdJtgWOSfIi4HSgz2Kha4oJjPn0XFrl3s9U1Y2S3AZ4YJ8ButECAEcleS9tuNfkcMYhCuEs+EvaKIXdGaZ451irnVw9yWuBK1bVdZNcH7g78LweY4zpLcDXknyou35P4E2za86aYiJoCd3ZjZ2SbFtVf9z0I7TAvpuefTc9+2569t30uhX6Xt6t0Kf585Ekx9AKrR49MZL3arS6fn9Pm97x/h5i3af7gv8J2knJM2ij1f+yi3VV4F96iLPgY91l0hCjah9Kq3vxBNrCClehnezVEkxgzKc/VdWZSbZKslVVfb4bzt+nu3U/C/gdcMeJ24oBKvl2z+HewPeB9wLPrapf9x2H8VY7eQPwVOB1AFV1XJJ3sUoTGFX1sm4EyS1pX7j3q6pvzrhZq06SK1TVzxdtfvpMGrM6nAJ8uVuCdvLshnPCN+0U7LtpnYJ9N61TsO+mdQr23bTGXKFPm6GqbpfkLsBjgVsmuRxwHvBd2pf/h1fVT3uK9U/d/u8L3A/YmVbQ89vA6xaPzujBDotr93U143o1sQrJ7xlu5ZY1wwTGfPp1kkvTKt2+M8nPaW8Evamq/QCSHAI8eSGR0L0pvLTPWBN+ANyCVtDw4sD1k1BVX+wzyIirnVyqqr6+sBZ5p9fXaQaOoQ1b2wagm+Lzo5m2aI5106E22ERbWvdGQKrqlwBV9anRG7d6/KS7bAVcZsZtWW3su+nZd9Oz76Zn303vNrRaZqcw8Ap92nxVdThw+EixfkU7idhr0c5lPJxWsH/SI5bYNpUkx23sdo/vpaXK2nLzphspcC7tzfnBtCI47xxi3fAk36yqG21qW0+xHg08CdiV9kX5ZsBXq+q2PcdZWO1k0OI3ST5OG+p1aFXtleS+wKOqarRVZPqU5InAgcDPWF//wg8HG5Hkz1x4Tu6uwGm0vnP1kRVKsl1tuKyzVsi+m559Nz37bnr23eZLctWltk+cuZZ6k+SBwINoJ0P/b+KmywDn97UySTf1pmijxz/K+uVhAY/v5Ww16wbowqrqnKo6v6rOq6pDquqVQyQvOlt1oy6AC84oDzUy50nAjYEfVtVtgBvR5q71bWG1k5OSvDjJ3gPEAHg8bfrItZL8GHgKrcjUavVk4JpVdZ2qun5VXc/kxSY9jTZE8u5VtUdV7QGc1v1u8mIFktw8ybdowz9JcoMk/zPjZq0K9t307Lvp2XfTs++m132Ruwpw2+733+H3GA3nK7QR6d/pfi5c/gW4c19BquqGtDqHl6YlMf6LtmjDj01eLM8RGHOoK7D5QuAKtLPgC2fCtx8g1sOAZ9AK6xSt0M5/VdXbB4h1ZFXduMs23rSq/pDkmO6Pt3cTq508gFaRuO/VThbibAdsVVVnL9r+8G7llVUhbcmrO1TVap8GM6okuwIvB06ljWA51uTFyiX5Gm0u62ELI7+SnFBV151ty+affTc9+2569t307Lvppa0otzftRMs1klyZNgL2ljNumtawrhDpT6rq3O76JWnF+08ZKN79gdcAL6yqFw8RYy2wBsZ8ehFwtxphedOqeluSo4Db0hIl966qIVYGATgtyQ60FU8+neRXtLmgQxl6tROgjZhZ5qYnA3OfwEjyz92vJwPrknyMDVeksbjYRlTVacD9ktwN+DRwqRk3adWpqlMX1ZI5f7n7akP23fTsu+nZd9Oz76Z2L9rI3W8AVNVPklhHZE4k2Qo4buhkXNavorik6n8VxffR6vctOB84lDaivBdJdqGdbL0X8CvaKiQf2uiDLuJMYMynn42RvFjQJSwG+4I/Eede3a/P6s72X5a2DFKvRlztZJNNmUHMaSx8APhRd9m2u2gzVNVHk3wGuPqs27LKnJrkFkClrYH+JLrh1dok+2569t307Lvp2XfT+2O3nGrBBaNfNSeq6s9Jjh2h+PvCKopXoCUWPtddvw2wjv5XUdymJpY9rqo/dn+7vehW/7sMLVHyCOCX3U3bJtlxoRi8NuQUkjkykVX8W+BKtJEKk2fCe1/adC1Ksj/wAdavdgLQ+2onK2jHN6pqrzFj9iHJ9rQpS2dv8s4XcROjV5bk6JVNS3J5WjXv29OSfp8CnuQ/7U2z76Zn303PvpuefTe9JP8K7AncAXgB8Ejg3VX1ypk2TBdI8jnayISvs+EywXcfINb/Ao+uqtO76zsDr6mqjY7QmCLOp4FXVdVh3fV70P5mb9fT/k+hTeFn4iesLx/glOQlOAJjvixkFYtWnOiOE7cV/WcV16rzaRnZDVY7oU2TGdNqGYEBQFfs9C10IzKS/AZ4ZFUdPdOGzTeHr265a1bVBssbJ7kl8OUZtWc1se+mZ99Nz76bnn03pap6SZI7AGcB1wT+s6o+PeNmaUPPHjHW7gvJi87PgGsMEGd/4J1JXkP7LnYa8LC+dl5Vu6/kfkmuU1Un9hV3tXMExhxKcgjw5IVpD90qIS+tqkfOtGGrRJLjaRngI6rqhkmuBTy7qu4/cjteXVVPGDPmlkhbi/rxVfV/3fVbAf/jSiQa0lIjlVbr6KWx2XfTs++mZ99Nz76bXpIXVtXTN7VNs5W23O2eVfWZJJcCth5iRG+SV9NG5Lybllh4AHBSVT2x71hdvEvTvjfPZHSy7xMbcgTGfLr+ZM2GqvpVkhvNsD2rzblVdW4Skly8qr6T5Jp9B1lm+sBvgKOr6pjVlLzonL2QvACoqi8lcRrJCnQrkbwKuCXtH+mXaEnI02basDmW5Oa0+as7Lfpb2h7YejatWh3su+nZd9Oz76Zn3/XiDsDiZMW+S2zTjCR5NPAYYEdaPbBdgIOBXqZbTKqqJyS5F3DrbtPrq6r3wpdJrgg8H7hyVe2b5NrAzavqTX3H2lRTRo4310xgzKetklyuqn4FFywH6mu1cmOtdrJ3d/lod/2uwJHA/kkOraoXDRBzSF9P8jrWZ7PvT1uVZC+AqvrGLBs3595CW7/7ft31h3Tb7jCzFs2/bWnrnm/DhlNxzqItM6jl2XfTs++mZ99Nz76bUpJ/BB4HXK0bKbrgMjj1Zt48HrgJ8DWAqvpekiv0HWTRiidDr9bxVtrnuWd21/8fbYGAsRMYTpmY4BSSOZTkYcAzgPfTDti/B/6rqt4+04atQkn+lm61k8kqwj3t+5PAfarqt931S9Nes3vRRmFcu894Q+tWhllOVdXYNURWjSTHVNUNN7VNF5bkqlX1w1m3YzWy76Zn303Pvpuefbf5klwWuBytcOcBEzedbfHT+ZLka1V10yTfrKobJdkG+MYQU5GTvBN4xsArnpDkyKq68cJz6raN/vnOKSQb8qz+HKqqtyU5ilZ0MsC9u6VOtZmq6gsD7n43YDIp8ifgqlX1+yR/WOYxc6uqbjPrNqxiv0jyENroFYAHAmfOsD2rycWTvB7YnYn/SSbMVsS+m559Nz37bnr23Waqqt/Qpuc+MMnWwBVpfXfpJJce+gusNssXkvwbcMmu4OrjWD9KuW87AycmGXrFk3OS/AXdCIgkN6Mdj2Pr9STsaucIDGlKSf6DNtriI92muwGHAS+lzcV78HKP1dqSZDfg1cDNaf/kvkKrgeGZtk1IcixtjuzRtBWEAHD1m02z76Zn303PvpuefTe9JE8AnkVbbeLP3eay0Pj86KZ2PIq2imKATwJvrAG+bHYjrC+k7xOX3TTqVwHXBU4AdgLuW1XHbfSBmx/nYlX1p0XbLl9Vv+gzzlphAkPaAkn+GrgV7Y36S1V11IybJK0qSY6uqr+edTtWI/tuevbd9Oy76dl300tyEnDTqnJ045xJ8tmqut1aXRWmmwpzTdpn/e8uTjRs4b5vA7wduDjwTeAxVXVKd5vTRpbhFBJpSkleAby3ql4x67Zotlz6eIt8NMnjaIW4Lph65dzmFbHvpmffTc++m559N71Tmc3QfW3azt2IiLsneQ+LVswYogh8N5XjVcBf0Yrkbg2cU1Xb97T/ey9z0zWSUFUf7CMO8CLgTlV1YpL70hYfeGhVHYErjyzLERjSlJI8nLZSxzVoH0beu5pHYCS5GPCPrF+S6gvAwX1mmteqyeJOG9umC0vygyU2V1VdbfTGrDL23fTsu+nZd9Oz76aX5E20s+AfY8Pkz8tm1igB0H3xfhRtRPLiz8GDFIHvagU+ADiUtiLgw4A9q+rfetr/WzZyc/V1girJsVV1g4nr1wE+SCtY+x+OwFiaCQxpC3XL3N6H9ka6W1XtOeMmTSXJG4GLAYd0mx4KnF9V/zC7Vq0O3bzmfRYtffyFqrrebFsmSdLql+TApbZX1bPHbouWluQ/quq5I8U6qqr2TnLcQh2UJF+pqluMEb8vXSLm76rqpxPbdgX+F7h6VV1m2QdfhDmFRNpyfwlci1ZVfDWvFnPjySww8Lnui7k27aXAV5JssPTxbJs035Lctqo+t9wwzR6HZ6459t307Lvp2XfTs++2nImKVeFzSbarqnO6ldn2Al4xUEHz3yXZFjgmyYuA04Ht+tp5kv+uqqd0vz95crp4krdW1SN6CnUAbWWdCxIYVXVaNyXnCT3FWHNMYEhTSvJC4N7A94H3As9dqIGwSp2f5OpV9X2AJFdjokq6lufSx1P5W+BztNV7FivaEEotzb6bnn03PftuevbdlBa+SCb5KN1SlpMGWDZT03stcIMkNwCeBrwJeBvt+O/bQ4GtaF/y/wm4Cm00dF9uPfH7w4HJene9rXxTVZ9ZZvtv8ETYspxCIk0pyf7AB4Cr0aoHA1BVX5xZo7ZAktsBbwFOpn0JvyqwX1V9fqYNkyRJF0lJ/rqqjh5r2UxNb2HVjCT/Cfy4qt401EoaSbYDfl9Vf+6ubw1cvKp+19P+L6hjtrim2VirgyT5eFXtO3Sc1cgRGNL0zqedUdkVOAa4GfBV2ln4VaeqPptkT9YvFfWdqvrDJh4mSZI0iKo6uvtpomL+nZ3kGcBDgFt3SYWLDRTrs8Dtgd921y8JfAroqwbGVt2KcltN/L6wKsjWPcUgyXKJkAA37CvOWmMCQ5rek4AbA0dU1W2SXAtYdXM0k9x6mZtu2i0VtSpHlEiSJGk09wceBDyqqn6aZDfgxQPFukRVLSQvqKrfJrlUj/u/LHA065MWk0vB9jl94Ujaqn9LLZm6Q49x1hQTGNL0zq2qc5OQ5OJV9Z0k15x1o6bw1CW2FXAD2uiS3jLNkiRJWnu6lTReNnH9R7QaGEM4J8leVfUNaFONgN/3tfOq2n0l90tynao6cQtCfRt4bFV9b4l9n7oF+13TTGBI0zstyQ7Ah4FPJ/kV8JOZtmgKVbVBUbEktwKeSavobAVkDSrJxYB/ZH3BrC8AB1fVn2bXqtXBvpuefTc9+2569t2WS3IZoCbPvms+dKvsvBC4Am1EQWiv1fYDhHsKcGiShc/dO9NGgIzt7bTVVqb1LNo0laU8cQv2u6ZZxFPqQVdc6rLAJ6rqj7NuzzS6Ip7/QRt98fyq+vSMm6SLgCRvpM2RPaTb9FDg/Kr6h9m1anWw76Zn303PvpuefTe9JNejnc3fkfbF+Azg4VV1wkwbpgskOQm4W1V9e6R4F2PDum2jJwIXF/jUOExgSBdxSe5KG3HxG+B5VfXlGTdJFyFJjq2qG2xqmy7MvpuefTc9+2569t30knwFeObCymhJ9qGdbOmraKO2UJIvV9UtZ92OMW3piiRJ/nljt1fVyzZ2+0WVU0gkfRQ4DTgTeHqyYR0h11jXwM5PcvWq+j5AkqvRVvjRptl307PvpmffTc++m952k8u6V9W6bilNzY+jkryXNrX6glXsquqDM2vR/LvMrBuwGpnAkHSbWTdAF2lPBT6f5GTaMNCrAvvNtkmrhn03Pftuevbd9Oy76Z2c5D9oNQegLdX5gxm2Rxe2PfA74P+3d+9BetX1HcffnyiKIEIo8QKUekdAuSlWxwsCFasOioBMHdEKWlELA9VW0aJAlVZRaB20Y0EhgSnewkVEURAd0EaGIIZiiJWqyE3UIHhhqlzy7R/nWdhsdhNycp49z+6+XzPPZM/vhPP9zpcnu/t8z+/8fvuOGytgNjcwNuix8aqacbsXjgIfIZH0kCQ5t6oO7DsPzT5JHsnqz7H+cR3/iQasXXvWrj1r1561ayfJfJqt6l9IU7srgOOr6s5eE1MvklxWVfusa6yDOBtNXFsjyVZVtbLjONsCpwIvoGn6fAc4qqpu6TLObGEDQ9JD4kJF6lKSF6/tfFVdMV25zDTWrj1r1561a8/aaS5IsjHwZmAnYOOx8ao6rOMYmwDfAl5C08yCZvbHxVW1Q0dx9qKZ7fNI4PvAW6vqxsG5DVr3Yop4lwLnsPoMo9dX1Uu7jDNb+AiJpIfKbqe69A+TjBWwC7At8LDpTWdGsXbtWbv2rF171q6lJGcy9e8fVVVvns58tFZnAz8EXgb8E/B6oOsdSQ6n2UJ1a+CaceO/BT7ZYZyTgJdV1fIkBwGXJnlDVV3Jg02TLi2oqjPHHS9McvQQ4swKNjAkSdOuqvYbf5zkhTS74fwcOKKXpGYIa9eetWvP2rVn7TbIRZOMbUfzIdbGz2h5alW9Nsmrq2pRknOAr3cZoKo+Dnw8yZFVdWqX157gEVW1fBBzcZIVwHlJjmE4N/RWJjkE+Ozg+HU0i+trEjYwJD1Uw+g4a45Lsg/wfppfCP65qi7tOaUZw9q1Z+3as3btWbv1V1Xnjn092LXlfcCLgQ8Dn+krL01qbK2Iu5I8E7gdeGKXAZLsXVXfBG5NcsDE8x3ueHJvksdX1e2D6y4f/Pu9CHhKRzHGOwz4BPCvNN8flgzGNAkbGJIeqvf0nYBmjySvpLkD+RvgH6vqv3pOacawdu1Zu/asXXvWbsMk2YGmfrsBHwXeVlX39ZuVJnHaYLHVY4ELgUfTNOy6tCfwTWC/Sc51uePJMcDjaJowzcWrbkmyJ0OYNVVVNwGv6vq6s5WLeEpzXJLHA8cBq4APAEcCB9I8t3hUVf28x/Q0SyVZBdwCXMsk0zGryh/kU7B27Vm79qxde9auvSRfBJ4DfAz4AnD/+PNV9es+8tLqkswDDqqqL/Sdy0yUZBHN79x3DY7nAyd3uQDqbOIMDEkLga8Am9Ks6vyfwCuBVwOfGvwpdW2vvhOYwaxde9auPWvXnrVrbw+aps/fA+8ajI090lrAk/tISqurqlVJjqBpMg1NkneuI49Thhl/kMPFVfXyji+781jzAqCq7kzizn9TcAaGNMeN3x41yU1Vtd24c8uqatfektOcl+Tcqjqw7zxmImvXnrVrz9q1Z+3aS7LT2KKL6keS9wP/B3weuHtsvMtZMkmOG3y5PU1z68LB8X7AFVX1lo7iTLVNaoCLquoJXcQZF+9a4CVVdefgeEvg8qp6VpdxZgtnYEiaN+7rs9ZyTuqDd9fas3btWbv2rF171q69s4GpPnRqeow97vC348Y6nSVTVScAJLkE2L2qfjc4Ph74YldxgKXA5Uy+gP0WHcYZczKwJMlimpodDJw4hDizgg0MSV9K8uiq+n1VHTs2mOSpwI96zEuC4WxXNldYu/asXXvWrj1r1547pfVvh6r6w/iBJBsPKdZ2wD3jju+h2x1PVgCHV9UNE08kubnDOABU1VlJrgb2pnkvH1BV13cdZ7awgSHNcVX1gSnG/xc4aJrTkSRJWl82f/q3hDVnwUw21oWzgauSnE/z//41rDmLeEMcz9SzkI/sMM4DBg0LmxYPgQ0MaY4bhQWRpLXwrlp71q49a9eetWvP2mnGGexmtw3wqMHCk2Pv48cAmwwjZlWdmORi4EWDoUOr6vsdXn/xWs5d0FUctWMDQ9JmfScgrcV7+k5gJkjyJ1V1x4Rha9eetWvP2rVn7dq7Z91/RUPyMuBNwLY0azmMNTB+C7xviHE3AX5bVWcmWZDkSVX10y4u7M290eYuJJKkaZfkL6vqa4OvNwdOoVlR/AfA31XVL/rMb5Ql+TDwsapameQ5NNvWrQI2At5YVZf3muAIS3INcB7w2ar6cd/5zCSD99pHgVuB9wJnAM+lWSvprV3e/ZxtkjwaeDdwIM2HvHuAHwOfqqqFPaY2IyQJzXttG5rHBW4Drio/xIyUJAdW1bnTFOs44DnA9lX19CRbA1+sqhd0eP0pjS0mqn7YwJAEQJJtgVOBF9D8gvAd4KiquqXXxDQrJbmmqnYffP1p4HbgdOAAYM+q2r/H9EZakuvGtlZL8i3g3VW1NMnTgXOq6jn9Zji6kvwUOJdmhffbgc8Cn6+q23pNbAZIchVwHM0K/CfRNBoXJ9kH+FBVPb/P/EZZki8B5wPfoHnvbQp8DjgWuLWqhnmXekZLsi/w78ANNM0zaJpATwXeUVWX9JWb+pNkGbAbcE1V7TYY+++q2rnXxDQtbGBIAiDJpcA5NAsjARwCvL6qXtpfVpqtJjQwllXVruPOrXas1SX5IfDMqrovyZVV9bxx5x5obmhNE953LwJeR9M0W0EzK+O0PvMbZUm+P+6Dwk1Vtd1k57SmJNdW1S7jjpdW1R5J5gHXV9UzekxvpCVZAby8qm6cMP4k4KtVtUMvialXSa6qqueOfU9Psinw3a4bGN7cG01Tra4qae5ZUFVnVtV9g9dCYEHfSWnWemySdyZ5F/CYwRThMf5sWrtPAl9NsjfwtST/luTFSU4AlvWb2sxRVd+uqnfQTEv/COAMgrX7Q5J9k7wWqCT7AyTZE7i/18xG391JXgiQZD/g1wBVtQoX7lyXhwOTfVi8leaxOY2wJI8c0qW/kOQ/gC2S/A3N7KbThxDnTOBCYGuanxVfHoypRy7iKWnMyiSH0EyphubO5MRFAaWunM6DC8guArYCfjVYzXxZX0nNBFV1apIfAG8Dnk7zs3x74ALgQz2mNhP8aOJAVd0PfG3w0tTeRvPoyCqaRfvenmQhzQfJt/aY10zwduD0JNsD1wFvBkiygKYhqamdASxN8jng5sHYnwJ/BXymt6y0hiRnVNVh444fDXwJ2KfjOAE+DzyDZqHQ7YEPVNWlXcYZWFBV4xsWC5McPYQ4Wg8+QiIJgCTbAZ+guQtZNHt3H1VVP+s1MUmSNGcl2QF4Nc0d8NDMyLiwqq7vNTGtJskHga2q6u1J5gNfAU6f0ADoKtb3qurZXV93kjjfABay+s29Q6uq06aM1o8NDEnStHOLsvasXXvWrj1r156101yR5CPA5sCzgQ8Pa1eSJJ8EFlbV0mFcf1wcb+6NIB8hkQRAkkU035TvGhzPB04ePx1Q6tBm6/4rmoK1a8/atWft2rN2Q5Dk4qp6ed95zHVJDhh3eBXw/sGfleSAqjpvCGH3Ag5P8jPgbpqZOdX1Ip5VdRPwqi6vqQ3nDAxJwOSryLuyvCRJ6kuS3ac6BVxUVU+Yzny0piRre0SkhnEjLMmfTRGs05kR3twbTc7AkDRmXpL5VXUnQJIt8XuEhswtytqzdu1Zu/asXXvWrpWlwOVMvlvLFtObiiZTVYdOV6wke9Css3HxhPH9gNuArh/t2HmseQFQVXcm8cZez9yqTtKYk4ElST6Y5J9onvM7qeecNPu5RVl71q49a9eetWvP2q2/FcDhVbXXxBewsu/k9KAkC5K8L8lpSc4Ye3Uc5qM074mJVgzOdW3eYNYF4M29UeEjJJIekGRHYG+aOx2XucK3hi3JsqradV1jWpO1a8/atWft2rN26y/JQcB1VfU/k5zbv6oumP6sNJkkS4BvA98D7h8b73IhzyTXVdWzpjh3bVXt0lWswTXfCLwXWEwza+pg4MSqOrvLOFo/dpAkPWDQsLBpoem0MskhrL5F2R095jOTWLv2rF171q49a7eeqmrxWs5dMI2paN02qar3DDnGo9ZybtOug1XVWUmu5sGbewd4c69/zsCQJPXGLcras3btWbv2rF171m79uQXtzJHkQ8CSqvrqEGN8iqbpd2yN+xCb5ATgCVX11mHF1uiwgSFJkiRp5CQ5bm3nq+qE6cpFa5fkdzSzIP4I3MuDW5s+psMYmwKfBp4LLBsM7wJcDbylqn7fVSyNLhsYkqTeuEVZe9auPWvXnrVrz9pJ3UjyZGCnweHyqvrJhPM7VdXy6c9M08E1MCRJfXKLsvasXXvWrj1r1561a8ktaGeGQVPuacDGY2NVdUXXcQYNi5+s5a+cDezedVyNBrdRlST1yS3K2rN27Vm79qxde9auPbegHXFJ3gJcAXwdOGHw5/F9pdNTXE0Dv2lKkvp0MrAkyWpblPWb0oxh7dqzdu1Zu/asXXsLqmp8w2JhkqP7SkaTOgrYA7iyqvZK8gyaRkYfXCNhFnMNDElSr5LsyINblF3mFmUPnbVrz9q1Z+3as3btJPkGsJDVt6A9tKr26S0prSbJ0qraI8ky4M+r6o9JllXVrj3kck1V+QjJLGUDQ5IkSdLIcgva0ZfkfOBQ4GiaJt2dwEZV9Yoecrmyqp433XE1PWxgSJIkSZI6kWRPYHPga1V1zxCuv1FV3TthbKuqWtl1LI0eF/GUJEmSNLKSLEqyxbjj+UnO6DElTSHJJsDdwHe7bl4k2SvJLcBtSS5J8sRxpy/pMpZGlw0MSZIkSaNsjS1oAbegHQFJXpXkxiTXJHkFsJzmcZ/rkvx1x+FOAl5WVQuA04BLk4w9KuLOI3OEu5BIkiRJGmXzkswfNC7cgna0fBDYl+aRkW/RNJt+kuSxwGXAog5jPaKqlgNU1eIkK4DzkhyDO4/MGf7DlyRJkjTK3IJ2dK2qqh8BJPlpVf0EoKp+meS+jmPdm+TxVXX7IMbyJPsAFwFP6TiWRpQNDEmSJEkjq6rOSnI1D25Be4Bb0I6MeUnm0yxNsGrw9djjHF0vV3AM8Djg9rGBqrplsGjoER3H0ohyFxJJkiRJ0npLciOwisnXoKiqevL0ZqTZzgaGJEmSJGlokuw0tn7FkK5/cVW9fFjX1+jwERJJkiRJ0jCdDey+IRdIMtV/H2DXDbm2Zg4bGJIkSZKkYepim9OlwOVTXGuLDq6vGcAGhiRJkiRpmLpYt2AFcHhV3TDxRJKbO7i+ZoCuV4aVJEmSJKlrxzP159cjpzEP9chFPCVJkiRJQ5Pkyqp6Xt95aOazgSFJkiRJai3JRlV174SxrapqZYcx3rm281V1SlexNLp8hESSJEmStN6S7JXkFuC2JJckeeK405d0HG6zdbw0BzgDQ5IkSZK03pIsBd5UVcuTHAT8C/CGqroyyferareeU9Qs4wwMSZIkSVIbj6iq5QBVtRjYH1iU5DV0s/PIGpJsm+T8JL9M8osk5ybZdhixNHpsYEiSJEmS2rg3yePHDgbNjH2A44CnDSnmmcCFwNbANsCXB2OaA3yERJIkSZK03pL8BfCrqrp2wvjmwBFVdeIQYi6rql3XNabZyRkYkiRJkqT1VlXfmNi8GIz/ZhjNi4GVSQ5J8rDB6xDgjiHF0oixgSFJkiRJ6lSSi4d06cOAg4HbgZ8DBw3GNAf4CIkkSZIkab0l2X2qU8BFVfWE6cxHs9/D+05AkiRJkjQjLQUup2lYTLTFMAImWQQcVVV3DY7nAydXlbMw5gAbGJIkSZKkNlYAh1fVDRNPJLl5SDF3HmteAFTVnUl2G1IsjRjXwJAkSZIktXE8U3+mPHJIMecNZl0AkGRLvDE/Z7gGhiRJkiRpRkjyRuC9wGKgaBb0PLGqzu41MU0LGxiSJEmSpPWW5J1rO19Vpwwp7o7A3jRrb1xWVdcPI45Gj1NtJEmSJEltbNZH0EHDwqbFHOQMDEmSJEmSNPJcxFOSJEmS1FqSbZOcn+SXSX6R5Nwk2/adl2YfGxiSJEmSpA1xJnAhsDWwDfDlwZjUKR8hkSRJkiS1lmRZVe26rjFpQzkDQ5IkSZK0IVYmOSTJwwavQ4A7+k5Ks48zMCRJkiRJrSXZDvgE8HyggCXAUVX1s14T06xjA0OSJEmSJI08HyGRJEmSJLWWZFGSLcYdz09yRo8paZaygSFJkiRJ2hA7V9VdYwdVdSewW3/paLaygSFJkiRJ2hDzkswfO0iyJfDwHvPRLOWbSpIkSZK0IU4GliRZTLOI58HAif2mpNnIRTwlSZIkSRskyY7A3kCAy6rq+p5T0ixkA0OSJEmSJI0818CQJEmSJEkjzwaGJEmSJEkaeTYwJEmSJEnSyLOBIUmSJEmSRt7/AxW/nrGb6FcBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean performance increase\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
